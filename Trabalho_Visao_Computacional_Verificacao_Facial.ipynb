{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4c4ae182",
      "metadata": {
        "id": "4c4ae182"
      },
      "source": [
        "\n",
        "# Verificação Facial — Colab/Local (Webcam + Preview)  \n",
        "- **Detecta ambiente Colab/Local**:  \n",
        "  - `IN_COLAB` (True/False)\n",
        "- **Detectores de face**:  \n",
        "  - `haar` (OpenCV CascadeClassifier)  \n",
        "  - `dnn_ssd_resnet10` (OpenCV DNN com Caffe)\n",
        "- **Runner interativo**:\n",
        "  - **Inclusão (novo)**: coleta amostras de um novo usuário e treina LBPH  \n",
        "  - **Autenticação (auth)**: modos **1:1** (usuário esperado) e **1:N** (identificação)\n",
        "  - **Liveness**: checagem simples de energia do sinal\n",
        "- **Avaliação offline** renovada:\n",
        "  - Suporta **.zip / .tar / .tar.gz / .tgz** e **extração recursiva** (ex.: ZIP contendo TAR.GZ).\n",
        "  - **Remoto default** (POSITIVES): **Caltech Face 1999** (`faces.tar`, CaltechDATA).\n",
        "  - **Fallback NEGATIVES**: **Caltech-101** (extrai `BACKGROUND_Google`; se ausente, usa outras categorias ≠ “face”).\n",
        "  - **Câmera também em Remoto/Default** quando `negatives/` estiver vazio (opção interativa).\n",
        "  - Funciona com **single-class**: converte todas as imagens extraídas em `positives/` e completa `negatives/` automaticamente.\n",
        "- **Métricas e gráficos**: matriz de confusão, accuracy, precision, recall, F1, tempo médio; tabela comparativa (se `pandas` disponível).\n",
        "- **Dicas de tuning**: `conf_threshold` para DNN, `minNeighbors/scaleFactor/minSize` para Haar, filtros pós-detecção (razão w/h e tamanho).\n",
        "- **Downloads automáticos**:\n",
        "  - `deploy.prototxt` e `res10_300x300_ssd_iter_140000.caffemodel` (DNN SSD-ResNet10)\n",
        "  - Dataset remoto padrão (CBCL/MIT) reorganizado em `positives/` e `negatives/`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c0088b9",
      "metadata": {
        "id": "5c0088b9"
      },
      "source": [
        "## 1) Instalação (reinicie o runtime após rodar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d0a9722c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0a9722c",
        "outputId": "c7bfa5af-2a0d-4ee6-b8e8-c7ae7f6eca03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python==4.8.1.78 in /usr/local/lib/python3.12/dist-packages (4.8.1.78)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "OpenCV: 4.8.1\n",
            "NumPy: 1.26.4\n",
            "cv2.face OK\n"
          ]
        }
      ],
      "source": [
        "# Recomendado: após executar, vá em Runtime > Restart runtime\n",
        "#!pip uninstall -y opencv-python opencv-contrib-python numpy\n",
        "!pip install --no-cache-dir numpy==1.26.4 opencv-contrib-python==4.8.1.78 matplotlib\n",
        "\n",
        "import cv2, numpy as np\n",
        "print(\"OpenCV:\", cv2.__version__)\n",
        "print(\"NumPy:\", np.__version__)\n",
        "try:\n",
        "    _ = cv2.face.LBPHFaceRecognizer_create()\n",
        "    print(\"cv2.face OK\")\n",
        "except Exception as e:\n",
        "    print(\"Falha cv2.face:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c0cfa7d",
      "metadata": {
        "id": "0c0cfa7d"
      },
      "source": [
        "## 2) Imports, diretórios e parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "207dadc2",
      "metadata": {
        "id": "207dadc2"
      },
      "outputs": [],
      "source": [
        "import base64, json, time, uuid, math\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Javascript, display\n",
        "\n",
        "# Estrutura de pastas\n",
        "DATA_DIR = Path(\"cv_colab_data\")\n",
        "ENROLL_DIR = DATA_DIR/\"enroll\"\n",
        "EVIDENCE_DIR = DATA_DIR/\"evidence\"\n",
        "for d in (DATA_DIR, ENROLL_DIR, EVIDENCE_DIR):\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Parâmetros globais (ajuste conforme sua calibração/ambiente)\n",
        "SERVICE_THRESHOLD = 55.0       # será ajustado automaticamente na calibração\n",
        "LIVENESS_MIN_ENERGY = 8.0      # energia mínima média para ser \"live\"\n",
        "\n",
        "def show_bgr(img, title=\"preview\"):\n",
        "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    plt.figure(figsize=(5,4))\n",
        "    plt.imshow(rgb)\n",
        "    plt.title(title)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1196b8d6",
      "metadata": {
        "id": "1196b8d6"
      },
      "source": [
        "## 3) Pré-processamento (CLAHE + blur)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "799dc6d4",
      "metadata": {
        "id": "799dc6d4"
      },
      "outputs": [],
      "source": [
        "def preprocess_face_gray(gray_200x200):\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    g = clahe.apply(gray_200x200)\n",
        "    g = cv2.GaussianBlur(g, (3,3), 0)\n",
        "    return g"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "babfdb10",
      "metadata": {
        "id": "babfdb10"
      },
      "source": [
        "## 4) Webcam persistente + Preview - Verificação Facial Dual (Colab ↔ Local)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "21d7e319",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21d7e319",
        "outputId": "fc4ca60a-ba8d-4fde-c3f5-dd44c52041b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IN_COLAB = True\n"
          ]
        }
      ],
      "source": [
        "import time, base64, uuid\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# Detecta ambiente\n",
        "IN_COLAB = True\n",
        "try:\n",
        "    from google.colab import output  # só existe no Colab\n",
        "    from IPython.display import Javascript, display\n",
        "    IN_COLAB = True\n",
        "except Exception:\n",
        "    IN_COLAB = False\n",
        "\n",
        "print(\"IN_COLAB =\", IN_COLAB)\n",
        "\n",
        "# ---------- (opcional) janela processada no Colab ----------\n",
        "def update_display_img(frame_bgr):\n",
        "    \"\"\"\n",
        "    Atualiza a <img id='output'> no Colab. Em ambiente local, essa função não faz nada\n",
        "    (use cv2.imshow no seu fluxo local).\n",
        "    \"\"\"\n",
        "    if not IN_COLAB:\n",
        "        return\n",
        "    ok, buffer = cv2.imencode('.jpg', frame_bgr)\n",
        "    if not ok:\n",
        "        return\n",
        "    b64 = base64.b64encode(buffer).decode('utf-8')\n",
        "    output.eval_js(f\"window.updateProcessed && window.updateProcessed('{b64}')\")\n",
        "\n",
        "# ---------- Colab: stream persistente via JS ----------\n",
        "if IN_COLAB:\n",
        "    def _ensure_camera_ready(show_raw=False, width=640, height=480):\n",
        "        js = f\"\"\"\n",
        "        (async () => {{\n",
        "          let container = document.getElementById('camera-container');\n",
        "          if (!container) {{\n",
        "            container = document.createElement('div');\n",
        "            container.id = 'camera-container';\n",
        "            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n",
        "            document.body.appendChild(container);\n",
        "            container.innerHTML = `\n",
        "              <div id=\"cam-left\" style=\"display:{'flex' if show_raw else 'none'}; flex-direction:column; align-items:center; gap:6px;\">\n",
        "                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:{width}px; border:1px solid #ddd; border-radius:8px;\"></video>\n",
        "                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n",
        "              </div>\n",
        "              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
        "                <img id=\"output\" style=\"max-width:{width}px; border:1px solid #ddd; border-radius:8px;\">\n",
        "                <small style=\"color:#555\">Frame processado</small>\n",
        "              </div>\n",
        "              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n",
        "            `;\n",
        "          }} else {{\n",
        "            const left = document.getElementById('cam-left');\n",
        "            if (left) left.style.display = { '\"flex\"' if show_raw else '\"none\"' };\n",
        "          }}\n",
        "\n",
        "          if (!window._colabStream || window._colabStreamInactive) {{\n",
        "            try {{\n",
        "              window._colabStream = await navigator.mediaDevices.getUserMedia({{ video: {{width:{width}, height:{height}}}, audio:false }});\n",
        "              window._colabStreamInactive = false;\n",
        "            }} catch (e) {{\n",
        "              console.error('getUserMedia failed', e);\n",
        "              return false;\n",
        "            }}\n",
        "          }}\n",
        "          const video = document.getElementById('webcam');\n",
        "          if (video && video.srcObject !== window._colabStream) {{\n",
        "            video.srcObject = window._colabStream;\n",
        "          }}\n",
        "\n",
        "          const canvas = document.getElementById('canvas');\n",
        "          window.captureFrame = () => {{\n",
        "            const ctx = canvas.getContext('2d');\n",
        "            const vw = (video && video.videoWidth) ? video.videoWidth : {width};\n",
        "            const vh = (video && video.videoHeight) ? video.videoHeight : {height};\n",
        "            canvas.width = vw; canvas.height = vh;\n",
        "            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n",
        "            return canvas.toDataURL('image/jpeg', 0.9);\n",
        "          }};\n",
        "          window.updateProcessed = (b64) => {{\n",
        "            const img = document.getElementById('output');\n",
        "            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n",
        "          }};\n",
        "          window.stopColabCamera = () => {{\n",
        "            try {{\n",
        "              if (window._colabStream && !window._colabStreamInactive) {{\n",
        "                window._colabStream.getTracks().forEach(t => t.stop());\n",
        "                window._colabStreamInactive = true;\n",
        "              }}\n",
        "            }} catch (e) {{ console.warn(e); }}\n",
        "            const c = document.getElementById('camera-container');\n",
        "            if (c) c.remove();\n",
        "          }};\n",
        "          return true;\n",
        "        }} )();\n",
        "        \"\"\"\n",
        "        display(Javascript(js))\n",
        "        time.sleep(0.2)\n",
        "\n",
        "    def _b64_to_image(data_url_or_b64):\n",
        "        if data_url_or_b64 is None:\n",
        "            return None\n",
        "        s = data_url_or_b64\n",
        "        if isinstance(s, bytes):\n",
        "            s = s.decode(\"utf-8\")\n",
        "        if s.startswith(\"data:image\"):\n",
        "            s = s.split(\",\")[1]\n",
        "        arr = np.frombuffer(base64.b64decode(s), dtype=np.uint8)\n",
        "        return cv2.imdecode(arr, cv2.IMREAD_COLOR)\n",
        "\n",
        "    def capture_one(width=640, height=480, show_raw=False):\n",
        "        _ensure_camera_ready(show_raw=show_raw, width=width, height=height)\n",
        "        data_url = output.eval_js(\"window.captureFrame ? window.captureFrame() : null\")\n",
        "        return _b64_to_image(data_url)\n",
        "\n",
        "    def capture_sequence(n=24, delay_ms=80, width=640, height=480, show_raw=False, preview_callback=None):\n",
        "        _ensure_camera_ready(show_raw=show_raw, width=width, height=height)\n",
        "        frames = []\n",
        "        for i in range(n):\n",
        "            data_url = output.eval_js(\"window.captureFrame ? window.captureFrame() : null\")\n",
        "            img = _b64_to_image(data_url)\n",
        "            if img is not None:\n",
        "                frames.append(img)\n",
        "                if callable(preview_callback):\n",
        "                    preview_callback(img, i)\n",
        "            time.sleep(max(0, delay_ms/1000.0))\n",
        "        return frames\n",
        "\n",
        "    def stop_camera_ui():\n",
        "        display(Javascript(\"if (window.stopColabCamera) window.stopColabCamera();\"))\n",
        "        time.sleep(0.2)\n",
        "\n",
        "# ---------- Local: OpenCV VideoCapture ----------\n",
        "else:\n",
        "    def capture_one(cam_index=0, width=640, height=480, show_raw=False):\n",
        "        cap = cv2.VideoCapture(cam_index)\n",
        "        cap.set(cv2.CAP_PROP_FRAME_WIDTH,  width)\n",
        "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
        "        ret, frame = cap.read()\n",
        "        cap.release()\n",
        "        if not ret:\n",
        "            raise RuntimeError(\"Não conseguiu capturar frame da webcam local\")\n",
        "        return frame\n",
        "\n",
        "    def capture_sequence(n=24, delay_ms=80, cam_index=0, width=640, height=480, show_raw=False, preview_callback=None):\n",
        "        cap = cv2.VideoCapture(cam_index)\n",
        "        cap.set(cv2.CAP_PROP_FRAME_WIDTH,  width)\n",
        "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
        "        frames = []\n",
        "        for i in range(n):\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                continue\n",
        "            frames.append(frame)\n",
        "            if callable(preview_callback):\n",
        "                preview_callback(frame, i)\n",
        "            # preview simples local\n",
        "            cv2.imshow(\"preview\", frame)\n",
        "            if cv2.waitKey(delay_ms) & 0xFF == ord(\"q\"):\n",
        "                break\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        return frames\n",
        "\n",
        "    def stop_camera_ui():\n",
        "        # no local, apenas fecha janelas\n",
        "        cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a56dd9cb",
      "metadata": {
        "id": "a56dd9cb"
      },
      "source": [
        "## 5) Detecção de faces (Haar/DNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "23539590",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23539590",
        "outputId": "14987b3a-5213-49a8-9377-b7aabe3f2247"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Detecção] Modelo atual: haar | MODELS_DIR=cv_colab_data/models\n"
          ]
        }
      ],
      "source": [
        "# ============================\n",
        "# 5) Detecção de faces (Haar/DNN)\n",
        "# ============================\n",
        "#\n",
        "# Suporta dois detectores:\n",
        "#   - \"haar\": Haar Cascade (cv2.CascadeClassifier)\n",
        "#   - \"dnn_ssd_resnet10\": DNN (SSD ResNet10) via OpenCV DNN (Caffe)\n",
        "#\n",
        "# Escolha temporária (até o Runner setar automaticamente):\n",
        "#   - Ajuste DETECTION_MODEL = \"haar\" | \"dnn_ssd_resnet10\"\n",
        "#   - ou exporte a env: DETECTION_MODEL=haar | dnn_ssd_resnet10\n",
        "#\n",
        "# Uso: faces = detect_faces(img_bgr, conf_threshold=0.5)\n",
        "# Retorno: lista de (x, y, w, h, score)\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# ======================\n",
        "# Configuração do modelo\n",
        "# ======================\n",
        "DETECTION_MODEL = os.environ.get(\"DETECTION_MODEL\", \"haar\").strip().lower()\n",
        "\n",
        "# Honra o DATA_DIR definido em outra célula; se não existir, cria um default\n",
        "try:\n",
        "    DATA_DIR  # definido na sua célula de diretórios\n",
        "except NameError:\n",
        "    DATA_DIR = Path(\"cv_colab_data\")\n",
        "    DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "MODELS_DIR = DATA_DIR / \"models\"\n",
        "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Haar: caminho padrão do OpenCV (com fallback)\n",
        "try:\n",
        "    import cv2.data as cvd\n",
        "    HAAR_PATH = str(Path(cvd.haarcascades) / \"haarcascade_frontalface_default.xml\")\n",
        "except Exception:\n",
        "    # fallback: se quiser manter tudo em DATA_DIR/models, pode copiar o xml pra lá\n",
        "    HAAR_PATH = str(MODELS_DIR / \"haarcascade_frontalface_default.xml\")\n",
        "\n",
        "# DNN (SSD ResNet10): caminhos dentro de DATA_DIR/models\n",
        "DNN_PROTO_PATH   = MODELS_DIR / \"deploy.prototxt\"\n",
        "# usamos o modelo Caffe \"não-fp16\", disponível publicamente:\n",
        "DNN_WEIGHTS_PATH = MODELS_DIR / \"res10_300x300_ssd_iter_140000.caffemodel\"\n",
        "\n",
        "# URLs oficiais/alternativas\n",
        "DNN_PROTO_URL   = \"https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt\"\n",
        "DNN_WEIGHTS_URL = \"https://github.com/opencv/opencv_3rdparty/raw/dnn_samples_face_detector_20170830/res10_300x300_ssd_iter_140000.caffemodel\"\n",
        "\n",
        "# --------------\n",
        "# Inicialização\n",
        "# --------------\n",
        "_haar_cascade = None\n",
        "_dnn_net = None\n",
        "\n",
        "def _download_file(url: str, dest: Path) -> bool:\n",
        "    \"\"\"\n",
        "    Baixa com urllib; se falhar e houver 'wget', tenta wget.\n",
        "    Retorna True se o arquivo existir ao final.\n",
        "    \"\"\"\n",
        "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
        "    try:\n",
        "        import urllib.request\n",
        "        print(f\"Baixando {dest.name} …\")\n",
        "        urllib.request.urlretrieve(url, str(dest))\n",
        "        return dest.exists()\n",
        "    except Exception as e:\n",
        "        print(f\"Aviso: urllib falhou ({e}). Tentando wget (se disponível)…\")\n",
        "        try:\n",
        "            code = os.system(f\"wget -q -O {dest} {url}\")\n",
        "            return dest.exists() and code == 0\n",
        "        except Exception as e2:\n",
        "            print(f\"Aviso: wget também falhou ({e2}).\")\n",
        "            return dest.exists()\n",
        "\n",
        "def _download_if_missing():\n",
        "    ok = True\n",
        "    if not Path(DNN_PROTO_PATH).exists():\n",
        "        ok = _download_file(DNN_PROTO_URL, DNN_PROTO_PATH) and ok\n",
        "    if not Path(DNN_WEIGHTS_PATH).exists():\n",
        "        ok = _download_file(DNN_WEIGHTS_URL, DNN_WEIGHTS_PATH) and ok\n",
        "    if not ok:\n",
        "        print(\n",
        "            \"[DNN] Não foi possível garantir todos os arquivos.\\n\"\n",
        "            f\"  Prototxt: {DNN_PROTO_PATH}\\n\"\n",
        "            f\"  Pesos   : {DNN_WEIGHTS_PATH}\\n\"\n",
        "            \"  → Baixe manualmente ou defina DNN_PROTO_PATH / DNN_WEIGHTS_PATH.\"\n",
        "        )\n",
        "\n",
        "def _init_haar():\n",
        "    global _haar_cascade\n",
        "    if _haar_cascade is None:\n",
        "        if not os.path.exists(HAAR_PATH):\n",
        "            raise FileNotFoundError(f\"Haar cascade não encontrado em: {HAAR_PATH}\")\n",
        "        _haar_cascade = cv2.CascadeClassifier(HAAR_PATH)\n",
        "\n",
        "def _init_dnn():\n",
        "    _download_if_missing()\n",
        "    global _dnn_net\n",
        "    if _dnn_net is None:\n",
        "        if not (Path(DNN_PROTO_PATH).exists() and Path(DNN_WEIGHTS_PATH).exists()):\n",
        "            raise FileNotFoundError(\n",
        "                \"Arquivos do DNN não encontrados.\\n\"\n",
        "                f\"  Prototxt: {DNN_PROTO_PATH}\\n\"\n",
        "                f\"  Pesos   : {DNN_WEIGHTS_PATH}\\n\"\n",
        "                \"Ajuste DNN_PROTO_PATH / DNN_WEIGHTS_PATH ou salve os arquivos em DATA_DIR/'models'.\"\n",
        "            )\n",
        "        _dnn_net = cv2.dnn.readNetFromCaffe(str(DNN_PROTO_PATH), str(DNN_WEIGHTS_PATH))\n",
        "\n",
        "# --------------------\n",
        "# Função de detecção\n",
        "# --------------------\n",
        "def detect_faces(image_bgr, conf_threshold: float = 0.5):\n",
        "    \"\"\"\n",
        "    Retorna lista de detecções: (x, y, w, h, score)\n",
        "    \"\"\"\n",
        "    model = DETECTION_MODEL\n",
        "    if model == \"haar\":\n",
        "        _init_haar()\n",
        "        gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
        "        rects = _haar_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "        return [(int(x), int(y), int(w), int(h), 1.0) for (x, y, w, h) in rects]\n",
        "\n",
        "    elif model in (\"dnn\", \"dnn_ssd_resnet10\", \"ssd\", \"resnet10\"):\n",
        "        _init_dnn()\n",
        "        (h, w) = image_bgr.shape[:2]\n",
        "        blob = cv2.dnn.blobFromImage(\n",
        "            cv2.resize(image_bgr, (300, 300)), 1.0, (300, 300),\n",
        "            (104.0, 177.0, 123.0)\n",
        "        )\n",
        "        _dnn_net.setInput(blob)\n",
        "        detections = _dnn_net.forward()\n",
        "        boxes = []\n",
        "        for i in range(detections.shape[2]):\n",
        "            confidence = float(detections[0, 0, i, 2])\n",
        "            if confidence >= conf_threshold:\n",
        "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "                x, y = max(0, startX), max(0, startY)\n",
        "                ww, hh = max(0, endX - startX), max(0, endY - startY)\n",
        "                boxes.append((x, y, ww, hh, confidence))\n",
        "        return boxes\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Modelo '{model}' não suportado. Use 'haar' ou 'dnn_ssd_resnet10'.\")\n",
        "\n",
        "# --------------------\n",
        "# Helper de visualização\n",
        "# --------------------\n",
        "def draw_faces(image_bgr, faces, color=(0,255,0), thickness=2):\n",
        "    out = image_bgr.copy()\n",
        "    for (x,y,w,h,score) in faces:\n",
        "        cv2.rectangle(out, (x,y), (x+w, y+h), color, thickness)\n",
        "        cv2.putText(out, f\"{score:.2f}\", (x, max(0,y-5)), cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 1, cv2.LINE_AA)\n",
        "    return out\n",
        "\n",
        "print(f\"[Detecção] Modelo atual: {DETECTION_MODEL} | MODELS_DIR={MODELS_DIR}\")\n",
        "\n",
        "# Teste rápido (opcional)\n",
        "# img = capture_one(show_raw=True)\n",
        "# faces = detect_faces(img)\n",
        "# vis = draw_faces(img, faces)\n",
        "# show_bgr(vis, \"faces detectadas\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5b79479",
      "metadata": {
        "id": "c5b79479"
      },
      "source": [
        "## 6) Config de preview e evidências"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "af35c8bc",
      "metadata": {
        "id": "af35c8bc"
      },
      "outputs": [],
      "source": [
        "# Cores das caixas (BGR)\n",
        "PREVIEW_BOX_COLOR = (0, 255, 0)     # verde\n",
        "CALIB_BOX_COLOR   = (255, 165, 0)   # laranja\n",
        "FINAL_BOX_COLOR   = (0, 255, 255)   # amarelo\n",
        "SAVE_EVIDENCE     = True\n",
        "\n",
        "def draw_box(img_bgr, bbox, color, thickness=2, label=None):\n",
        "    x,y,w,h = bbox\n",
        "    cv2.rectangle(img_bgr, (x,y), (x+w, y+h), color, thickness)\n",
        "    if label:\n",
        "        cv2.putText(img_bgr, label, (x, max(0, y-8)), cv2.FONT_HERSHEY_SIMPLEX, 0.55, color, 2, cv2.LINE_AA)\n",
        "\n",
        "def maybe_save_evidence(result: dict, vis_bgr, prefix=\"auth\"):\n",
        "    if not SAVE_EVIDENCE:\n",
        "        return\n",
        "    status = result.get(\"status\", \"\")\n",
        "    if status in (\"error\", \"route_review\"):\n",
        "        ts = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "        name = f\"{prefix}_{status}_{ts}_{uuid.uuid4().hex[:6]}.jpg\"\n",
        "        cv2.imwrite(str(EVIDENCE_DIR / name), vis_bgr)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5ae218f",
      "metadata": {
        "id": "d5ae218f"
      },
      "source": [
        "## 7) Enrollment com preview (função)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bf25ffcf",
      "metadata": {
        "id": "bf25ffcf"
      },
      "outputs": [],
      "source": [
        "def enroll_user_with_preview(user_id=\"novo_usuario_preview\", n_samples=30, interval_ms=100):\n",
        "    user_dir = ENROLL_DIR / user_id\n",
        "    user_dir.mkdir(parents=True, exist_ok=True)\n",
        "    setup = capture_one(show_raw=True)  # inicializa UI (mostra preview bruto)\n",
        "\n",
        "    saved = 0\n",
        "    attempts = 0\n",
        "    print(f\"Coletando {n_samples} amostras para '{user_id}'… Olhe para a câmera.\")\n",
        "    while saved < n_samples and attempts < n_samples*3:\n",
        "        attempts += 1\n",
        "        fr = capture_one(show_raw=True)\n",
        "        if fr is None:\n",
        "            time.sleep(0.05);\n",
        "            continue\n",
        "        faces = detect_faces(fr)\n",
        "        vis = fr.copy()\n",
        "        if len(faces):\n",
        "            (x,y,w,h,score) = max(faces, key=lambda f: f[2]*f[3]) # Unpack 5 values\n",
        "            draw_box(vis, (x,y,w,h), PREVIEW_BOX_COLOR, label=\"enroll\")\n",
        "            face = fr[y:y+h, x:x+w]\n",
        "            g = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
        "            g = cv2.resize(g, (200,200))\n",
        "            g = preprocess_face_gray(g)\n",
        "            cv2.imwrite(str(user_dir/f\"{user_id}_{uuid.uuid4().hex[:6]}.jpg\"), g)\n",
        "            saved += 1\n",
        "        update_display_img(vis)\n",
        "        time.sleep(max(0, interval_ms/1000.0))\n",
        "    print(f\"✅ Enrollment concluído: {saved}/{n_samples} amostras salvas.\")\n",
        "    if saved < max(10, int(0.5*n_samples)):\n",
        "        print(\"⚠️ Poucas amostras úteis. Considere refazer com melhor enquadramento/iluminação.\")\n",
        "    # não fecha a UI aqui para reaproveitar no próximo passo"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0f00c3b",
      "metadata": {
        "id": "a0f00c3b"
      },
      "source": [
        "## 8) Modelo LBPH em memória (cache global)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "be1e62e6",
      "metadata": {
        "id": "be1e62e6"
      },
      "outputs": [],
      "source": [
        "REC_CACHE = None\n",
        "LABEL_MAP_CACHE = None\n",
        "INV_LABEL_CACHE = None\n",
        "\n",
        "def _load_images_and_labels():\n",
        "    images, labels = [], []\n",
        "    label_map = {}\n",
        "    next_label = 0\n",
        "    for ud in sorted(ENROLL_DIR.glob(\"*\")):\n",
        "        if not ud.is_dir():\n",
        "            continue\n",
        "        uid = ud.name\n",
        "        label_map[uid] = next_label\n",
        "        for p in ud.glob(\"*.jpg\"):\n",
        "            g = cv2.imread(str(p), cv2.IMREAD_GRAYSCALE)\n",
        "            if g is None:\n",
        "                continue\n",
        "            g = cv2.resize(g, (200,200))\n",
        "            g = preprocess_face_gray(g)\n",
        "            images.append(g); labels.append(next_label)\n",
        "        next_label += 1\n",
        "    return images, np.array(labels), label_map\n",
        "\n",
        "def train_lbph_in_memory(neighbors=16):\n",
        "    global REC_CACHE, LABEL_MAP_CACHE, INV_LABEL_CACHE\n",
        "    images, labels, label_map = _load_images_and_labels()\n",
        "    if len(images) == 0:\n",
        "        raise RuntimeError(\"Sem amostras. Faça o enrollment antes.\")\n",
        "    rec = cv2.face.LBPHFaceRecognizer_create(radius=2, neighbors=neighbors, grid_x=8, grid_y=8)\n",
        "    rec.train(images, labels)\n",
        "    REC_CACHE = rec\n",
        "    LABEL_MAP_CACHE = label_map\n",
        "    INV_LABEL_CACHE = {v:k for k,v in label_map.items()}\n",
        "    print(f\"Modelo LBPH treinado em memória. Usuários: {list(label_map.keys())}\")\n",
        "    return rec\n",
        "\n",
        "def get_recognizer(neighbors=16, force_retrain=False):\n",
        "    global REC_CACHE, LABEL_MAP_CACHE, INV_LABEL_CACHE\n",
        "    if force_retrain or REC_CACHE is None or LABEL_MAP_CACHE is None or INV_LABEL_CACHE is None:\n",
        "        print(\"↻ Treinando LBPH (memória)…\")\n",
        "        return train_lbph_in_memory(neighbors=neighbors)\n",
        "    return REC_CACHE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de3a1cce",
      "metadata": {
        "id": "de3a1cce"
      },
      "source": [
        "## 9) Calibração automática do limiar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6a2c5e8c",
      "metadata": {
        "id": "6a2c5e8c"
      },
      "outputs": [],
      "source": [
        "def _detect_face_gray200(img_bgr):\n",
        "    faces = detect_faces(img_bgr)\n",
        "    if len(faces)==0:\n",
        "        return None, None\n",
        "    (x,y,w,h,score) = max(faces, key=lambda f: f[2]*f[3]) # Unpack 5 values including score\n",
        "    face = img_bgr[y:y+h, x:x+w]\n",
        "    g = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
        "    g = cv2.resize(g, (200,200))\n",
        "    g = preprocess_face_gray(g)\n",
        "    return g, (x,y,w,h)\n",
        "\n",
        "def calibrate_threshold(samples=15, neighbors=16):\n",
        "    global SERVICE_THRESHOLD\n",
        "    rec = get_recognizer(neighbors=neighbors)\n",
        "    dists = []\n",
        "    print(f\"📏 Calibrando limiar (coletando {samples} distâncias)…\")\n",
        "    for i in range(samples):\n",
        "        fr = capture_one(show_raw=True)\n",
        "        if fr is None:\n",
        "            time.sleep(0.05);\n",
        "            continue\n",
        "        g200, bbox = _detect_face_gray200(fr)\n",
        "        vis = fr.copy()\n",
        "        if bbox is not None:\n",
        "            (x,y,w,h) = bbox\n",
        "            draw_box(vis, (x,y,w,h), CALIB_BOX_COLOR, label=\"calib\")\n",
        "            _, dist = rec.predict(g200)\n",
        "            dists.append(dist)\n",
        "            print(f\"[{i+1}/{samples}] dist={dist:.1f}\")\n",
        "        update_display_img(vis)\n",
        "        time.sleep(0.08)\n",
        "    if dists:\n",
        "        p95 = float(np.percentile(dists, 95))\n",
        "        SERVICE_THRESHOLD = round(p95 + 5.0, 1)\n",
        "        print(f\"🎯 Novo SERVICE_THRESHOLD = {SERVICE_THRESHOLD} (p95={p95:.1f} + margem)\")\n",
        "    else:\n",
        "        print(\"⚠️ Calibração insuficiente; threshold mantido.\")\n",
        "    return SERVICE_THRESHOLD"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5468bd2f",
      "metadata": {
        "id": "5468bd2f"
      },
      "source": [
        "## 10) Liveness passivo com preview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4ff8dc03",
      "metadata": {
        "id": "4ff8dc03"
      },
      "outputs": [],
      "source": [
        "def liveness_passive_preview(n=24, delay_ms=80, min_energy=LIVENESS_MIN_ENERGY):\n",
        "    prev = None\n",
        "    energy = 0.0\n",
        "    used = 0\n",
        "    for i in range(n):\n",
        "        fr = capture_one(show_raw=True)\n",
        "        if fr is None:\n",
        "            time.sleep(0.05)\n",
        "            continue\n",
        "        faces = detect_faces(fr)\n",
        "        vis = fr.copy()\n",
        "        if len(faces):\n",
        "            (x,y,w,h,score) = max(faces, key=lambda f: f[2]*f[3]) # Unpack 5 values\n",
        "            draw_box(vis, (x,y,w,h), PREVIEW_BOX_COLOR, label=\"live\")\n",
        "            face = fr[y:y+h, x:x+w]\n",
        "            g = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
        "            g = cv2.resize(g, (160,160))\n",
        "            g = preprocess_face_gray(g)\n",
        "            if prev is not None:\n",
        "                diff = cv2.absdiff(g, prev)\n",
        "                energy += float(np.mean(diff))\n",
        "            prev = g; used += 1\n",
        "        update_display_img(vis)\n",
        "        time.sleep(max(0, delay_ms/1000.0))\n",
        "    avg = energy / max(1, used)\n",
        "    verdict = \"live\" if avg >= min_energy else \"spoof\"\n",
        "    print(f\"[Liveness] energia média: {avg:.2f} -> {verdict}\")\n",
        "    return verdict, avg"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3eff28f",
      "metadata": {
        "id": "b3eff28f"
      },
      "source": [
        "## 11) Autenticação 1:1 (com liveness e preview)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6ea82543",
      "metadata": {
        "id": "6ea82543"
      },
      "outputs": [],
      "source": [
        "def authenticate_1v1_preview(expected_user=\"novo_usuario_preview\", neighbors=16, require_liveness=True):\n",
        "    thr = SERVICE_THRESHOLD\n",
        "    if require_liveness:\n",
        "        verdict, energy = liveness_passive_preview(n=24, delay_ms=80, min_energy=LIVENESS_MIN_ENERGY)\n",
        "        if verdict != \"live\":\n",
        "            print(f\"🛑 Liveness falhou (energia={energy:.2f}).\")\n",
        "            result = {\"status\":\"route_review\", \"mode\":\"1v1\", \"reason\":\"liveness_fail\", \"energy\":energy}\n",
        "            maybe_save_evidence(result, np.zeros((10,10,3), dtype=np.uint8), prefix=\"auth_1v1\")\n",
        "            return result\n",
        "\n",
        "    rec = get_recognizer(neighbors=neighbors)\n",
        "    fr = capture_one(show_raw=True)\n",
        "    if fr is None:\n",
        "        result = {\"status\":\"error\", \"mode\":\"1v1\", \"reason\":\"capture_fail\"}\n",
        "        return result\n",
        "\n",
        "    g200, bbox = _detect_face_gray200(fr)\n",
        "    vis = fr.copy()\n",
        "    if bbox is None:\n",
        "        update_display_img(vis)\n",
        "        result = {\"status\":\"error\", \"mode\":\"1v1\", \"reason\":\"no_face\"}\n",
        "        maybe_save_evidence(result, vis, prefix=\"auth_1v1\")\n",
        "        return result\n",
        "\n",
        "    (x,y,w,h) = bbox\n",
        "    draw_box(vis, (x,y,w,h), FINAL_BOX_COLOR, label=\"auth 1:1\")\n",
        "    update_display_img(vis)\n",
        "\n",
        "    label, conf = rec.predict(g200)\n",
        "    pred_user = INV_LABEL_CACHE.get(label, \"desconhecido\")\n",
        "    print(f\"🔐 1:1 — esperado={expected_user} | predito={pred_user} | dist={conf:.1f} | thr={thr}\")\n",
        "\n",
        "    if pred_user == expected_user and conf <= thr:\n",
        "        result = {\"status\":\"approved\", \"mode\":\"1v1\", \"user\":pred_user, \"dist\":float(conf), \"threshold\":thr}\n",
        "    else:\n",
        "        result = {\"status\":\"route_review\", \"mode\":\"1v1\", \"reason\":\"no_match\", \"pred\":pred_user, \"dist\":float(conf), \"threshold\":thr}\n",
        "        maybe_save_evidence(result, vis, prefix=\"auth_1v1\")\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eff1f2a9",
      "metadata": {
        "id": "eff1f2a9"
      },
      "source": [
        "## 12) Autenticação 1:N (com liveness e preview)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "353349b8",
      "metadata": {
        "id": "353349b8"
      },
      "outputs": [],
      "source": [
        "def authenticate_1vN_preview(neighbors=16, require_liveness=True):\n",
        "    thr = SERVICE_THRESHOLD\n",
        "    if require_liveness:\n",
        "        verdict, energy = liveness_passive_preview(n=24, delay_ms=80, min_energy=LIVENESS_MIN_ENERGY)\n",
        "        if verdict != \"live\":\n",
        "            print(f\"🛑 Liveness falhou (energia={energy:.2f}).\")\n",
        "            result = {\"status\":\"route_review\", \"mode\":\"1vN\", \"reason\":\"liveness_fail\", \"energy\":energy}\n",
        "            maybe_save_evidence(result, np.zeros((10,10,3), dtype=np.uint8), prefix=\"auth_1vN\")\n",
        "            return result\n",
        "\n",
        "    rec = get_recognizer(neighbors=neighbors)\n",
        "    fr = capture_one(show_raw=True)\n",
        "    if fr is None:\n",
        "        result = {\"status\":\"error\", \"mode\":\"1vN\", \"reason\":\"capture_fail\"}\n",
        "        return result\n",
        "\n",
        "    g200, bbox = _detect_face_gray200(fr)\n",
        "    vis = fr.copy()\n",
        "    if bbox is None:\n",
        "        update_display_img(vis)\n",
        "        result = {\"status\":\"error\", \"mode\":\"1vN\", \"reason\":\"no_face\"}\n",
        "        maybe_save_evidence(result, vis, prefix=\"auth_1vN\")\n",
        "        return result\n",
        "\n",
        "    (x,y,w,h) = bbox\n",
        "    draw_box(vis, (x,y,w,h), FINAL_BOX_COLOR, label=\"auth 1:N\")\n",
        "    update_display_img(vis)\n",
        "\n",
        "    label, conf = rec.predict(g200)  # menor = melhor\n",
        "    user_pred = INV_LABEL_CACHE.get(label, \"desconhecido\")\n",
        "    print(f\"🧭 1:N — predito={user_pred} | dist={conf:.1f} | thr={thr}\")\n",
        "\n",
        "    if conf <= thr:\n",
        "        result = {\"status\":\"approved\", \"mode\":\"1vN\", \"user\":user_pred, \"dist\":float(conf), \"threshold\":thr}\n",
        "    else:\n",
        "        result = {\"status\":\"route_review\", \"mode\":\"1vN\", \"reason\":\"no_match\", \"pred\":user_pred, \"dist\":float(conf), \"threshold\":thr}\n",
        "        maybe_save_evidence(result, vis, prefix=\"auth_1vN\")\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vxUzE2bnhcOQ",
      "metadata": {
        "id": "vxUzE2bnhcOQ"
      },
      "source": [
        "## 13) Bloco de utilidades de avaliação\n",
        "\n",
        "> Adicionar aspas\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "PhKjkZ4ghdSl",
      "metadata": {
        "id": "PhKjkZ4ghdSl"
      },
      "outputs": [],
      "source": [
        "# =============================================\n",
        "# Função: avaliação OFFLINE com DATASET AUTOMÁTICO\n",
        "#  - positives: ENROLL_DIR/<user> (ou todos, se não houver alvo)\n",
        "#  - negatives: persistidos em DATA_DIR/\"negatives\" (captura da câmera se faltarem)\n",
        "#  - usa detect_faces() da célula 5\n",
        "# Retorna: dict com métricas e info (ou None se falhar)\n",
        "# =============================================\n",
        "import os, time, shutil\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "try:\n",
        "    import pandas as pd\n",
        "except Exception:\n",
        "    pd = None\n",
        "\n",
        "def run_offline_eval_from_enrollment(\n",
        "    neg_target_min: int = 30,\n",
        "    capture_batch: int = 30,\n",
        "    capture_sleep_sec: float = 0.15,\n",
        "    eval_max_images: int | None = None,\n",
        "    conf_threshold: float = 0.5,\n",
        "    use_camera: bool = True,\n",
        "    negatives_src_dir: str | Path | None = None,\n",
        "    dataset_dir_override: str | Path | None = None, # Adicionado\n",
        "    default_dataset_dir: str | Path | None = None,  # Adicionado\n",
        "):\n",
        "    \"\"\"\n",
        "    Executa avaliação offline após o fluxo principal do Runner.\n",
        "    - Garante arquivos do DNN (se DETECTION_MODEL = dnn_ssd_resnet10).\n",
        "    - Monta dataset em DATA_DIR/'dataset_auto' (positives de ENROLL_DIR, negatives persistentes).\n",
        "    - Roda matriz de confusão e métricas (robusto a apenas 1 classe).\n",
        "    \"\"\"\n",
        "    # ===== caminhos vindos de células anteriores =====\n",
        "    try:\n",
        "        DATA_DIR\n",
        "    except NameError:\n",
        "        # fallback seguro\n",
        "        globals()[\"DATA_DIR\"] = Path(\"cv_colab_data\")\n",
        "        DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    try:\n",
        "        ENROLL_DIR\n",
        "    except NameError:\n",
        "        globals()[\"ENROLL_DIR\"] = DATA_DIR / \"enroll\"\n",
        "        ENROLL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    NEG_STORE_DIR = DATA_DIR / \"negatives\"      # negativos persistentes\n",
        "    DATASET_AUTO  = DATA_DIR / \"dataset_auto\"   # dataset gerado automaticamente\n",
        "    POS_DIR_AUTO  = DATASET_AUTO / \"positives\"\n",
        "    NEG_DIR_AUTO  = DATASET_AUTO / \"negatives\"\n",
        "    NEG_STORE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    NAME_MAP = {True: \"face\", False: \"no_face\"}\n",
        "\n",
        "    # ===== helpers =====\n",
        "    def _list_images(dirpath: Path):\n",
        "        exts = {\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\"}\n",
        "        if not dirpath.is_dir():\n",
        "            return []\n",
        "        return sorted([str(p) for p in dirpath.iterdir() if p.suffix.lower() in exts])\n",
        "\n",
        "    def _copy_all_images(src: Path, dst: Path):\n",
        "        dst.mkdir(parents=True, exist_ok=True)\n",
        "        count = 0\n",
        "        for ext in (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.bmp\",\"*.tif\",\"*.tiff\"):\n",
        "            for p in src.rglob(ext):\n",
        "                out = dst / f\"{p.stem}_{count}{p.suffix.lower()}\"\n",
        "                try:\n",
        "                    shutil.copy2(p, out)\n",
        "                    count += 1\n",
        "                except Exception:\n",
        "                    pass\n",
        "        return count\n",
        "\n",
        "    def _capture_negatives_persistent(store_dir: Path, frames=30, sleep=0.15):\n",
        "        if not use_camera:\n",
        "            return 0\n",
        "        cap = cv2.VideoCapture(0)\n",
        "        if not cap.isOpened():\n",
        "            print(\"✘ Não foi possível abrir a câmera para capturar negativos.\")\n",
        "            return 0\n",
        "        print(f\"🎥 Capturando {frames} negativos (aponte para parede/quadro vazio ou saia do frame)…\")\n",
        "        count = 0\n",
        "        for i in range(frames):\n",
        "            ok, frame = cap.read()\n",
        "            if not ok:\n",
        "                break\n",
        "            out = store_dir / f\"neg_{int(time.time())}_{i:03d}.jpg\"\n",
        "            cv2.imwrite(str(out), frame)\n",
        "            time.sleep(sleep)\n",
        "            count += 1\n",
        "        cap.release()\n",
        "        print(f\"✔ Negativos capturados (persistentes): {count}\")\n",
        "        return count\n",
        "\n",
        "    def _ensure_dnn_files_if_needed():\n",
        "        det = os.environ.get(\"DETECTION_MODEL\", \"\").lower()\n",
        "        if det not in (\"dnn_ssd_resnet10\", \"dnn\", \"ssd\", \"resnet10\"):\n",
        "            return\n",
        "        MODELS_DIR = DATA_DIR / \"models\"\n",
        "        PROTO   = MODELS_DIR / \"deploy.prototxt\"\n",
        "        WEIGHTS = MODELS_DIR / \"res10_300x300_ssd_iter_140000.caffemodel\"\n",
        "        if PROTO.exists() and WEIGHTS.exists():\n",
        "            return\n",
        "        MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "        try:\n",
        "            import urllib.request\n",
        "            if not PROTO.exists():\n",
        "                print(\"Baixando deploy.prototxt …\")\n",
        "                urllib.request.urlretrieve(\n",
        "                    \"https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt\",\n",
        "                    str(PROTO)\n",
        "                )\n",
        "            if not WEIGHTS.exists():\n",
        "                print(\"Baixando res10_300x300_ssd_iter_140000.caffemodel …\")\n",
        "                urllib.request.urlretrieve(\n",
        "                    \"https://github.com/opencv/opencv_3rdparty/raw/dnn_samples_face_detector_20170830/res10_300x300_ssd_iter_140000.caffemodel\",\n",
        "                    str(WEIGHTS)\n",
        "                )\n",
        "            print(\"✔ DNN pronto em\", MODELS_DIR)\n",
        "        except Exception as e:\n",
        "            print(\"✘ Falha ao baixar arquivos do DNN automaticamente:\", e)\n",
        "            print(\"  → Baixe manualmente para:\", MODELS_DIR)\n",
        "\n",
        "    def _evaluate_current_detector(dataset_dir: Path, max_images=None, conf_threshold=0.5):\n",
        "        pos_imgs = _list_images(dataset_dir / \"positives\")\n",
        "        neg_imgs = _list_images(dataset_dir / \"negatives\")\n",
        "        if max_images:\n",
        "            pos_imgs = pos_imgs[:max_images]\n",
        "            neg_imgs = neg_imgs[:max_images]\n",
        "\n",
        "        y_true, y_pred, times = [], [], []\n",
        "        import time as _t\n",
        "        # usa detect_faces() da célula 5\n",
        "        for p in pos_imgs:\n",
        "            img = cv2.imread(p)\n",
        "            if img is None:\n",
        "                continue\n",
        "            t0 = _t.perf_counter()\n",
        "            boxes = detect_faces(img, conf_threshold=conf_threshold)\n",
        "            times.append(_t.perf_counter() - t0)\n",
        "            y_true.append(True)\n",
        "            y_pred.append(len(boxes) > 0)\n",
        "\n",
        "        for p in neg_imgs:\n",
        "            img = cv2.imread(p)\n",
        "            if img is None:\n",
        "                continue\n",
        "            t0 = _t.perf_counter()\n",
        "            boxes = detect_faces(img, conf_threshold=conf_threshold)\n",
        "            times.append(_t.perf_counter() - t0)\n",
        "            y_true.append(False)\n",
        "            y_pred.append(len(boxes) > 0)\n",
        "\n",
        "        if not y_true:\n",
        "            raise ValueError(\"Dataset vazio para avaliação.\")\n",
        "\n",
        "        # classes realmente presentes\n",
        "        present = sorted(set(y_true))\n",
        "        cm = confusion_matrix(y_true, y_pred, labels=present)\n",
        "        acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "        def _safe(fn):\n",
        "            try:\n",
        "                return fn(y_true, y_pred, zero_division=0)\n",
        "            except Exception:\n",
        "                return float(\"nan\")\n",
        "\n",
        "        if set(present) == {True, False}:\n",
        "            prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "            rec  = recall_score(y_true, y_pred, zero_division=0)\n",
        "            f1   = f1_score(y_true, y_pred, zero_division=0)\n",
        "            print(\"\\n=== Relatório (2 classes) ===\")\n",
        "            print(classification_report(\n",
        "                y_true, y_pred, labels=present,\n",
        "                target_names=[NAME_MAP[c] for c in present], zero_division=0\n",
        "            ))\n",
        "        else:\n",
        "            prec = _safe(precision_score)\n",
        "            rec  = _safe(recall_score)\n",
        "            f1   = _safe(f1_score)\n",
        "            faltante = \"no_face\" if present == [True] else \"face\"\n",
        "            print(f\"\\n[AVISO] Apenas 1 classe presente (faltando: {faltante}). Métricas completas não se aplicam.\")\n",
        "\n",
        "        avg_time = float(np.mean(times)) if times else float(\"nan\")\n",
        "        mdl = os.environ.get(\"DETECTION_MODEL\", \"(desconhecido)\")\n",
        "\n",
        "        print(f\"\\n=== Resultados: {mdl} ===\")\n",
        "        print(f\"Accuracy : {acc:.4f}\")\n",
        "        print(f\"Precision: {prec if np.isfinite(prec) else 'N/A'}\")\n",
        "        print(f\"Recall   : {rec if np.isfinite(rec) else 'N/A'}\")\n",
        "        print(f\"F1-score : {f1 if np.isfinite(f1) else 'N/A'}\")\n",
        "        print(f\"Tempo médio por imagem: {avg_time:.4f} s\")\n",
        "\n",
        "        # Plot\n",
        "        plt.figure(figsize=(4, 3))\n",
        "        plt.imshow(cm, interpolation='nearest')\n",
        "        plt.title(f\"Matriz de Confusão - {mdl}\")\n",
        "        plt.colorbar()\n",
        "        ticks = np.arange(len(present))\n",
        "        plt.xticks(ticks, [NAME_MAP[c] for c in present], rotation=45)\n",
        "        plt.yticks(ticks, [NAME_MAP[c] for c in present])\n",
        "        thresh = cm.max() / 2.0 if cm.size else 0\n",
        "        for i in range(cm.shape[0]):\n",
        "            for j in range(cm.shape[1]):\n",
        "                plt.text(j, i, f\"{cm[i, j]:d}\",\n",
        "                         ha=\"center\",\n",
        "                         color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        plt.ylabel('Verdadeiro')\n",
        "        plt.xlabel('Predito')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        metrics = {\n",
        "            \"model\": mdl, \"accuracy\": float(acc),\n",
        "            \"precision\": (float(prec) if np.isfinite(prec) else None),\n",
        "            \"recall\": (float(rec) if np.isfinite(rec) else None),\n",
        "            \"f1\": (float(f1) if np.isfinite(f1) else None),\n",
        "            \"avg_time\": avg_time, \"n_samples\": len(y_true),\n",
        "            \"classes_presentes\": [NAME_MAP[c] for c in present],\n",
        "            \"confusion_matrix\": cm,\n",
        "        }\n",
        "\n",
        "        if pd is not None:\n",
        "            try:\n",
        "                df = pd.DataFrame([{\n",
        "                    \"modelo\": metrics[\"model\"], \"accuracy\": metrics[\"accuracy\"],\n",
        "                    \"precision\": metrics[\"precision\"], \"recall\": metrics[\"recall\"],\n",
        "                    \"f1\": metrics[\"f1\"], \"avg_time\": metrics[\"avg_time\"],\n",
        "                    \"n\": metrics[\"n_samples\"], \"classes_presentes\": metrics[\"classes_presentes\"]\n",
        "                }])\n",
        "                display(df)\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    # ===== 1) DNN (se necessário) =====\n",
        "    _ensure_dnn_files_if_needed()\n",
        "\n",
        "    # ===== Use dataset_override if provided =====\n",
        "    if dataset_dir_override is not None:\n",
        "        print(f\"ℹ Usando dataset override: {dataset_dir_override}\")\n",
        "        try:\n",
        "            metrics = _evaluate_current_detector(Path(dataset_dir_override), max_images=eval_max_images, conf_threshold=conf_threshold)\n",
        "            return metrics\n",
        "        except Exception as e:\n",
        "            print(\"✘ Falha na avaliação offline com dataset override:\", e)\n",
        "            return None\n",
        "\n",
        "    # ===== Use default_dataset_dir if provided =====\n",
        "    if default_dataset_dir is not None:\n",
        "        print(f\"ℹ Usando dataset DEFAULT: {default_dataset_dir}\")\n",
        "        try:\n",
        "            metrics = _evaluate_current_detector(Path(default_dataset_dir), max_images=eval_max_images, conf_threshold=conf_threshold)\n",
        "            return metrics\n",
        "        except Exception as e:\n",
        "            print(\"✘ Falha na avaliação offline com dataset default:\", e)\n",
        "            return None\n",
        "\n",
        "    # ===== 2) usuário alvo para positives (para dataset_auto) =====\n",
        "    target_user = None\n",
        "    if 'NEW_USER_ID' in globals() and NEW_USER_ID:\n",
        "        target_user = NEW_USER_ID\n",
        "    elif 'AUTH_MODE_1V1' in globals() and AUTH_MODE_1V1 and 'EXPECTED_USER_1V1' in globals() and EXPECTED_USER_1V1:\n",
        "        target_user = EXPECTED_USER_1V1\n",
        "\n",
        "    # ===== 3) (re)criar dataset_auto =====\n",
        "    if DATASET_AUTO.exists():\n",
        "        shutil.rmtree(DATASET_AUTO)\n",
        "    POS_DIR_AUTO.mkdir(parents=True, exist_ok=True)\n",
        "    NEG_DIR_AUTO.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # ===== 4) positives (para dataset_auto) =====\n",
        "    npos = 0\n",
        "    if target_user:\n",
        "        src_pos = ENROLL_DIR / target_user\n",
        "        if src_pos.is_dir():\n",
        "            npos = _copy_all_images(src_pos, POS_DIR_AUTO)\n",
        "            print(f\"✔ Positives de '{target_user}': {npos}\")\n",
        "        else:\n",
        "            print(f\"✘ Não encontrei ENROLL_DIR para '{target_user}': {src_pos}\")\n",
        "    else:\n",
        "        if ENROLL_DIR.is_dir():\n",
        "            for sub in ENROLL_DIR.iterdir():\n",
        "                if sub.is_dir():\n",
        "                    npos += _copy_all_images(sub, POS_DIR_AUTO)\n",
        "        print(f\"✔ Positives (todos): {npos}\")\n",
        "\n",
        "    # ===== 5) negatives persistentes (para dataset_auto) =====\n",
        "    neg_existing = len(_list_images(NEG_STORE_DIR))\n",
        "    # opção: copiar de pasta externa, se fornecida\n",
        "    if negatives_src_dir is not None and Path(negatives_src_dir).is_dir():\n",
        "        added = _copy_all_images(Path(negatives_src_dir), NEG_STORE_DIR)\n",
        "        neg_existing += added\n",
        "        print(f\"✔ Negativos importados de '{negatives_src_dir}': +{added} (total={neg_existing})\")\n",
        "\n",
        "    if neg_existing < neg_target_min:\n",
        "        falta = neg_target_min - neg_existing\n",
        "        batch = max(capture_batch, falta)\n",
        "        print(f\"ℹ Negativos existentes: {neg_existing}. Capturando {batch} para atingir >= {neg_target_min} …\")\n",
        "        _capture_negatives_persistent(NEG_STORE_DIR, frames=batch, sleep=capture_sleep_sec)\n",
        "\n",
        "    # copiar negativos persistentes → dataset_auto\n",
        "    nneg = _copy_all_images(NEG_STORE_DIR, NEG_DIR_AUTO)\n",
        "    print(f\"✔ Negatives adicionados ao dataset_auto: {nneg}\")\n",
        "\n",
        "    # ===== 6) avaliação (dataset_auto) =====\n",
        "    try:\n",
        "        metrics = _evaluate_current_detector(DATASET_AUTO, max_images=eval_max_images, conf_threshold=conf_threshold)\n",
        "        return metrics\n",
        "    except Exception as e:\n",
        "        print(\"✘ Falha na avaliação offline:\", e)\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "250ccea5",
      "metadata": {
        "id": "250ccea5"
      },
      "source": [
        "## 14) Pipelines compactos (1:1 e 1:N)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "51b5a590",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "51b5a590",
        "outputId": "def72995-b51d-4418-d459-43887c9b80c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selecione o detector de faces a ser usado na célula 5 (detect_faces).\n",
            "Opções: 'haar' (CascadeClassifier) ou 'dnn_ssd_resnet10' (OpenCV DNN SSD ResNet10)\n",
            "Detector [dnn_ssd_resnet10/haar]: dnn\n",
            "[Runner] Detector selecionado: dnn_ssd_resnet10\n",
            "[Aviso DNN] Arquivos do DNN não encontrados.\n",
            "  Prototxt: models/deploy.prototxt\n",
            "  Pesos   : models/res10_300x300_ssd_iter_140000_fp16.caffemodel\n",
            "  → Ajuste DNN_PROTO_PATH / DNN_WEIGHTS_PATH ou coloque os arquivos em 'models/'.\n",
            "Deseja incluir um novo usuário no modelo ou apenas autenticar um já existente?\n",
            "Digite 'novo' para incluir, ou 'auth' para apenas autenticar.\n",
            "Modo [novo/auth]: novo\n",
            "Digite o identificador do novo usuário (ou deixe em branco para gerar automático): \n",
            "[auto] Nome atribuído: novo_usuario_preview_3\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coletando 30 amostras para 'novo_usuario_preview_3'… Olhe para a câmera.\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baixando deploy.prototxt …\n",
            "Baixando res10_300x300_ssd_iter_140000.caffemodel …\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Enrollment concluído: 30/30 amostras salvas.\n",
            "↻ Treinando LBPH (memória)…\n",
            "Modelo LBPH treinado em memória. Usuários: ['novo_usuario_preview_1', 'novo_usuario_preview_2', 'novo_usuario_preview_3']\n",
            "📏 Calibrando limiar (coletando 15 distâncias)…\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/15] dist=57.3\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2/15] dist=56.7\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3/15] dist=58.4\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4/15] dist=59.0\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5/15] dist=65.7\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[6/15] dist=62.8\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[7/15] dist=61.7\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[8/15] dist=63.3\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[9/15] dist=59.9\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[10/15] dist=65.2\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[11/15] dist=59.6\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[12/15] dist=59.3\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[13/15] dist=62.8\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[14/15] dist=64.2\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15/15] dist=62.3\n",
            "🎯 Novo SERVICE_THRESHOLD = 70.3 (p95=65.3 + margem)\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Liveness] energia média: 8.14 -> live\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        (async () => {\n          let container = document.getElementById('camera-container');\n          if (!container) {\n            container = document.createElement('div');\n            container.id = 'camera-container';\n            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n            document.body.appendChild(container);\n            container.innerHTML = `\n              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n              </div>\n              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n                <small style=\"color:#555\">Frame processado</small>\n              </div>\n              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n            `;\n          } else {\n            const left = document.getElementById('cam-left');\n            if (left) left.style.display = \"flex\";\n          }\n\n          if (!window._colabStream || window._colabStreamInactive) {\n            try {\n              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n              window._colabStreamInactive = false;\n            } catch (e) {\n              console.error('getUserMedia failed', e);\n              return false;\n            }\n          }\n          const video = document.getElementById('webcam');\n          if (video && video.srcObject !== window._colabStream) {\n            video.srcObject = window._colabStream;\n          }\n\n          const canvas = document.getElementById('canvas');\n          window.captureFrame = () => {\n            const ctx = canvas.getContext('2d');\n            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n            canvas.width = vw; canvas.height = vh;\n            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n            return canvas.toDataURL('image/jpeg', 0.9);\n          };\n          window.updateProcessed = (b64) => {\n            const img = document.getElementById('output');\n            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n          };\n          window.stopColabCamera = () => {\n            try {\n              if (window._colabStream && !window._colabStreamInactive) {\n                window._colabStream.getTracks().forEach(t => t.stop());\n                window._colabStreamInactive = true;\n              }\n            } catch (e) { console.warn(e); }\n            const c = document.getElementById('camera-container');\n            if (c) c.remove();\n          };\n          return true;\n        } )();\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔐 1:1 — esperado=novo_usuario_preview_3 | predito=novo_usuario_preview_3 | dist=64.3 | thr=70.3\n"
          ]
        },
        {
          "data": {
            "application/javascript": "if (window.stopColabCamera) window.stopColabCamera();",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'status': 'approved',\n",
              " 'mode': '1v1',\n",
              " 'user': 'novo_usuario_preview_3',\n",
              " 'dist': 64.29688706991057,\n",
              " 'threshold': 70.3}"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# =============================\n",
        "# Runner: inclusão (novo) ou autenticação (auth) com escolha 1:1 / 1:N\n",
        "# + escolha do detector de faces (haar | dnn_ssd_resnet10)\n",
        "# =============================\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Aqui apenas definimos qual detector será usado pelo pipeline já existente.\n",
        "print(\"Selecione o detector de faces a ser usado na célula 5 (detect_faces).\")\n",
        "print(\"Opções: 'haar' (CascadeClassifier) ou 'dnn_ssd_resnet10' (OpenCV DNN SSD ResNet10)\")\n",
        "_detector_choice = input(\"Detector [dnn_ssd_resnet10/haar]: \").strip().lower()\n",
        "if _detector_choice not in (\"\", \"haar\", \"dnn_ssd_resnet10\", \"dnn\", \"ssd\", \"resnet10\"):\n",
        "    print(\"Opção inválida; usando padrão: dnn_ssd_resnet10\")\n",
        "    _detector_choice = \"dnn_ssd_resnet10\"\n",
        "if _detector_choice in (\"\", \"dnn\", \"ssd\", \"resnet10\"):\n",
        "    _detector_choice = \"dnn_ssd_resnet10\"\n",
        "\n",
        "# Propaga para a célula 5: variável global e variável de ambiente (para debug/diagnóstico)\n",
        "try:\n",
        "    DETECTION_MODEL  # verifica se existe a global da célula 5\n",
        "    globals()[\"DETECTION_MODEL\"] = _detector_choice\n",
        "except NameError:\n",
        "    # Se a célula 5 ainda não foi executada, definimos aqui para não quebrar;\n",
        "    # quando a célula 5 for rodada, ela lerá este valor do ambiente.\n",
        "    pass\n",
        "os.environ[\"DETECTION_MODEL\"] = _detector_choice\n",
        "print(f\"[Runner] Detector selecionado: {os.environ['DETECTION_MODEL']}\")\n",
        "\n",
        "# (Opcional) Validação rápida de arquivos quando DNN é escolhido (evita erro tardio)\n",
        "if os.environ[\"DETECTION_MODEL\"] == \"dnn_ssd_resnet10\":\n",
        "    proto = os.environ.get(\"DNN_PROTO_PATH\", \"models/deploy.prototxt\")\n",
        "    weights = os.environ.get(\"DNN_WEIGHTS_PATH\", \"models/res10_300x300_ssd_iter_140000_fp16.caffemodel\")\n",
        "    if not (Path(proto).exists() and Path(weights).exists()):\n",
        "        print(\"[Aviso DNN] Arquivos do DNN não encontrados.\")\n",
        "        print(f\"  Prototxt: {proto}\")\n",
        "        print(f\"  Pesos   : {weights}\")\n",
        "        print(\"  → Ajuste DNN_PROTO_PATH / DNN_WEIGHTS_PATH ou coloque os arquivos em 'models/'.\")\n",
        "\n",
        "N_SAMPLES          = 30                      # amostras para enrollment (30–60 recomendado)\n",
        "FRAME_DELAY_MS     = 100                     # intervalo entre capturas (ms)\n",
        "LBPH_NEIGHBORS     = 16                      # 8 ou 16 costumam ir bem\n",
        "DO_LIVENESS_TEST   = True                    # liveness antes da autenticação\n",
        "\n",
        "# Pergunta inicial\n",
        "print(\"Deseja incluir um novo usuário no modelo ou apenas autenticar um já existente?\")\n",
        "print(\"Digite 'novo' para incluir, ou 'auth' para apenas autenticar.\")\n",
        "modo = input(\"Modo [novo/auth]: \").strip().lower()\n",
        "\n",
        "# Definições padrão\n",
        "NEW_USER_ID = None\n",
        "EXPECTED_USER_1V1 = None\n",
        "AUTH_MODE_1V1 = True  # default (será perguntado quando for 'auth')\n",
        "\n",
        "if modo == \"novo\":\n",
        "    typed_name = input(\"Digite o identificador do novo usuário (ou deixe em branco para gerar automático): \").strip()\n",
        "    if not typed_name:\n",
        "        # Gera nome automático com o próximo índice baseado nas pastas já existentes\n",
        "        try:\n",
        "            existing_dirs = sorted([d.name for d in ENROLL_DIR.iterdir() if d.is_dir()])\n",
        "        except Exception:\n",
        "            existing_dirs = []\n",
        "        idx = len(existing_dirs)\n",
        "        typed_name = f\"novo_usuario_preview_{idx+1}\"\n",
        "        print(f\"[auto] Nome atribuído: {typed_name}\")\n",
        "    NEW_USER_ID = typed_name\n",
        "    EXPECTED_USER_1V1 = NEW_USER_ID  # após incluir, autentica 1:1 (mesma pessoa)\n",
        "\n",
        "elif modo == \"auth\":\n",
        "    # Escolha do tipo de autenticação\n",
        "    print(\"Qual tipo de autenticação deseja usar?\")\n",
        "    print(\"Digite '1' para 1:1 (comparar com um usuário específico) ou 'N' para 1:N (identificar entre os cadastrados).\")\n",
        "    auth_choice = input(\"Tipo [1/N]: \").strip().lower()\n",
        "    if auth_choice == \"1\":\n",
        "        AUTH_MODE_1V1 = True\n",
        "        EXPECTED_USER_1V1 = input(\"Digite o identificador do usuário a ser autenticado (1:1): \").strip()\n",
        "        if not EXPECTED_USER_1V1:\n",
        "            raise ValueError(\"Para autenticação 1:1 é necessário informar o identificador esperado.\")\n",
        "    else:\n",
        "        AUTH_MODE_1V1 = False\n",
        "        EXPECTED_USER_1V1 = None  # 1:N não requer nome\n",
        "else:\n",
        "    raise ValueError(\"Opção inválida. Use 'novo' ou 'auth'.\")\n",
        "\n",
        "display_result = {\"status\":\"error\", \"reason\":\"not_executed\"}\n",
        "try:\n",
        "    if modo == \"novo\":\n",
        "        # 1) enrollment do novo usuário\n",
        "        enroll_user_with_preview(user_id=NEW_USER_ID, n_samples=N_SAMPLES, interval_ms=FRAME_DELAY_MS)\n",
        "        # 2) re-treino do modelo em memória\n",
        "        _ = get_recognizer(neighbors=LBPH_NEIGHBORS, force_retrain=True)\n",
        "        # 3) calibração de threshold\n",
        "        calibrate_threshold(samples=15, neighbors=LBPH_NEIGHBORS)\n",
        "    else:\n",
        "        # Apenas autenticação: garante que o modelo está carregado (re-treina se necessário)\n",
        "        try:\n",
        "            _ = get_recognizer(neighbors=LBPH_NEIGHBORS, force_retrain=False)\n",
        "        except Exception:\n",
        "            _ = get_recognizer(neighbors=LBPH_NEIGHBORS, force_retrain=True)\n",
        "\n",
        "    # 4) autenticação (sempre roda)\n",
        "    if AUTH_MODE_1V1:\n",
        "        display_result = authenticate_1v1_preview(expected_user=EXPECTED_USER_1V1,\n",
        "                                                  neighbors=LBPH_NEIGHBORS,\n",
        "                                                  require_liveness=DO_LIVENESS_TEST)\n",
        "    else:\n",
        "        display_result = authenticate_1vN_preview(neighbors=LBPH_NEIGHBORS,\n",
        "                                                  require_liveness=DO_LIVENESS_TEST)\n",
        "\n",
        "finally:\n",
        "    # sempre encerra a pré-visualização no Colab / janelas no local\n",
        "    try:\n",
        "        stop_camera_ui()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "display_result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "C9h-DdbkOaqp",
      "metadata": {
        "id": "C9h-DdbkOaqp"
      },
      "source": [
        "## 15) Execução de AVALIAÇÃO offline (após o fluxo de câmera)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "RxMyTuepD2e2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RxMyTuepD2e2",
        "outputId": "da509ba3-b43f-4b37-a917-d3b8cbbca674"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rodar avaliação offline (Automático/Default/Remoto)? [s/N]: s\n",
            "Fonte do dataset:\n",
            "  1) Automático (enrollment + negatives persistentes/câmera)\n",
            "  2) DEFAULT (cv_colab_data/dataset_default)\n",
            "  3) REMOTO/LOCAL existente (URL .zip/.tar/.tar.gz/.tgz ou caminho local)\n",
            "Escolha [1/2/3]: 3\n",
            "Informe URL (.zip/.tar/.tar.gz/.tgz) OU caminho local com positives/ e negatives/ (Enter = usar default https://data.caltech.edu/records/6rjah-hdv18/files/faces.tar): \n",
            "Baixando dataset remoto: https://data.caltech.edu/records/6rjah-hdv18/files/faces.tar\n",
            "✔ Arquivo salvo em: /tmp/tmpsq7_kc9_/dataset_remote.tar\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2285713670.py:239: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "  tf.extractall(str(out_dir))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[debug] Arquivos extraídos: 452 (mostrando até 12)\n",
            "   - cv_colab_data/dataset_remote/image_0079.jpg\n",
            "   - cv_colab_data/dataset_remote/image_0070.jpg\n",
            "   - cv_colab_data/dataset_remote/image_0179.jpg\n",
            "   - cv_colab_data/dataset_remote/image_0295.jpg\n",
            "   - cv_colab_data/dataset_remote/image_0343.jpg\n",
            "   - cv_colab_data/dataset_remote/image_0379.jpg\n",
            "   - cv_colab_data/dataset_remote/image_0375.jpg\n",
            "   - cv_colab_data/dataset_remote/image_0009.jpg\n",
            "   - cv_colab_data/dataset_remote/image_0064.jpg\n",
            "   - cv_colab_data/dataset_remote/image_0319.jpg\n",
            "   - cv_colab_data/dataset_remote/image_0045.jpg\n",
            "   - cv_colab_data/dataset_remote/image_0083.jpg\n",
            "[single-class] Convertendo todas as imagens extraídas em 'positives/' e completando 'negatives/'…\n",
            "[single-class] Positives criados: 450\n",
            "[negatives] Nenhum negative encontrado. Baixando Caltech-101…\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2285713670.py:109: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "  tf.extractall(str(out_dir)); return True\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[negatives] Encontrado BACKGROUND_Google — usando como negativos.\n",
            "[negatives] Copiados 467 negatives → cv_colab_data/dataset_remote/negatives\n",
            "✔ dataset 'single-class' preparado em: cv_colab_data/dataset_remote\n",
            "Usar câmera para completar negativos (também em Remoto/Default)? [S/n]: s\n",
            "Pasta extra com negativos (vazio = nenhuma): \n",
            "Limitar nº de imagens por classe? (vazio = sem limite): \n",
            "Conf threshold (vazio = 0.5): \n",
            "ℹ Usando dataset override: cv_colab_data/dataset_remote\n",
            "\n",
            "=== Relatório (2 classes) ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     no_face       1.00      0.80      0.89       467\n",
            "        face       0.83      1.00      0.91       450\n",
            "\n",
            "    accuracy                           0.90       917\n",
            "   macro avg       0.91      0.90      0.90       917\n",
            "weighted avg       0.92      0.90      0.90       917\n",
            "\n",
            "\n",
            "=== Resultados: dnn_ssd_resnet10 ===\n",
            "Accuracy : 0.8975\n",
            "Precision: 0.8272058823529411\n",
            "Recall   : 1.0\n",
            "F1-score : 0.9054325955734407\n",
            "Tempo médio por imagem: 0.0572 s\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"        )\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"modelo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"dnn_ssd_resnet10\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8974918211559433,\n        \"max\": 0.8974918211559433,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8974918211559433\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8272058823529411,\n        \"max\": 0.8272058823529411,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8272058823529411\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9054325955734407,\n        \"max\": 0.9054325955734407,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9054325955734407\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.05718926935877509,\n        \"max\": 0.05718926935877509,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.05718926935877509\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 917,\n        \"max\": 917,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          917\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"classes_presentes\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-f389c3d7-0075-44c4-829c-c1b439ddd6f4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>modelo</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "      <th>avg_time</th>\n",
              "      <th>n</th>\n",
              "      <th>classes_presentes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dnn_ssd_resnet10</td>\n",
              "      <td>0.897492</td>\n",
              "      <td>0.827206</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.905433</td>\n",
              "      <td>0.057189</td>\n",
              "      <td>917</td>\n",
              "      <td>[no_face, face]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f389c3d7-0075-44c4-829c-c1b439ddd6f4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f389c3d7-0075-44c4-829c-c1b439ddd6f4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f389c3d7-0075-44c4-829c-c1b439ddd6f4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "             modelo  accuracy  precision  recall        f1  avg_time    n  \\\n",
              "0  dnn_ssd_resnet10  0.897492   0.827206     1.0  0.905433  0.057189  917   \n",
              "\n",
              "  classes_presentes  \n",
              "0   [no_face, face]  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# =============================\n",
        "# Execução de AVALIAÇÃO offline (após o fluxo de câmera)\n",
        "# - Fonte: Automático | Default | Remoto/Local\n",
        "# - Remoto default (positivos): Caltech Face 1999 (faces.tar)\n",
        "# - Fallback de negativos: Caltech-101 (extrai camadas internas; usa BACKGROUND_Google ou outras classes não-face)\n",
        "# - Captura por câmera também em Remoto/Default quando negatives/ estiver vazio\n",
        "# =============================\n",
        "from pathlib import Path\n",
        "import os, re, shutil, tarfile, zipfile, urllib.request, tempfile, glob\n",
        "\n",
        "# ---------- diretórios base ----------\n",
        "try:\n",
        "    DATA_DIR\n",
        "except NameError:\n",
        "    DATA_DIR = Path(\"cv_colab_data\")\n",
        "    DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "DEFAULT_DATASET_DIR = DATA_DIR / \"dataset_default\"\n",
        "(DEFAULT_DATASET_DIR / \"positives\").mkdir(parents=True, exist_ok=True)\n",
        "(DEFAULT_DATASET_DIR / \"negatives\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ---------- URLs defaults ----------\n",
        "# Positivos (rostos) — Caltech Face 1999 (CaltechDATA)\n",
        "REMOTE_DATASET_URL_DEFAULT = \"https://data.caltech.edu/records/6rjah-hdv18/files/faces.tar\"\n",
        "# Negativos fallback — Caltech-101 (CaltechDATA, zip que contém .tar.gz internamente)\n",
        "CALTECH101_URL = \"https://data.caltech.edu/records/mzrjq-6wc02/files/caltech-101.zip\"\n",
        "\n",
        "# ---------- helpers utilitários ----------\n",
        "def _debug_list_some_files(root: Path, n=12):\n",
        "    files = [p for p in root.rglob(\"*\") if p.is_file()]\n",
        "    print(f\"[debug] Arquivos extraídos: {len(files)} (mostrando até {n})\")\n",
        "    for p in files[:n]:\n",
        "        print(\"   -\", p.as_posix())\n",
        "\n",
        "def _find_dataset_root_with_pos_neg(root: Path) -> Path | None:\n",
        "    \"\"\"Procura um diretório que contenha positives/ e negatives/.\"\"\"\n",
        "    if (root / \"positives\").is_dir() and (root / \"negatives\").is_dir():\n",
        "        return root\n",
        "    for p in root.rglob(\"*\"):\n",
        "        if p.is_dir() and (p / \"positives\").is_dir() and (p / \"negatives\").is_dir():\n",
        "            return p\n",
        "    return None\n",
        "\n",
        "def _collect_images(root: Path):\n",
        "    return [Path(x) for x in glob.glob(str(root / \"**\" / \"*\"), recursive=True)\n",
        "            if os.path.isfile(x) and Path(x).suffix.lower() in (\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\",\".pgm\")]\n",
        "\n",
        "def _reorganize_faces_nonfaces(src_root: Path) -> Path | None:\n",
        "    \"\"\"\n",
        "    Heurística para separar positivos/negativos:\n",
        "      - negativos: 'nonface', 'non-face', 'non_face', 'non', 'neg', 'background', 'bg'\n",
        "      - positivos: contém 'face' e NÃO contém termos de negativo (evita 'interface')\n",
        "    \"\"\"\n",
        "    neg_patterns = (r\"non[\\-_ ]?face\", r\"\\bnon\\b\", r\"\\bneg(ative)?s?\\b\", r\"background\", r\"\\bbg\\b\")\n",
        "    def is_neg(path_str: str):\n",
        "        low = path_str.lower()\n",
        "        return any(re.search(p, low) for p in neg_patterns)\n",
        "\n",
        "    pos_dir = src_root / \"positives\"; pos_dir.mkdir(exist_ok=True)\n",
        "    neg_dir = src_root / \"negatives\"; neg_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    copied_pos = copied_neg = 0\n",
        "    for f in _collect_images(src_root):\n",
        "        s = f.as_posix().lower()\n",
        "        if is_neg(s):\n",
        "            dst = neg_dir / f.name\n",
        "            try: shutil.copy2(f, dst); copied_neg += 1\n",
        "            except: pass\n",
        "        elif (\"face\" in s) and not is_neg(s) and (\"interface\" not in s):\n",
        "            dst = pos_dir / f.name\n",
        "            try: shutil.copy2(f, dst); copied_pos += 1\n",
        "            except: pass\n",
        "\n",
        "    if copied_pos + copied_neg == 0:\n",
        "        return None\n",
        "    print(f\"[reorganize] positives={copied_pos}, negatives={copied_neg}\")\n",
        "    return src_root\n",
        "\n",
        "# ---------- negativos: Caltech-101 com extração recursiva ----------\n",
        "def _ensure_negatives_from_caltech101(neg_dir: Path, max_to_copy: int | None = None):\n",
        "    \"\"\"\n",
        "    Se 'neg_dir' estiver vazio, baixa Caltech-101 (CaltechDATA, .zip) e preenche negativos:\n",
        "      1) Extrai recursivamente camadas internas (.zip/.tar/.tgz/.tar.gz).\n",
        "      2) Preferência: pasta BACKGROUND_Google.\n",
        "      3) Se não houver, usa outras categorias != 'face' como negativos.\n",
        "    \"\"\"\n",
        "    if any(neg_dir.iterdir()):\n",
        "        return\n",
        "\n",
        "    print(\"[negatives] Nenhum negative encontrado. Baixando Caltech-101…\")\n",
        "    import zipfile, tarfile\n",
        "    tmp = Path(tempfile.mkdtemp())\n",
        "    try:\n",
        "        # download\n",
        "        guessed_suffix = \"\".join(Path(CALTECH101_URL.split(\"?\")[0]).suffixes) or \".zip\"\n",
        "        arc = tmp / (\"caltech101\" + guessed_suffix)\n",
        "        urllib.request.urlretrieve(CALTECH101_URL, str(arc))\n",
        "\n",
        "        extract_root = tmp / \"caltech101_extracted\"\n",
        "        extract_root.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        def _extract_once(archive_path: Path, out_dir: Path):\n",
        "            low = archive_path.name.lower()\n",
        "            if low.endswith(\".zip\"):\n",
        "                with zipfile.ZipFile(str(archive_path), \"r\") as zf:\n",
        "                    zf.extractall(str(out_dir)); return True\n",
        "            if low.endswith((\".tar.gz\", \".tgz\", \".tar\")):\n",
        "                with tarfile.open(str(archive_path), \"r:*\") as tf:\n",
        "                    tf.extractall(str(out_dir)); return True\n",
        "            return False\n",
        "\n",
        "        # primeira camada\n",
        "        if not _extract_once(arc, extract_root):\n",
        "            print(\"[negatives] Formato não reconhecido no primeiro nível, abortando fallback.\")\n",
        "            return\n",
        "\n",
        "        # extrai camadas internas até 2 níveis\n",
        "        def _extract_nested_archives(root: Path, max_depth: int = 2):\n",
        "            for _ in range(max_depth):\n",
        "                inner = [p for p in root.rglob(\"*\") if p.is_file() and (\n",
        "                    p.name.lower().endswith(\".zip\") or\n",
        "                    p.name.lower().endswith(\".tar\") or\n",
        "                    p.name.lower().endswith(\".tar.gz\") or\n",
        "                    p.name.lower().endswith(\".tgz\") or\n",
        "                    p.name.lower().endswith(\".gz\")\n",
        "                )]\n",
        "                any_new = False\n",
        "                for a in inner:\n",
        "                    base = a.name\n",
        "                    for suf in (\".tar.gz\", \".tgz\", \".zip\", \".tar\", \".gz\"):\n",
        "                        if base.endswith(suf):\n",
        "                            base = base[: -len(suf)]\n",
        "                    out = a.parent / (base + \"_extracted\")\n",
        "                    out.mkdir(exist_ok=True)\n",
        "                    try:\n",
        "                        if _extract_once(a, out):\n",
        "                            any_new = True\n",
        "                    except Exception:\n",
        "                        pass\n",
        "                if not any_new:\n",
        "                    break\n",
        "\n",
        "        _extract_nested_archives(extract_root, max_depth=2)\n",
        "\n",
        "        # localizar BACKGROUND_Google\n",
        "        bg = None\n",
        "        for p in extract_root.rglob(\"*\"):\n",
        "            if p.is_dir() and p.name.lower() == \"background_google\":\n",
        "                bg = p; break\n",
        "\n",
        "        exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"}\n",
        "        copied = 0\n",
        "        def _copy_all_images(src_dir: Path):\n",
        "            nonlocal copied\n",
        "            for f in src_dir.rglob(\"*\"):\n",
        "                if f.is_file() and f.suffix.lower() in exts:\n",
        "                    if max_to_copy is not None and copied >= max_to_copy:\n",
        "                        return\n",
        "                    dst = neg_dir / f.name\n",
        "                    try: shutil.copy2(f, dst); copied += 1\n",
        "                    except: pass\n",
        "\n",
        "        if bg is not None:\n",
        "            print(\"[negatives] Encontrado BACKGROUND_Google — usando como negativos.\")\n",
        "            _copy_all_images(bg)\n",
        "        else:\n",
        "            print(\"[negatives] BACKGROUND_Google não encontrado. Usando outras categorias como negativos.\")\n",
        "            # escolher diretório com mais subpastas (normalmente '101_ObjectCategories')\n",
        "            candidate_roots = [p for p in extract_root.rglob(\"*\") if p.is_dir()]\n",
        "            root = max(candidate_roots, key=lambda d: sum(1 for _ in d.iterdir() if _.is_dir()), default=extract_root)\n",
        "            for cat in root.iterdir():\n",
        "                if not cat.is_dir(): continue\n",
        "                name = cat.name.lower()\n",
        "                if \"face\" in name:  # não usar categorias de rosto como negativos\n",
        "                    continue\n",
        "                _copy_all_images(cat)\n",
        "                if max_to_copy is not None and copied >= max_to_copy:\n",
        "                    break\n",
        "\n",
        "        print(f\"[negatives] Copiados {copied} negatives → {neg_dir}\")\n",
        "        if copied == 0:\n",
        "            print(\"[negatives] Aviso: não foi possível obter imagens negativas do Caltech-101 (verifique o pacote).\")\n",
        "\n",
        "    finally:\n",
        "        try: shutil.rmtree(tmp)\n",
        "        except: pass\n",
        "\n",
        "# ---------- negativos via câmera (agora também em Remoto/Default) ----------\n",
        "def _ensure_negatives_via_camera(neg_dir: Path, frames: int = 40, sleep_sec: float = 0.15):\n",
        "    import time, cv2\n",
        "    neg_dir.mkdir(parents=True, exist_ok=True)\n",
        "    cap = cv2.VideoCapture(0)\n",
        "    if not cap.isOpened():\n",
        "        print(\"✘ Câmera indisponível para capturar negativos.\")\n",
        "        return 0\n",
        "    print(f\"🎥 Capturando {frames} negativos… (aponte para parede/fundo vazio)\")\n",
        "    saved = 0\n",
        "    for i in range(frames):\n",
        "        ok, frame = cap.read()\n",
        "        if not ok: break\n",
        "        cv2.imwrite(str(neg_dir / f\"neg_cam_{int(time.time())}_{i:03d}.jpg\"), frame)\n",
        "        time.sleep(sleep_sec); saved += 1\n",
        "    cap.release()\n",
        "    print(f\"✔ Negativos capturados: {saved}\")\n",
        "    return saved\n",
        "\n",
        "# ---------- download/extração do dataset remoto (faces.tar, etc.) ----------\n",
        "def _download_and_unpack_archive(url: str, dest_root: Path, *, fallback_to_default=True) -> Path:\n",
        "    \"\"\"\n",
        "    Baixa .zip/.tar/.tar.gz/.tgz para dest_root/dataset_remote e tenta:\n",
        "      1) Encontrar positives/ e negatives/;\n",
        "      2) Reorganizar por heurística (face vs non/background);\n",
        "      3) Completar negatives com Caltech-101, se necessário;\n",
        "      4) Fallback POSITIVOS default (Caltech Face 1999);\n",
        "      5) Último recurso: 'single-class' (todas imagens -> positives) + completar negatives.\n",
        "    Retorna a pasta final contendo positives/ e negatives/.\n",
        "    \"\"\"\n",
        "    dest_root.mkdir(parents=True, exist_ok=True)\n",
        "    tmp_dir = Path(tempfile.mkdtemp())\n",
        "    try:\n",
        "        suffixes = \"\".join(Path(url.split(\"?\")[0]).suffixes) or \".bin\"\n",
        "        archive_path = tmp_dir / f\"dataset_remote{suffixes}\"\n",
        "        print(f\"Baixando dataset remoto: {url}\")\n",
        "        urllib.request.urlretrieve(url, str(archive_path))\n",
        "        print(f\"✔ Arquivo salvo em: {archive_path}\")\n",
        "\n",
        "        out_dir = dest_root / \"dataset_remote\"\n",
        "        if out_dir.exists(): shutil.rmtree(out_dir)\n",
        "        out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # extrair primeira camada\n",
        "        lower = archive_path.name.lower()\n",
        "        try:\n",
        "            if lower.endswith(\".zip\"):\n",
        "                with zipfile.ZipFile(str(archive_path), \"r\") as zf:\n",
        "                    zf.extractall(str(out_dir))\n",
        "            elif lower.endswith((\".tar.gz\", \".tgz\", \".tar\")):\n",
        "                with tarfile.open(str(archive_path), \"r:*\") as tf:\n",
        "                    tf.extractall(str(out_dir))\n",
        "            else:\n",
        "                try:\n",
        "                    with zipfile.ZipFile(str(archive_path), \"r\") as zf:\n",
        "                        zf.extractall(str(out_dir))\n",
        "                except zipfile.BadZipFile:\n",
        "                    with tarfile.open(str(archive_path), \"r:*\") as tf:\n",
        "                        tf.extractall(str(out_dir))\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Falha ao extrair: {e}\")\n",
        "\n",
        "        # extrair camadas internas até 2 níveis (se houver)\n",
        "        def _extract_nested_archives(root: Path, max_depth: int = 2):\n",
        "            for _ in range(max_depth):\n",
        "                inner = [p for p in root.rglob(\"*\") if p.is_file() and (\n",
        "                    p.name.lower().endswith(\".zip\") or\n",
        "                    p.name.lower().endswith(\".tar\") or\n",
        "                    p.name.lower().endswith(\".tar.gz\") or\n",
        "                    p.name.lower().endswith(\".tgz\") or\n",
        "                    p.name.lower().endswith(\".gz\")\n",
        "                )]\n",
        "                any_new = False\n",
        "                for a in inner:\n",
        "                    base = a.name\n",
        "                    for suf in (\".tar.gz\", \".tgz\", \".zip\", \".tar\", \".gz\"):\n",
        "                        if base.endswith(suf):\n",
        "                            base = base[: -len(suf)]\n",
        "                    out = a.parent / (base + \"_extracted\")\n",
        "                    out.mkdir(exist_ok=True)\n",
        "                    try:\n",
        "                        if a.name.lower().endswith(\".zip\"):\n",
        "                            with zipfile.ZipFile(str(a), \"r\") as zf: zf.extractall(str(out))\n",
        "                            any_new = True\n",
        "                        else:\n",
        "                            with tarfile.open(str(a), \"r:*\") as tf: tf.extractall(str(out))\n",
        "                            any_new = True\n",
        "                    except Exception:\n",
        "                        pass\n",
        "                if not any_new:\n",
        "                    break\n",
        "\n",
        "        _extract_nested_archives(out_dir, max_depth=2)\n",
        "        _debug_list_some_files(out_dir)\n",
        "\n",
        "        # já existe positives/negatives?\n",
        "        ds = _find_dataset_root_with_pos_neg(out_dir)\n",
        "        if ds:\n",
        "            print(f\"✔ dataset com positives/negatives encontrado em: {ds}\")\n",
        "            _ensure_negatives_from_caltech101(ds / \"negatives\")\n",
        "            return ds\n",
        "\n",
        "        # tenta reorganizar por heurística\n",
        "        ds = _reorganize_faces_nonfaces(out_dir)\n",
        "        if ds:\n",
        "            _ensure_negatives_from_caltech101(ds / \"negatives\")\n",
        "            if _find_dataset_root_with_pos_neg(ds):\n",
        "                print(f\"✔ dataset reorganizado em: {ds}\")\n",
        "                return ds\n",
        "\n",
        "        # fallback: positivos default\n",
        "        if fallback_to_default and (url != REMOTE_DATASET_URL_DEFAULT):\n",
        "            print(\"[fallback] Estrutura não reconhecida. Baixando POSITIVOS default (Caltech Face 1999)…\")\n",
        "            return _download_and_unpack_archive(REMOTE_DATASET_URL_DEFAULT, dest_root, fallback_to_default=False)\n",
        "\n",
        "        # último recurso: single-class (tudo -> positives) + completar negatives\n",
        "        print(\"[single-class] Convertendo todas as imagens extraídas em 'positives/' e completando 'negatives/'…\")\n",
        "        pos_dir = out_dir / \"positives\"\n",
        "        neg_dir = out_dir / \"negatives\"\n",
        "        pos_dir.mkdir(exist_ok=True); neg_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        imgs = _collect_images(out_dir)\n",
        "        copied = 0\n",
        "        for f in imgs:\n",
        "            # evitar arquivos já nas pastas alvo\n",
        "            try:\n",
        "                if f.is_relative_to(pos_dir) or f.is_relative_to(neg_dir):\n",
        "                    continue\n",
        "            except AttributeError:\n",
        "                # Python < 3.9: fallback\n",
        "                if str(pos_dir) in str(f.parent) or str(neg_dir) in str(f.parent):\n",
        "                    continue\n",
        "            try:\n",
        "                shutil.copy2(f, pos_dir / f.name); copied += 1\n",
        "            except: pass\n",
        "        print(f\"[single-class] Positives criados: {copied}\")\n",
        "\n",
        "        _ensure_negatives_from_caltech101(neg_dir)\n",
        "\n",
        "        if _find_dataset_root_with_pos_neg(out_dir):\n",
        "            print(f\"✔ dataset 'single-class' preparado em: {out_dir}\")\n",
        "            return out_dir\n",
        "\n",
        "        raise ValueError(\"Não foi possível montar positives/ e negatives/ automaticamente.\")\n",
        "    finally:\n",
        "        try: shutil.rmtree(tmp_dir)\n",
        "        except: pass\n",
        "\n",
        "# compat com versões antigas do código\n",
        "_download_and_unpack_zip = _download_and_unpack_archive\n",
        "\n",
        "# ---------- fluxo interativo ----------\n",
        "try:\n",
        "    run_eval_auto = input(\n",
        "        \"Rodar avaliação offline (Automático/Default/Remoto)? [s/N]: \"\n",
        "    ).strip().lower() in (\"s\",\"sim\",\"y\",\"yes\")\n",
        "except Exception:\n",
        "    run_eval_auto = False\n",
        "\n",
        "if run_eval_auto:\n",
        "    print(\"Fonte do dataset:\")\n",
        "    print(\"  1) Automático (enrollment + negatives persistentes/câmera)\")\n",
        "    print(f\"  2) DEFAULT ({DEFAULT_DATASET_DIR})\")\n",
        "    print(\"  3) REMOTO/LOCAL existente (URL .zip/.tar/.tar.gz/.tgz ou caminho local)\")\n",
        "    choice = (input(\"Escolha [1/2/3]: \").strip() or \"1\")\n",
        "\n",
        "    dataset_override = None\n",
        "    default_dir = None\n",
        "\n",
        "    if choice == \"2\":\n",
        "        default_dir = DEFAULT_DATASET_DIR\n",
        "        print(f\"ℹ Usando dataset DEFAULT: {default_dir}\")\n",
        "\n",
        "    elif choice == \"3\":\n",
        "        ds_input = input(\n",
        "            \"Informe URL (.zip/.tar/.tar.gz/.tgz) OU caminho local com positives/ e negatives/ \"\n",
        "            f\"(Enter = usar default {REMOTE_DATASET_URL_DEFAULT}): \"\n",
        "        ).strip()\n",
        "        if not ds_input:\n",
        "            ds_input = REMOTE_DATASET_URL_DEFAULT\n",
        "\n",
        "        if ds_input.startswith((\"http://\",\"https://\")):\n",
        "            dataset_override = _download_and_unpack_archive(ds_input, DATA_DIR)\n",
        "        else:\n",
        "            p = Path(ds_input)\n",
        "            if not p.exists():\n",
        "                raise ValueError(f\"Caminho não existe: {p}\")\n",
        "            if not ((p / \"positives\").is_dir() and (p / \"negatives\").is_dir()):\n",
        "                raise ValueError(f\"Caminho inválido (esperado positives/ e negatives/): {p}\")\n",
        "            dataset_override = p\n",
        "\n",
        "    # Perguntas opcionais (as mesmas que você já tinha)\n",
        "    try:\n",
        "        use_camera = input(\"Usar câmera para completar negativos (também em Remoto/Default)? [S/n]: \").strip().lower()\n",
        "        use_camera = not (use_camera in (\"n\",\"nao\",\"não\"))\n",
        "    except Exception:\n",
        "        use_camera = True\n",
        "\n",
        "    try:\n",
        "        neg_src = input(\"Pasta extra com negativos (vazio = nenhuma): \").strip() or None\n",
        "    except Exception:\n",
        "        neg_src = None\n",
        "\n",
        "    try:\n",
        "        max_imgs = input(\"Limitar nº de imagens por classe? (vazio = sem limite): \").strip()\n",
        "        max_imgs = int(max_imgs) if max_imgs else None\n",
        "    except Exception:\n",
        "        max_imgs = None\n",
        "\n",
        "    try:\n",
        "        th = input(\"Conf threshold (vazio = 0.5): \").strip()\n",
        "        th = float(th) if th else 0.5\n",
        "    except Exception:\n",
        "        th = 0.5\n",
        "\n",
        "    # ---------- chamadas finais ----------\n",
        "    if dataset_override is not None:\n",
        "        # REMOTO/LOCAL (pronto/baixado)\n",
        "        # se negatives/ estiver vazio e o usuário permitir, completa com câmera\n",
        "        neg_dir_check = dataset_override / \"negatives\"\n",
        "        if use_camera and (not any(neg_dir_check.iterdir())):\n",
        "            _ensure_negatives_via_camera(neg_dir_check, frames=40, sleep_sec=0.15)\n",
        "\n",
        "        _ = run_offline_eval_from_enrollment(\n",
        "            eval_max_images=max_imgs,\n",
        "            conf_threshold=th,\n",
        "            use_camera=False,                 # já tratamos câmera acima\n",
        "            negatives_src_dir=None,\n",
        "            dataset_dir_override=dataset_override,\n",
        "            default_dataset_dir=None,\n",
        "        )\n",
        "\n",
        "    elif default_dir is not None:\n",
        "        # DEFAULT\n",
        "        neg_dir_check = default_dir / \"negatives\"\n",
        "        if use_camera and (not any(neg_dir_check.iterdir())):\n",
        "            _ensure_negatives_via_camera(neg_dir_check, frames=40, sleep_sec=0.15)\n",
        "\n",
        "        _ = run_offline_eval_from_enrollment(\n",
        "            eval_max_images=max_imgs,\n",
        "            conf_threshold=th,\n",
        "            use_camera=False,                 # já tratamos câmera acima\n",
        "            negatives_src_dir=None,\n",
        "            dataset_dir_override=None,\n",
        "            default_dataset_dir=default_dir,\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        # AUTOMÁTICO (enrollment + negativos persistentes/câmera/pasta extra)\n",
        "        _ = run_offline_eval_from_enrollment(\n",
        "            neg_target_min=30,\n",
        "            capture_batch=30,\n",
        "            capture_sleep_sec=0.15,\n",
        "            eval_max_images=max_imgs,\n",
        "            conf_threshold=th,\n",
        "            use_camera=use_camera,            # aqui a câmera ainda vale dentro da função\n",
        "            negatives_src_dir=neg_src,\n",
        "            dataset_dir_override=None,\n",
        "            default_dataset_dir=None,\n",
        "        )\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
