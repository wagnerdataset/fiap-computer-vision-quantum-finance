{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4c4ae182",
      "metadata": {
        "id": "4c4ae182"
      },
      "source": [
        "\n",
        "# Verificação Facial — Colab/Local (Webcam + Preview)  \n",
        "**Detecção (Haar), Pré-processamento, LBPH em memória, Liveness passivo, Calibração, Autenticação 1:1 e 1:N**\n",
        "\n",
        "Este notebook inclui:\n",
        "- Instalação compatível (NumPy 1.26.4 + OpenCV 4.8.1.78).\n",
        "- **Webcam persistente + Preview - Verificação Facial Dual (Colab ↔ Local) - Detecta ambiente (IN_COLAB = True/False)**\n",
        "- Preview ao vivo do **vídeo bruto** (opcional) e do **frame processado**.\n",
        "- Detecção de face (Haar), **pré-processamento (CLAHE + blur)**.\n",
        "- **Treino LBPH em memória** (sem `read()`/`write()` do modelo para evitar corrupção).\n",
        "- **Calibração automática** que atualiza `SERVICE_THRESHOLD`.\n",
        "- **Liveness passivo** por energia de movimento com preview.\n",
        "- **Autenticação 1:1** e **1:N** com flows dedicados.\n",
        "- **Evidências** opcionais (frames de falhas) em `cv_colab_data/evidence/`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c0088b9",
      "metadata": {
        "id": "5c0088b9"
      },
      "source": [
        "## 1) Instalação (reinicie o runtime após rodar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d0a9722c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0a9722c",
        "outputId": "258b2be3-a90d-49a2-82b6-fcfaae2dfb4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python==4.8.1.78 in /usr/local/lib/python3.12/dist-packages (4.8.1.78)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "OpenCV: 4.8.1\n",
            "NumPy: 1.26.4\n",
            "cv2.face OK\n"
          ]
        }
      ],
      "source": [
        "# Recomendado: após executar, vá em Runtime > Restart runtime\n",
        "#!pip uninstall -y opencv-python opencv-contrib-python numpy\n",
        "!pip install --no-cache-dir numpy==1.26.4 opencv-contrib-python==4.8.1.78 matplotlib\n",
        "\n",
        "import cv2, numpy as np\n",
        "print(\"OpenCV:\", cv2.__version__)\n",
        "print(\"NumPy:\", np.__version__)\n",
        "try:\n",
        "    _ = cv2.face.LBPHFaceRecognizer_create()\n",
        "    print(\"cv2.face OK\")\n",
        "except Exception as e:\n",
        "    print(\"Falha cv2.face:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c0cfa7d",
      "metadata": {
        "id": "0c0cfa7d"
      },
      "source": [
        "## 2) Imports, diretórios e parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "207dadc2",
      "metadata": {
        "id": "207dadc2"
      },
      "outputs": [],
      "source": [
        "import base64, json, time, uuid, math\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Javascript, display\n",
        "\n",
        "# Estrutura de pastas\n",
        "DATA_DIR = Path(\"cv_colab_data\")\n",
        "ENROLL_DIR = DATA_DIR/\"enroll\"\n",
        "EVIDENCE_DIR = DATA_DIR/\"evidence\"\n",
        "for d in (DATA_DIR, ENROLL_DIR, EVIDENCE_DIR):\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Parâmetros globais (ajuste conforme sua calibração/ambiente)\n",
        "SERVICE_THRESHOLD = 55.0       # será ajustado automaticamente na calibração\n",
        "LIVENESS_MIN_ENERGY = 8.0      # energia mínima média para ser \"live\"\n",
        "\n",
        "def show_bgr(img, title=\"preview\"):\n",
        "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    plt.figure(figsize=(5,4))\n",
        "    plt.imshow(rgb)\n",
        "    plt.title(title)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1196b8d6",
      "metadata": {
        "id": "1196b8d6"
      },
      "source": [
        "## 3) Pré-processamento (CLAHE + blur)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "799dc6d4",
      "metadata": {
        "id": "799dc6d4"
      },
      "outputs": [],
      "source": [
        "def preprocess_face_gray(gray_200x200):\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    g = clahe.apply(gray_200x200)\n",
        "    g = cv2.GaussianBlur(g, (3,3), 0)\n",
        "    return g"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "babfdb10",
      "metadata": {
        "id": "babfdb10"
      },
      "source": [
        "## 4) Webcam persistente + Preview - Verificação Facial Dual (Colab ↔ Local)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "21d7e319",
      "metadata": {
        "id": "21d7e319",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0b4734f-573d-4dfb-cb94-2078193bfecf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IN_COLAB = True\n"
          ]
        }
      ],
      "source": [
        "import time, base64, uuid\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# Detecta ambiente\n",
        "IN_COLAB = True\n",
        "try:\n",
        "    from google.colab import output  # só existe no Colab\n",
        "    from IPython.display import Javascript, display\n",
        "    IN_COLAB = True\n",
        "except Exception:\n",
        "    IN_COLAB = False\n",
        "\n",
        "print(\"IN_COLAB =\", IN_COLAB)\n",
        "\n",
        "# ---------- (opcional) janela processada no Colab ----------\n",
        "def update_display_img(frame_bgr):\n",
        "    \"\"\"\n",
        "    Atualiza a <img id='output'> no Colab. Em ambiente local, essa função não faz nada\n",
        "    (use cv2.imshow no seu fluxo local).\n",
        "    \"\"\"\n",
        "    if not IN_COLAB:\n",
        "        return\n",
        "    ok, buffer = cv2.imencode('.jpg', frame_bgr)\n",
        "    if not ok:\n",
        "        return\n",
        "    b64 = base64.b64encode(buffer).decode('utf-8')\n",
        "    output.eval_js(f\"window.updateProcessed && window.updateProcessed('{b64}')\")\n",
        "\n",
        "# ---------- Colab: stream persistente via JS ----------\n",
        "if IN_COLAB:\n",
        "    def _ensure_camera_ready(show_raw=False, width=640, height=480):\n",
        "        js = f\"\"\"\n",
        "        (async () => {{\n",
        "          let container = document.getElementById('camera-container');\n",
        "          if (!container) {{\n",
        "            container = document.createElement('div');\n",
        "            container.id = 'camera-container';\n",
        "            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n",
        "            document.body.appendChild(container);\n",
        "            container.innerHTML = `\n",
        "              <div id=\"cam-left\" style=\"display:{'flex' if show_raw else 'none'}; flex-direction:column; align-items:center; gap:6px;\">\n",
        "                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:{width}px; border:1px solid #ddd; border-radius:8px;\"></video>\n",
        "                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n",
        "              </div>\n",
        "              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
        "                <img id=\"output\" style=\"max-width:{width}px; border:1px solid #ddd; border-radius:8px;\">\n",
        "                <small style=\"color:#555\">Frame processado</small>\n",
        "              </div>\n",
        "              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n",
        "            `;\n",
        "          }} else {{\n",
        "            const left = document.getElementById('cam-left');\n",
        "            if (left) left.style.display = { '\"flex\"' if show_raw else '\"none\"' };\n",
        "          }}\n",
        "\n",
        "          if (!window._colabStream || window._colabStreamInactive) {{\n",
        "            try {{\n",
        "              window._colabStream = await navigator.mediaDevices.getUserMedia({{ video: {{width:{width}, height:{height}}}, audio:false }});\n",
        "              window._colabStreamInactive = false;\n",
        "            }} catch (e) {{\n",
        "              console.error('getUserMedia failed', e);\n",
        "              return false;\n",
        "            }}\n",
        "          }}\n",
        "          const video = document.getElementById('webcam');\n",
        "          if (video && video.srcObject !== window._colabStream) {{\n",
        "            video.srcObject = window._colabStream;\n",
        "          }}\n",
        "\n",
        "          const canvas = document.getElementById('canvas');\n",
        "          window.captureFrame = () => {{\n",
        "            const ctx = canvas.getContext('2d');\n",
        "            const vw = (video && video.videoWidth) ? video.videoWidth : {width};\n",
        "            const vh = (video && video.videoHeight) ? video.videoHeight : {height};\n",
        "            canvas.width = vw; canvas.height = vh;\n",
        "            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n",
        "            return canvas.toDataURL('image/jpeg', 0.9);\n",
        "          }};\n",
        "          window.updateProcessed = (b64) => {{\n",
        "            const img = document.getElementById('output');\n",
        "            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n",
        "          }};\n",
        "          window.stopColabCamera = () => {{\n",
        "            try {{\n",
        "              if (window._colabStream && !window._colabStreamInactive) {{\n",
        "                window._colabStream.getTracks().forEach(t => t.stop());\n",
        "                window._colabStreamInactive = true;\n",
        "              }}\n",
        "            }} catch (e) {{ console.warn(e); }}\n",
        "            const c = document.getElementById('camera-container');\n",
        "            if (c) c.remove();\n",
        "          }};\n",
        "          return true;\n",
        "        }} )();\n",
        "        \"\"\"\n",
        "        display(Javascript(js))\n",
        "        time.sleep(0.2)\n",
        "\n",
        "    def _b64_to_image(data_url_or_b64):\n",
        "        if data_url_or_b64 is None:\n",
        "            return None\n",
        "        s = data_url_or_b64\n",
        "        if isinstance(s, bytes):\n",
        "            s = s.decode(\"utf-8\")\n",
        "        if s.startswith(\"data:image\"):\n",
        "            s = s.split(\",\")[1]\n",
        "        arr = np.frombuffer(base64.b64decode(s), dtype=np.uint8)\n",
        "        return cv2.imdecode(arr, cv2.IMREAD_COLOR)\n",
        "\n",
        "    def capture_one(width=640, height=480, show_raw=False):\n",
        "        _ensure_camera_ready(show_raw=show_raw, width=width, height=height)\n",
        "        data_url = output.eval_js(\"window.captureFrame ? window.captureFrame() : null\")\n",
        "        return _b64_to_image(data_url)\n",
        "\n",
        "    def capture_sequence(n=24, delay_ms=80, width=640, height=480, show_raw=False, preview_callback=None):\n",
        "        _ensure_camera_ready(show_raw=show_raw, width=width, height=height)\n",
        "        frames = []\n",
        "        for i in range(n):\n",
        "            data_url = output.eval_js(\"window.captureFrame ? window.captureFrame() : null\")\n",
        "            img = _b64_to_image(data_url)\n",
        "            if img is not None:\n",
        "                frames.append(img)\n",
        "                if callable(preview_callback):\n",
        "                    preview_callback(img, i)\n",
        "            time.sleep(max(0, delay_ms/1000.0))\n",
        "        return frames\n",
        "\n",
        "    def stop_camera_ui():\n",
        "        display(Javascript(\"if (window.stopColabCamera) window.stopColabCamera();\"))\n",
        "        time.sleep(0.2)\n",
        "\n",
        "# ---------- Local: OpenCV VideoCapture ----------\n",
        "else:\n",
        "    def capture_one(cam_index=0, width=640, height=480, show_raw=False):\n",
        "        cap = cv2.VideoCapture(cam_index)\n",
        "        cap.set(cv2.CAP_PROP_FRAME_WIDTH,  width)\n",
        "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
        "        ret, frame = cap.read()\n",
        "        cap.release()\n",
        "        if not ret:\n",
        "            raise RuntimeError(\"Não conseguiu capturar frame da webcam local\")\n",
        "        return frame\n",
        "\n",
        "    def capture_sequence(n=24, delay_ms=80, cam_index=0, width=640, height=480, show_raw=False, preview_callback=None):\n",
        "        cap = cv2.VideoCapture(cam_index)\n",
        "        cap.set(cv2.CAP_PROP_FRAME_WIDTH,  width)\n",
        "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
        "        frames = []\n",
        "        for i in range(n):\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                continue\n",
        "            frames.append(frame)\n",
        "            if callable(preview_callback):\n",
        "                preview_callback(frame, i)\n",
        "            # preview simples local\n",
        "            cv2.imshow(\"preview\", frame)\n",
        "            if cv2.waitKey(delay_ms) & 0xFF == ord(\"q\"):\n",
        "                break\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        return frames\n",
        "\n",
        "    def stop_camera_ui():\n",
        "        # no local, apenas fecha janelas\n",
        "        cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a56dd9cb",
      "metadata": {
        "id": "a56dd9cb"
      },
      "source": [
        "## 5) Detecção de faces (Haar/DNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "23539590",
      "metadata": {
        "id": "23539590",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8ef6e78-9c5d-45c9-8a31-320bbf704d06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Detecção] Modelo atual: haar | MODELS_DIR=cv_colab_data/models\n"
          ]
        }
      ],
      "source": [
        "# ============================\n",
        "# 5) Detecção de faces (Haar/DNN)\n",
        "# ============================\n",
        "#\n",
        "# Suporta dois detectores:\n",
        "#   - \"haar\": Haar Cascade (cv2.CascadeClassifier)\n",
        "#   - \"dnn_ssd_resnet10\": DNN (SSD ResNet10) via OpenCV DNN (Caffe)\n",
        "#\n",
        "# Escolha temporária (até o Runner setar automaticamente):\n",
        "#   - Ajuste DETECTION_MODEL = \"haar\" | \"dnn_ssd_resnet10\"\n",
        "#   - ou exporte a env: DETECTION_MODEL=haar | dnn_ssd_resnet10\n",
        "#\n",
        "# Uso: faces = detect_faces(img_bgr, conf_threshold=0.5)\n",
        "# Retorno: lista de (x, y, w, h, score)\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# ======================\n",
        "# Configuração do modelo\n",
        "# ======================\n",
        "DETECTION_MODEL = os.environ.get(\"DETECTION_MODEL\", \"haar\").strip().lower()\n",
        "\n",
        "# Honra o DATA_DIR definido em outra célula; se não existir, cria um default\n",
        "try:\n",
        "    DATA_DIR  # definido na sua célula de diretórios\n",
        "except NameError:\n",
        "    DATA_DIR = Path(\"cv_colab_data\")\n",
        "    DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "MODELS_DIR = DATA_DIR / \"models\"\n",
        "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Haar: caminho padrão do OpenCV (com fallback)\n",
        "try:\n",
        "    import cv2.data as cvd\n",
        "    HAAR_PATH = str(Path(cvd.haarcascades) / \"haarcascade_frontalface_default.xml\")\n",
        "except Exception:\n",
        "    # fallback: se quiser manter tudo em DATA_DIR/models, pode copiar o xml pra lá\n",
        "    HAAR_PATH = str(MODELS_DIR / \"haarcascade_frontalface_default.xml\")\n",
        "\n",
        "# DNN (SSD ResNet10): caminhos dentro de DATA_DIR/models\n",
        "DNN_PROTO_PATH   = MODELS_DIR / \"deploy.prototxt\"\n",
        "# usamos o modelo Caffe \"não-fp16\", disponível publicamente:\n",
        "DNN_WEIGHTS_PATH = MODELS_DIR / \"res10_300x300_ssd_iter_140000.caffemodel\"\n",
        "\n",
        "# URLs oficiais/alternativas\n",
        "DNN_PROTO_URL   = \"https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt\"\n",
        "DNN_WEIGHTS_URL = \"https://github.com/opencv/opencv_3rdparty/raw/dnn_samples_face_detector_20170830/res10_300x300_ssd_iter_140000.caffemodel\"\n",
        "\n",
        "# --------------\n",
        "# Inicialização\n",
        "# --------------\n",
        "_haar_cascade = None\n",
        "_dnn_net = None\n",
        "\n",
        "def _download_file(url: str, dest: Path) -> bool:\n",
        "    \"\"\"\n",
        "    Baixa com urllib; se falhar e houver 'wget', tenta wget.\n",
        "    Retorna True se o arquivo existir ao final.\n",
        "    \"\"\"\n",
        "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
        "    try:\n",
        "        import urllib.request\n",
        "        print(f\"Baixando {dest.name} …\")\n",
        "        urllib.request.urlretrieve(url, str(dest))\n",
        "        return dest.exists()\n",
        "    except Exception as e:\n",
        "        print(f\"Aviso: urllib falhou ({e}). Tentando wget (se disponível)…\")\n",
        "        try:\n",
        "            code = os.system(f\"wget -q -O {dest} {url}\")\n",
        "            return dest.exists() and code == 0\n",
        "        except Exception as e2:\n",
        "            print(f\"Aviso: wget também falhou ({e2}).\")\n",
        "            return dest.exists()\n",
        "\n",
        "def _download_if_missing():\n",
        "    ok = True\n",
        "    if not Path(DNN_PROTO_PATH).exists():\n",
        "        ok = _download_file(DNN_PROTO_URL, DNN_PROTO_PATH) and ok\n",
        "    if not Path(DNN_WEIGHTS_PATH).exists():\n",
        "        ok = _download_file(DNN_WEIGHTS_URL, DNN_WEIGHTS_PATH) and ok\n",
        "    if not ok:\n",
        "        print(\n",
        "            \"[DNN] Não foi possível garantir todos os arquivos.\\n\"\n",
        "            f\"  Prototxt: {DNN_PROTO_PATH}\\n\"\n",
        "            f\"  Pesos   : {DNN_WEIGHTS_PATH}\\n\"\n",
        "            \"  → Baixe manualmente ou defina DNN_PROTO_PATH / DNN_WEIGHTS_PATH.\"\n",
        "        )\n",
        "\n",
        "def _init_haar():\n",
        "    global _haar_cascade\n",
        "    if _haar_cascade is None:\n",
        "        if not os.path.exists(HAAR_PATH):\n",
        "            raise FileNotFoundError(f\"Haar cascade não encontrado em: {HAAR_PATH}\")\n",
        "        _haar_cascade = cv2.CascadeClassifier(HAAR_PATH)\n",
        "\n",
        "def _init_dnn():\n",
        "    _download_if_missing()\n",
        "    global _dnn_net\n",
        "    if _dnn_net is None:\n",
        "        if not (Path(DNN_PROTO_PATH).exists() and Path(DNN_WEIGHTS_PATH).exists()):\n",
        "            raise FileNotFoundError(\n",
        "                \"Arquivos do DNN não encontrados.\\n\"\n",
        "                f\"  Prototxt: {DNN_PROTO_PATH}\\n\"\n",
        "                f\"  Pesos   : {DNN_WEIGHTS_PATH}\\n\"\n",
        "                \"Ajuste DNN_PROTO_PATH / DNN_WEIGHTS_PATH ou salve os arquivos em DATA_DIR/'models'.\"\n",
        "            )\n",
        "        _dnn_net = cv2.dnn.readNetFromCaffe(str(DNN_PROTO_PATH), str(DNN_WEIGHTS_PATH))\n",
        "\n",
        "# --------------------\n",
        "# Função de detecção\n",
        "# --------------------\n",
        "def detect_faces(image_bgr, conf_threshold: float = 0.5):\n",
        "    \"\"\"\n",
        "    Retorna lista de detecções: (x, y, w, h, score)\n",
        "    \"\"\"\n",
        "    model = DETECTION_MODEL\n",
        "    if model == \"haar\":\n",
        "        _init_haar()\n",
        "        gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
        "        rects = _haar_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "        return [(int(x), int(y), int(w), int(h), 1.0) for (x, y, w, h) in rects]\n",
        "\n",
        "    elif model in (\"dnn\", \"dnn_ssd_resnet10\", \"ssd\", \"resnet10\"):\n",
        "        _init_dnn()\n",
        "        (h, w) = image_bgr.shape[:2]\n",
        "        blob = cv2.dnn.blobFromImage(\n",
        "            cv2.resize(image_bgr, (300, 300)), 1.0, (300, 300),\n",
        "            (104.0, 177.0, 123.0)\n",
        "        )\n",
        "        _dnn_net.setInput(blob)\n",
        "        detections = _dnn_net.forward()\n",
        "        boxes = []\n",
        "        for i in range(detections.shape[2]):\n",
        "            confidence = float(detections[0, 0, i, 2])\n",
        "            if confidence >= conf_threshold:\n",
        "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "                x, y = max(0, startX), max(0, startY)\n",
        "                ww, hh = max(0, endX - startX), max(0, endY - startY)\n",
        "                boxes.append((x, y, ww, hh, confidence))\n",
        "        return boxes\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Modelo '{model}' não suportado. Use 'haar' ou 'dnn_ssd_resnet10'.\")\n",
        "\n",
        "# --------------------\n",
        "# Helper de visualização\n",
        "# --------------------\n",
        "def draw_faces(image_bgr, faces, color=(0,255,0), thickness=2):\n",
        "    out = image_bgr.copy()\n",
        "    for (x,y,w,h,score) in faces:\n",
        "        cv2.rectangle(out, (x,y), (x+w, y+h), color, thickness)\n",
        "        cv2.putText(out, f\"{score:.2f}\", (x, max(0,y-5)), cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 1, cv2.LINE_AA)\n",
        "    return out\n",
        "\n",
        "print(f\"[Detecção] Modelo atual: {DETECTION_MODEL} | MODELS_DIR={MODELS_DIR}\")\n",
        "\n",
        "# Teste rápido (opcional)\n",
        "# img = capture_one(show_raw=True)\n",
        "# faces = detect_faces(img)\n",
        "# vis = draw_faces(img, faces)\n",
        "# show_bgr(vis, \"faces detectadas\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5b79479",
      "metadata": {
        "id": "c5b79479"
      },
      "source": [
        "## 6) Config de preview e evidências"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "af35c8bc",
      "metadata": {
        "id": "af35c8bc"
      },
      "outputs": [],
      "source": [
        "# Cores das caixas (BGR)\n",
        "PREVIEW_BOX_COLOR = (0, 255, 0)     # verde\n",
        "CALIB_BOX_COLOR   = (255, 165, 0)   # laranja\n",
        "FINAL_BOX_COLOR   = (0, 255, 255)   # amarelo\n",
        "SAVE_EVIDENCE     = True\n",
        "\n",
        "def draw_box(img_bgr, bbox, color, thickness=2, label=None):\n",
        "    x,y,w,h = bbox\n",
        "    cv2.rectangle(img_bgr, (x,y), (x+w, y+h), color, thickness)\n",
        "    if label:\n",
        "        cv2.putText(img_bgr, label, (x, max(0, y-8)), cv2.FONT_HERSHEY_SIMPLEX, 0.55, color, 2, cv2.LINE_AA)\n",
        "\n",
        "def maybe_save_evidence(result: dict, vis_bgr, prefix=\"auth\"):\n",
        "    if not SAVE_EVIDENCE:\n",
        "        return\n",
        "    status = result.get(\"status\", \"\")\n",
        "    if status in (\"error\", \"route_review\"):\n",
        "        ts = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "        name = f\"{prefix}_{status}_{ts}_{uuid.uuid4().hex[:6]}.jpg\"\n",
        "        cv2.imwrite(str(EVIDENCE_DIR / name), vis_bgr)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5ae218f",
      "metadata": {
        "id": "d5ae218f"
      },
      "source": [
        "## 7) Enrollment com preview (função)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bf25ffcf",
      "metadata": {
        "id": "bf25ffcf"
      },
      "outputs": [],
      "source": [
        "def enroll_user_with_preview(user_id=\"novo_usuario_preview\", n_samples=30, interval_ms=100):\n",
        "    user_dir = ENROLL_DIR / user_id\n",
        "    user_dir.mkdir(parents=True, exist_ok=True)\n",
        "    setup = capture_one(show_raw=True)  # inicializa UI (mostra preview bruto)\n",
        "\n",
        "    saved = 0\n",
        "    attempts = 0\n",
        "    print(f\"Coletando {n_samples} amostras para '{user_id}'… Olhe para a câmera.\")\n",
        "    while saved < n_samples and attempts < n_samples*3:\n",
        "        attempts += 1\n",
        "        fr = capture_one(show_raw=True)\n",
        "        if fr is None:\n",
        "            time.sleep(0.05);\n",
        "            continue\n",
        "        faces = detect_faces(fr)\n",
        "        vis = fr.copy()\n",
        "        if len(faces):\n",
        "            (x,y,w,h,score) = max(faces, key=lambda f: f[2]*f[3]) # Unpack 5 values\n",
        "            draw_box(vis, (x,y,w,h), PREVIEW_BOX_COLOR, label=\"enroll\")\n",
        "            face = fr[y:y+h, x:x+w]\n",
        "            g = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
        "            g = cv2.resize(g, (200,200))\n",
        "            g = preprocess_face_gray(g)\n",
        "            cv2.imwrite(str(user_dir/f\"{user_id}_{uuid.uuid4().hex[:6]}.jpg\"), g)\n",
        "            saved += 1\n",
        "        update_display_img(vis)\n",
        "        time.sleep(max(0, interval_ms/1000.0))\n",
        "    print(f\"✅ Enrollment concluído: {saved}/{n_samples} amostras salvas.\")\n",
        "    if saved < max(10, int(0.5*n_samples)):\n",
        "        print(\"⚠️ Poucas amostras úteis. Considere refazer com melhor enquadramento/iluminação.\")\n",
        "    # não fecha a UI aqui para reaproveitar no próximo passo"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0f00c3b",
      "metadata": {
        "id": "a0f00c3b"
      },
      "source": [
        "## 8) Modelo LBPH em memória (cache global)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "be1e62e6",
      "metadata": {
        "id": "be1e62e6"
      },
      "outputs": [],
      "source": [
        "REC_CACHE = None\n",
        "LABEL_MAP_CACHE = None\n",
        "INV_LABEL_CACHE = None\n",
        "\n",
        "def _load_images_and_labels():\n",
        "    images, labels = [], []\n",
        "    label_map = {}\n",
        "    next_label = 0\n",
        "    for ud in sorted(ENROLL_DIR.glob(\"*\")):\n",
        "        if not ud.is_dir():\n",
        "            continue\n",
        "        uid = ud.name\n",
        "        label_map[uid] = next_label\n",
        "        for p in ud.glob(\"*.jpg\"):\n",
        "            g = cv2.imread(str(p), cv2.IMREAD_GRAYSCALE)\n",
        "            if g is None:\n",
        "                continue\n",
        "            g = cv2.resize(g, (200,200))\n",
        "            g = preprocess_face_gray(g)\n",
        "            images.append(g); labels.append(next_label)\n",
        "        next_label += 1\n",
        "    return images, np.array(labels), label_map\n",
        "\n",
        "def train_lbph_in_memory(neighbors=16):\n",
        "    global REC_CACHE, LABEL_MAP_CACHE, INV_LABEL_CACHE\n",
        "    images, labels, label_map = _load_images_and_labels()\n",
        "    if len(images) == 0:\n",
        "        raise RuntimeError(\"Sem amostras. Faça o enrollment antes.\")\n",
        "    rec = cv2.face.LBPHFaceRecognizer_create(radius=2, neighbors=neighbors, grid_x=8, grid_y=8)\n",
        "    rec.train(images, labels)\n",
        "    REC_CACHE = rec\n",
        "    LABEL_MAP_CACHE = label_map\n",
        "    INV_LABEL_CACHE = {v:k for k,v in label_map.items()}\n",
        "    print(f\"Modelo LBPH treinado em memória. Usuários: {list(label_map.keys())}\")\n",
        "    return rec\n",
        "\n",
        "def get_recognizer(neighbors=16, force_retrain=False):\n",
        "    global REC_CACHE, LABEL_MAP_CACHE, INV_LABEL_CACHE\n",
        "    if force_retrain or REC_CACHE is None or LABEL_MAP_CACHE is None or INV_LABEL_CACHE is None:\n",
        "        print(\"↻ Treinando LBPH (memória)…\")\n",
        "        return train_lbph_in_memory(neighbors=neighbors)\n",
        "    return REC_CACHE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de3a1cce",
      "metadata": {
        "id": "de3a1cce"
      },
      "source": [
        "## 9) Calibração automática do limiar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6a2c5e8c",
      "metadata": {
        "id": "6a2c5e8c"
      },
      "outputs": [],
      "source": [
        "def _detect_face_gray200(img_bgr):\n",
        "    faces = detect_faces(img_bgr)\n",
        "    if len(faces)==0:\n",
        "        return None, None\n",
        "    (x,y,w,h,score) = max(faces, key=lambda f: f[2]*f[3]) # Unpack 5 values including score\n",
        "    face = img_bgr[y:y+h, x:x+w]\n",
        "    g = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
        "    g = cv2.resize(g, (200,200))\n",
        "    g = preprocess_face_gray(g)\n",
        "    return g, (x,y,w,h)\n",
        "\n",
        "def calibrate_threshold(samples=15, neighbors=16):\n",
        "    global SERVICE_THRESHOLD\n",
        "    rec = get_recognizer(neighbors=neighbors)\n",
        "    dists = []\n",
        "    print(f\"📏 Calibrando limiar (coletando {samples} distâncias)…\")\n",
        "    for i in range(samples):\n",
        "        fr = capture_one(show_raw=True)\n",
        "        if fr is None:\n",
        "            time.sleep(0.05);\n",
        "            continue\n",
        "        g200, bbox = _detect_face_gray200(fr)\n",
        "        vis = fr.copy()\n",
        "        if bbox is not None:\n",
        "            (x,y,w,h) = bbox\n",
        "            draw_box(vis, (x,y,w,h), CALIB_BOX_COLOR, label=\"calib\")\n",
        "            _, dist = rec.predict(g200)\n",
        "            dists.append(dist)\n",
        "            print(f\"[{i+1}/{samples}] dist={dist:.1f}\")\n",
        "        update_display_img(vis)\n",
        "        time.sleep(0.08)\n",
        "    if dists:\n",
        "        p95 = float(np.percentile(dists, 95))\n",
        "        SERVICE_THRESHOLD = round(p95 + 5.0, 1)\n",
        "        print(f\"🎯 Novo SERVICE_THRESHOLD = {SERVICE_THRESHOLD} (p95={p95:.1f} + margem)\")\n",
        "    else:\n",
        "        print(\"⚠️ Calibração insuficiente; threshold mantido.\")\n",
        "    return SERVICE_THRESHOLD"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5468bd2f",
      "metadata": {
        "id": "5468bd2f"
      },
      "source": [
        "## 10) Liveness passivo com preview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4ff8dc03",
      "metadata": {
        "id": "4ff8dc03"
      },
      "outputs": [],
      "source": [
        "def liveness_passive_preview(n=24, delay_ms=80, min_energy=LIVENESS_MIN_ENERGY):\n",
        "    prev = None\n",
        "    energy = 0.0\n",
        "    used = 0\n",
        "    for i in range(n):\n",
        "        fr = capture_one(show_raw=True)\n",
        "        if fr is None:\n",
        "            time.sleep(0.05)\n",
        "            continue\n",
        "        faces = detect_faces(fr)\n",
        "        vis = fr.copy()\n",
        "        if len(faces):\n",
        "            (x,y,w,h,score) = max(faces, key=lambda f: f[2]*f[3]) # Unpack 5 values\n",
        "            draw_box(vis, (x,y,w,h), PREVIEW_BOX_COLOR, label=\"live\")\n",
        "            face = fr[y:y+h, x:x+w]\n",
        "            g = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
        "            g = cv2.resize(g, (160,160))\n",
        "            g = preprocess_face_gray(g)\n",
        "            if prev is not None:\n",
        "                diff = cv2.absdiff(g, prev)\n",
        "                energy += float(np.mean(diff))\n",
        "            prev = g; used += 1\n",
        "        update_display_img(vis)\n",
        "        time.sleep(max(0, delay_ms/1000.0))\n",
        "    avg = energy / max(1, used)\n",
        "    verdict = \"live\" if avg >= min_energy else \"spoof\"\n",
        "    print(f\"[Liveness] energia média: {avg:.2f} -> {verdict}\")\n",
        "    return verdict, avg"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3eff28f",
      "metadata": {
        "id": "b3eff28f"
      },
      "source": [
        "## 11) Autenticação 1:1 (com liveness e preview)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6ea82543",
      "metadata": {
        "id": "6ea82543"
      },
      "outputs": [],
      "source": [
        "def authenticate_1v1_preview(expected_user=\"novo_usuario_preview\", neighbors=16, require_liveness=True):\n",
        "    thr = SERVICE_THRESHOLD\n",
        "    if require_liveness:\n",
        "        verdict, energy = liveness_passive_preview(n=24, delay_ms=80, min_energy=LIVENESS_MIN_ENERGY)\n",
        "        if verdict != \"live\":\n",
        "            print(f\"🛑 Liveness falhou (energia={energy:.2f}).\")\n",
        "            result = {\"status\":\"route_review\", \"mode\":\"1v1\", \"reason\":\"liveness_fail\", \"energy\":energy}\n",
        "            maybe_save_evidence(result, np.zeros((10,10,3), dtype=np.uint8), prefix=\"auth_1v1\")\n",
        "            return result\n",
        "\n",
        "    rec = get_recognizer(neighbors=neighbors)\n",
        "    fr = capture_one(show_raw=True)\n",
        "    if fr is None:\n",
        "        result = {\"status\":\"error\", \"mode\":\"1v1\", \"reason\":\"capture_fail\"}\n",
        "        return result\n",
        "\n",
        "    g200, bbox = _detect_face_gray200(fr)\n",
        "    vis = fr.copy()\n",
        "    if bbox is None:\n",
        "        update_display_img(vis)\n",
        "        result = {\"status\":\"error\", \"mode\":\"1v1\", \"reason\":\"no_face\"}\n",
        "        maybe_save_evidence(result, vis, prefix=\"auth_1v1\")\n",
        "        return result\n",
        "\n",
        "    (x,y,w,h) = bbox\n",
        "    draw_box(vis, (x,y,w,h), FINAL_BOX_COLOR, label=\"auth 1:1\")\n",
        "    update_display_img(vis)\n",
        "\n",
        "    label, conf = rec.predict(g200)\n",
        "    pred_user = INV_LABEL_CACHE.get(label, \"desconhecido\")\n",
        "    print(f\"🔐 1:1 — esperado={expected_user} | predito={pred_user} | dist={conf:.1f} | thr={thr}\")\n",
        "\n",
        "    if pred_user == expected_user and conf <= thr:\n",
        "        result = {\"status\":\"approved\", \"mode\":\"1v1\", \"user\":pred_user, \"dist\":float(conf), \"threshold\":thr}\n",
        "    else:\n",
        "        result = {\"status\":\"route_review\", \"mode\":\"1v1\", \"reason\":\"no_match\", \"pred\":pred_user, \"dist\":float(conf), \"threshold\":thr}\n",
        "        maybe_save_evidence(result, vis, prefix=\"auth_1v1\")\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eff1f2a9",
      "metadata": {
        "id": "eff1f2a9"
      },
      "source": [
        "## 12) Autenticação 1:N (com liveness e preview)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "353349b8",
      "metadata": {
        "id": "353349b8"
      },
      "outputs": [],
      "source": [
        "def authenticate_1vN_preview(neighbors=16, require_liveness=True):\n",
        "    thr = SERVICE_THRESHOLD\n",
        "    if require_liveness:\n",
        "        verdict, energy = liveness_passive_preview(n=24, delay_ms=80, min_energy=LIVENESS_MIN_ENERGY)\n",
        "        if verdict != \"live\":\n",
        "            print(f\"🛑 Liveness falhou (energia={energy:.2f}).\")\n",
        "            result = {\"status\":\"route_review\", \"mode\":\"1vN\", \"reason\":\"liveness_fail\", \"energy\":energy}\n",
        "            maybe_save_evidence(result, np.zeros((10,10,3), dtype=np.uint8), prefix=\"auth_1vN\")\n",
        "            return result\n",
        "\n",
        "    rec = get_recognizer(neighbors=neighbors)\n",
        "    fr = capture_one(show_raw=True)\n",
        "    if fr is None:\n",
        "        result = {\"status\":\"error\", \"mode\":\"1vN\", \"reason\":\"capture_fail\"}\n",
        "        return result\n",
        "\n",
        "    g200, bbox = _detect_face_gray200(fr)\n",
        "    vis = fr.copy()\n",
        "    if bbox is None:\n",
        "        update_display_img(vis)\n",
        "        result = {\"status\":\"error\", \"mode\":\"1vN\", \"reason\":\"no_face\"}\n",
        "        maybe_save_evidence(result, vis, prefix=\"auth_1vN\")\n",
        "        return result\n",
        "\n",
        "    (x,y,w,h) = bbox\n",
        "    draw_box(vis, (x,y,w,h), FINAL_BOX_COLOR, label=\"auth 1:N\")\n",
        "    update_display_img(vis)\n",
        "\n",
        "    label, conf = rec.predict(g200)  # menor = melhor\n",
        "    user_pred = INV_LABEL_CACHE.get(label, \"desconhecido\")\n",
        "    print(f\"🧭 1:N — predito={user_pred} | dist={conf:.1f} | thr={thr}\")\n",
        "\n",
        "    if conf <= thr:\n",
        "        result = {\"status\":\"approved\", \"mode\":\"1vN\", \"user\":user_pred, \"dist\":float(conf), \"threshold\":thr}\n",
        "    else:\n",
        "        result = {\"status\":\"route_review\", \"mode\":\"1vN\", \"reason\":\"no_match\", \"pred\":user_pred, \"dist\":float(conf), \"threshold\":thr}\n",
        "        maybe_save_evidence(result, vis, prefix=\"auth_1vN\")\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13) Bloco de utilidades de avaliação\n",
        "\n",
        "> Adicionar aspas\n",
        "\n"
      ],
      "metadata": {
        "id": "vxUzE2bnhcOQ"
      },
      "id": "vxUzE2bnhcOQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================\n",
        "# Função: avaliação OFFLINE com DATASET AUTOMÁTICO\n",
        "#  - positives: ENROLL_DIR/<user> (ou todos, se não houver alvo)\n",
        "#  - negatives: persistidos em DATA_DIR/\"negatives\" (captura da câmera se faltarem)\n",
        "#  - usa detect_faces() da célula 5\n",
        "# Retorna: dict com métricas e info (ou None se falhar)\n",
        "# =============================================\n",
        "import os, time, shutil\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "try:\n",
        "    import pandas as pd\n",
        "except Exception:\n",
        "    pd = None\n",
        "\n",
        "def run_offline_eval_from_enrollment(\n",
        "    neg_target_min: int = 30,\n",
        "    capture_batch: int = 30,\n",
        "    capture_sleep_sec: float = 0.15,\n",
        "    eval_max_images: int | None = None,\n",
        "    conf_threshold: float = 0.5,\n",
        "    use_camera: bool = True,\n",
        "    negatives_src_dir: str | Path | None = None,\n",
        "    dataset_dir_override: str | Path | None = None, # Adicionado\n",
        "    default_dataset_dir: str | Path | None = None,  # Adicionado\n",
        "):\n",
        "    \"\"\"\n",
        "    Executa avaliação offline após o fluxo principal do Runner.\n",
        "    - Garante arquivos do DNN (se DETECTION_MODEL = dnn_ssd_resnet10).\n",
        "    - Monta dataset em DATA_DIR/'dataset_auto' (positives de ENROLL_DIR, negatives persistentes).\n",
        "    - Roda matriz de confusão e métricas (robusto a apenas 1 classe).\n",
        "    \"\"\"\n",
        "    # ===== caminhos vindos de células anteriores =====\n",
        "    try:\n",
        "        DATA_DIR\n",
        "    except NameError:\n",
        "        # fallback seguro\n",
        "        globals()[\"DATA_DIR\"] = Path(\"cv_colab_data\")\n",
        "        DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    try:\n",
        "        ENROLL_DIR\n",
        "    except NameError:\n",
        "        globals()[\"ENROLL_DIR\"] = DATA_DIR / \"enroll\"\n",
        "        ENROLL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    NEG_STORE_DIR = DATA_DIR / \"negatives\"      # negativos persistentes\n",
        "    DATASET_AUTO  = DATA_DIR / \"dataset_auto\"   # dataset gerado automaticamente\n",
        "    POS_DIR_AUTO  = DATASET_AUTO / \"positives\"\n",
        "    NEG_DIR_AUTO  = DATASET_AUTO / \"negatives\"\n",
        "    NEG_STORE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    NAME_MAP = {True: \"face\", False: \"no_face\"}\n",
        "\n",
        "    # ===== helpers =====\n",
        "    def _list_images(dirpath: Path):\n",
        "        exts = {\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\"}\n",
        "        if not dirpath.is_dir():\n",
        "            return []\n",
        "        return sorted([str(p) for p in dirpath.iterdir() if p.suffix.lower() in exts])\n",
        "\n",
        "    def _copy_all_images(src: Path, dst: Path):\n",
        "        dst.mkdir(parents=True, exist_ok=True)\n",
        "        count = 0\n",
        "        for ext in (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.bmp\",\"*.tif\",\"*.tiff\"):\n",
        "            for p in src.rglob(ext):\n",
        "                out = dst / f\"{p.stem}_{count}{p.suffix.lower()}\"\n",
        "                try:\n",
        "                    shutil.copy2(p, out)\n",
        "                    count += 1\n",
        "                except Exception:\n",
        "                    pass\n",
        "        return count\n",
        "\n",
        "    def _capture_negatives_persistent(store_dir: Path, frames=30, sleep=0.15):\n",
        "        if not use_camera:\n",
        "            return 0\n",
        "        cap = cv2.VideoCapture(0)\n",
        "        if not cap.isOpened():\n",
        "            print(\"✘ Não foi possível abrir a câmera para capturar negativos.\")\n",
        "            return 0\n",
        "        print(f\"🎥 Capturando {frames} negativos (aponte para parede/quadro vazio ou saia do frame)…\")\n",
        "        count = 0\n",
        "        for i in range(frames):\n",
        "            ok, frame = cap.read()\n",
        "            if not ok:\n",
        "                break\n",
        "            out = store_dir / f\"neg_{int(time.time())}_{i:03d}.jpg\"\n",
        "            cv2.imwrite(str(out), frame)\n",
        "            time.sleep(sleep)\n",
        "            count += 1\n",
        "        cap.release()\n",
        "        print(f\"✔ Negativos capturados (persistentes): {count}\")\n",
        "        return count\n",
        "\n",
        "    def _ensure_dnn_files_if_needed():\n",
        "        det = os.environ.get(\"DETECTION_MODEL\", \"\").lower()\n",
        "        if det not in (\"dnn_ssd_resnet10\", \"dnn\", \"ssd\", \"resnet10\"):\n",
        "            return\n",
        "        MODELS_DIR = DATA_DIR / \"models\"\n",
        "        PROTO   = MODELS_DIR / \"deploy.prototxt\"\n",
        "        WEIGHTS = MODELS_DIR / \"res10_300x300_ssd_iter_140000.caffemodel\"\n",
        "        if PROTO.exists() and WEIGHTS.exists():\n",
        "            return\n",
        "        MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "        try:\n",
        "            import urllib.request\n",
        "            if not PROTO.exists():\n",
        "                print(\"Baixando deploy.prototxt …\")\n",
        "                urllib.request.urlretrieve(\n",
        "                    \"https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt\",\n",
        "                    str(PROTO)\n",
        "                )\n",
        "            if not WEIGHTS.exists():\n",
        "                print(\"Baixando res10_300x300_ssd_iter_140000.caffemodel …\")\n",
        "                urllib.request.urlretrieve(\n",
        "                    \"https://github.com/opencv/opencv_3rdparty/raw/dnn_samples_face_detector_20170830/res10_300x300_ssd_iter_140000.caffemodel\",\n",
        "                    str(WEIGHTS)\n",
        "                )\n",
        "            print(\"✔ DNN pronto em\", MODELS_DIR)\n",
        "        except Exception as e:\n",
        "            print(\"✘ Falha ao baixar arquivos do DNN automaticamente:\", e)\n",
        "            print(\"  → Baixe manualmente para:\", MODELS_DIR)\n",
        "\n",
        "    def _evaluate_current_detector(dataset_dir: Path, max_images=None, conf_threshold=0.5):\n",
        "        pos_imgs = _list_images(dataset_dir / \"positives\")\n",
        "        neg_imgs = _list_images(dataset_dir / \"negatives\")\n",
        "        if max_images:\n",
        "            pos_imgs = pos_imgs[:max_images]\n",
        "            neg_imgs = neg_imgs[:max_images]\n",
        "\n",
        "        y_true, y_pred, times = [], [], []\n",
        "        import time as _t\n",
        "        # usa detect_faces() da célula 5\n",
        "        for p in pos_imgs:\n",
        "            img = cv2.imread(p)\n",
        "            if img is None:\n",
        "                continue\n",
        "            t0 = _t.perf_counter()\n",
        "            boxes = detect_faces(img, conf_threshold=conf_threshold)\n",
        "            times.append(_t.perf_counter() - t0)\n",
        "            y_true.append(True)\n",
        "            y_pred.append(len(boxes) > 0)\n",
        "\n",
        "        for p in neg_imgs:\n",
        "            img = cv2.imread(p)\n",
        "            if img is None:\n",
        "                continue\n",
        "            t0 = _t.perf_counter()\n",
        "            boxes = detect_faces(img, conf_threshold=conf_threshold)\n",
        "            times.append(_t.perf_counter() - t0)\n",
        "            y_true.append(False)\n",
        "            y_pred.append(len(boxes) > 0)\n",
        "\n",
        "        if not y_true:\n",
        "            raise ValueError(\"Dataset vazio para avaliação.\")\n",
        "\n",
        "        # classes realmente presentes\n",
        "        present = sorted(set(y_true))\n",
        "        cm = confusion_matrix(y_true, y_pred, labels=present)\n",
        "        acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "        def _safe(fn):\n",
        "            try:\n",
        "                return fn(y_true, y_pred, zero_division=0)\n",
        "            except Exception:\n",
        "                return float(\"nan\")\n",
        "\n",
        "        if set(present) == {True, False}:\n",
        "            prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "            rec  = recall_score(y_true, y_pred, zero_division=0)\n",
        "            f1   = f1_score(y_true, y_pred, zero_division=0)\n",
        "            print(\"\\n=== Relatório (2 classes) ===\")\n",
        "            print(classification_report(\n",
        "                y_true, y_pred, labels=present,\n",
        "                target_names=[NAME_MAP[c] for c in present], zero_division=0\n",
        "            ))\n",
        "        else:\n",
        "            prec = _safe(precision_score)\n",
        "            rec  = _safe(recall_score)\n",
        "            f1   = _safe(f1_score)\n",
        "            faltante = \"no_face\" if present == [True] else \"face\"\n",
        "            print(f\"\\n[AVISO] Apenas 1 classe presente (faltando: {faltante}). Métricas completas não se aplicam.\")\n",
        "\n",
        "        avg_time = float(np.mean(times)) if times else float(\"nan\")\n",
        "        mdl = os.environ.get(\"DETECTION_MODEL\", \"(desconhecido)\")\n",
        "\n",
        "        print(f\"\\n=== Resultados: {mdl} ===\")\n",
        "        print(f\"Accuracy : {acc:.4f}\")\n",
        "        print(f\"Precision: {prec if np.isfinite(prec) else 'N/A'}\")\n",
        "        print(f\"Recall   : {rec if np.isfinite(rec) else 'N/A'}\")\n",
        "        print(f\"F1-score : {f1 if np.isfinite(f1) else 'N/A'}\")\n",
        "        print(f\"Tempo médio por imagem: {avg_time:.4f} s\")\n",
        "\n",
        "        # Plot\n",
        "        plt.figure(figsize=(4, 3))\n",
        "        plt.imshow(cm, interpolation='nearest')\n",
        "        plt.title(f\"Matriz de Confusão - {mdl}\")\n",
        "        plt.colorbar()\n",
        "        ticks = np.arange(len(present))\n",
        "        plt.xticks(ticks, [NAME_MAP[c] for c in present], rotation=45)\n",
        "        plt.yticks(ticks, [NAME_MAP[c] for c in present])\n",
        "        thresh = cm.max() / 2.0 if cm.size else 0\n",
        "        for i in range(cm.shape[0]):\n",
        "            for j in range(cm.shape[1]):\n",
        "                plt.text(j, i, f\"{cm[i, j]:d}\",\n",
        "                         ha=\"center\",\n",
        "                         color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        plt.ylabel('Verdadeiro')\n",
        "        plt.xlabel('Predito')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        metrics = {\n",
        "            \"model\": mdl, \"accuracy\": float(acc),\n",
        "            \"precision\": (float(prec) if np.isfinite(prec) else None),\n",
        "            \"recall\": (float(rec) if np.isfinite(rec) else None),\n",
        "            \"f1\": (float(f1) if np.isfinite(f1) else None),\n",
        "            \"avg_time\": avg_time, \"n_samples\": len(y_true),\n",
        "            \"classes_presentes\": [NAME_MAP[c] for c in present],\n",
        "            \"confusion_matrix\": cm,\n",
        "        }\n",
        "\n",
        "        if pd is not None:\n",
        "            try:\n",
        "                df = pd.DataFrame([{\n",
        "                    \"modelo\": metrics[\"model\"], \"accuracy\": metrics[\"accuracy\"],\n",
        "                    \"precision\": metrics[\"precision\"], \"recall\": metrics[\"recall\"],\n",
        "                    \"f1\": metrics[\"f1\"], \"avg_time\": metrics[\"avg_time\"],\n",
        "                    \"n\": metrics[\"n_samples\"], \"classes_presentes\": metrics[\"classes_presentes\"]\n",
        "                }])\n",
        "                display(df)\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    # ===== 1) DNN (se necessário) =====\n",
        "    _ensure_dnn_files_if_needed()\n",
        "\n",
        "    # ===== Use dataset_override if provided =====\n",
        "    if dataset_dir_override is not None:\n",
        "        print(f\"ℹ Usando dataset override: {dataset_dir_override}\")\n",
        "        try:\n",
        "            metrics = _evaluate_current_detector(Path(dataset_dir_override), max_images=eval_max_images, conf_threshold=conf_threshold)\n",
        "            return metrics\n",
        "        except Exception as e:\n",
        "            print(\"✘ Falha na avaliação offline com dataset override:\", e)\n",
        "            return None\n",
        "\n",
        "    # ===== Use default_dataset_dir if provided =====\n",
        "    if default_dataset_dir is not None:\n",
        "        print(f\"ℹ Usando dataset DEFAULT: {default_dataset_dir}\")\n",
        "        try:\n",
        "            metrics = _evaluate_current_detector(Path(default_dataset_dir), max_images=eval_max_images, conf_threshold=conf_threshold)\n",
        "            return metrics\n",
        "        except Exception as e:\n",
        "            print(\"✘ Falha na avaliação offline com dataset default:\", e)\n",
        "            return None\n",
        "\n",
        "    # ===== 2) usuário alvo para positives (para dataset_auto) =====\n",
        "    target_user = None\n",
        "    if 'NEW_USER_ID' in globals() and NEW_USER_ID:\n",
        "        target_user = NEW_USER_ID\n",
        "    elif 'AUTH_MODE_1V1' in globals() and AUTH_MODE_1V1 and 'EXPECTED_USER_1V1' in globals() and EXPECTED_USER_1V1:\n",
        "        target_user = EXPECTED_USER_1V1\n",
        "\n",
        "    # ===== 3) (re)criar dataset_auto =====\n",
        "    if DATASET_AUTO.exists():\n",
        "        shutil.rmtree(DATASET_AUTO)\n",
        "    POS_DIR_AUTO.mkdir(parents=True, exist_ok=True)\n",
        "    NEG_DIR_AUTO.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # ===== 4) positives (para dataset_auto) =====\n",
        "    npos = 0\n",
        "    if target_user:\n",
        "        src_pos = ENROLL_DIR / target_user\n",
        "        if src_pos.is_dir():\n",
        "            npos = _copy_all_images(src_pos, POS_DIR_AUTO)\n",
        "            print(f\"✔ Positives de '{target_user}': {npos}\")\n",
        "        else:\n",
        "            print(f\"✘ Não encontrei ENROLL_DIR para '{target_user}': {src_pos}\")\n",
        "    else:\n",
        "        if ENROLL_DIR.is_dir():\n",
        "            for sub in ENROLL_DIR.iterdir():\n",
        "                if sub.is_dir():\n",
        "                    npos += _copy_all_images(sub, POS_DIR_AUTO)\n",
        "        print(f\"✔ Positives (todos): {npos}\")\n",
        "\n",
        "    # ===== 5) negatives persistentes (para dataset_auto) =====\n",
        "    neg_existing = len(_list_images(NEG_STORE_DIR))\n",
        "    # opção: copiar de pasta externa, se fornecida\n",
        "    if negatives_src_dir is not None and Path(negatives_src_dir).is_dir():\n",
        "        added = _copy_all_images(Path(negatives_src_dir), NEG_STORE_DIR)\n",
        "        neg_existing += added\n",
        "        print(f\"✔ Negativos importados de '{negatives_src_dir}': +{added} (total={neg_existing})\")\n",
        "\n",
        "    if neg_existing < neg_target_min:\n",
        "        falta = neg_target_min - neg_existing\n",
        "        batch = max(capture_batch, falta)\n",
        "        print(f\"ℹ Negativos existentes: {neg_existing}. Capturando {batch} para atingir >= {neg_target_min} …\")\n",
        "        _capture_negatives_persistent(NEG_STORE_DIR, frames=batch, sleep=capture_sleep_sec)\n",
        "\n",
        "    # copiar negativos persistentes → dataset_auto\n",
        "    nneg = _copy_all_images(NEG_STORE_DIR, NEG_DIR_AUTO)\n",
        "    print(f\"✔ Negatives adicionados ao dataset_auto: {nneg}\")\n",
        "\n",
        "    # ===== 6) avaliação (dataset_auto) =====\n",
        "    try:\n",
        "        metrics = _evaluate_current_detector(DATASET_AUTO, max_images=eval_max_images, conf_threshold=conf_threshold)\n",
        "        return metrics\n",
        "    except Exception as e:\n",
        "        print(\"✘ Falha na avaliação offline:\", e)\n",
        "        return None"
      ],
      "metadata": {
        "id": "PhKjkZ4ghdSl"
      },
      "id": "PhKjkZ4ghdSl",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "250ccea5",
      "metadata": {
        "id": "250ccea5"
      },
      "source": [
        "## 14) Pipelines compactos (1:1 e 1:N)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "51b5a590",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "51b5a590",
        "outputId": "00d0cff8-4b3e-4ad0-f40f-3140acbcee9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selecione o detector de faces a ser usado na célula 5 (detect_faces).\n",
            "Opções: 'haar' (CascadeClassifier) ou 'dnn_ssd_resnet10' (OpenCV DNN SSD ResNet10)\n",
            "Detector [dnn_ssd_resnet10/haar]: haar\n",
            "[Runner] Detector selecionado: haar\n",
            "Deseja incluir um novo usuário no modelo ou apenas autenticar um já existente?\n",
            "Digite 'novo' para incluir, ou 'auth' para apenas autenticar.\n",
            "Modo [novo/auth]: auth\n",
            "Qual tipo de autenticação deseja usar?\n",
            "Digite '1' para 1:1 (comparar com um usuário específico) ou 'N' para 1:N (identificar entre os cadastrados).\n",
            "Tipo [1/N]: n\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "          let container = document.getElementById('camera-container');\n",
              "          if (!container) {\n",
              "            container = document.createElement('div');\n",
              "            container.id = 'camera-container';\n",
              "            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n",
              "            document.body.appendChild(container);\n",
              "            container.innerHTML = `\n",
              "              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n",
              "                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n",
              "              </div>\n",
              "              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n",
              "                <small style=\"color:#555\">Frame processado</small>\n",
              "              </div>\n",
              "              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n",
              "            `;\n",
              "          } else {\n",
              "            const left = document.getElementById('cam-left');\n",
              "            if (left) left.style.display = \"flex\";\n",
              "          }\n",
              "\n",
              "          if (!window._colabStream || window._colabStreamInactive) {\n",
              "            try {\n",
              "              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n",
              "              window._colabStreamInactive = false;\n",
              "            } catch (e) {\n",
              "              console.error('getUserMedia failed', e);\n",
              "              return false;\n",
              "            }\n",
              "          }\n",
              "          const video = document.getElementById('webcam');\n",
              "          if (video && video.srcObject !== window._colabStream) {\n",
              "            video.srcObject = window._colabStream;\n",
              "          }\n",
              "\n",
              "          const canvas = document.getElementById('canvas');\n",
              "          window.captureFrame = () => {\n",
              "            const ctx = canvas.getContext('2d');\n",
              "            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n",
              "            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n",
              "            canvas.width = vw; canvas.height = vh;\n",
              "            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n",
              "            return canvas.toDataURL('image/jpeg', 0.9);\n",
              "          };\n",
              "          window.updateProcessed = (b64) => {\n",
              "            const img = document.getElementById('output');\n",
              "            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n",
              "          };\n",
              "          window.stopColabCamera = () => {\n",
              "            try {\n",
              "              if (window._colabStream && !window._colabStreamInactive) {\n",
              "                window._colabStream.getTracks().forEach(t => t.stop());\n",
              "                window._colabStreamInactive = true;\n",
              "              }\n",
              "            } catch (e) { console.warn(e); }\n",
              "            const c = document.getElementById('camera-container');\n",
              "            if (c) c.remove();\n",
              "          };\n",
              "          return true;\n",
              "        } )();\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "          let container = document.getElementById('camera-container');\n",
              "          if (!container) {\n",
              "            container = document.createElement('div');\n",
              "            container.id = 'camera-container';\n",
              "            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n",
              "            document.body.appendChild(container);\n",
              "            container.innerHTML = `\n",
              "              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n",
              "                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n",
              "              </div>\n",
              "              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n",
              "                <small style=\"color:#555\">Frame processado</small>\n",
              "              </div>\n",
              "              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n",
              "            `;\n",
              "          } else {\n",
              "            const left = document.getElementById('cam-left');\n",
              "            if (left) left.style.display = \"flex\";\n",
              "          }\n",
              "\n",
              "          if (!window._colabStream || window._colabStreamInactive) {\n",
              "            try {\n",
              "              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n",
              "              window._colabStreamInactive = false;\n",
              "            } catch (e) {\n",
              "              console.error('getUserMedia failed', e);\n",
              "              return false;\n",
              "            }\n",
              "          }\n",
              "          const video = document.getElementById('webcam');\n",
              "          if (video && video.srcObject !== window._colabStream) {\n",
              "            video.srcObject = window._colabStream;\n",
              "          }\n",
              "\n",
              "          const canvas = document.getElementById('canvas');\n",
              "          window.captureFrame = () => {\n",
              "            const ctx = canvas.getContext('2d');\n",
              "            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n",
              "            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n",
              "            canvas.width = vw; canvas.height = vh;\n",
              "            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n",
              "            return canvas.toDataURL('image/jpeg', 0.9);\n",
              "          };\n",
              "          window.updateProcessed = (b64) => {\n",
              "            const img = document.getElementById('output');\n",
              "            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n",
              "          };\n",
              "          window.stopColabCamera = () => {\n",
              "            try {\n",
              "              if (window._colabStream && !window._colabStreamInactive) {\n",
              "                window._colabStream.getTracks().forEach(t => t.stop());\n",
              "                window._colabStreamInactive = true;\n",
              "              }\n",
              "            } catch (e) { console.warn(e); }\n",
              "            const c = document.getElementById('camera-container');\n",
              "            if (c) c.remove();\n",
              "          };\n",
              "          return true;\n",
              "        } )();\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "          let container = document.getElementById('camera-container');\n",
              "          if (!container) {\n",
              "            container = document.createElement('div');\n",
              "            container.id = 'camera-container';\n",
              "            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n",
              "            document.body.appendChild(container);\n",
              "            container.innerHTML = `\n",
              "              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n",
              "                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n",
              "              </div>\n",
              "              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n",
              "                <small style=\"color:#555\">Frame processado</small>\n",
              "              </div>\n",
              "              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n",
              "            `;\n",
              "          } else {\n",
              "            const left = document.getElementById('cam-left');\n",
              "            if (left) left.style.display = \"flex\";\n",
              "          }\n",
              "\n",
              "          if (!window._colabStream || window._colabStreamInactive) {\n",
              "            try {\n",
              "              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n",
              "              window._colabStreamInactive = false;\n",
              "            } catch (e) {\n",
              "              console.error('getUserMedia failed', e);\n",
              "              return false;\n",
              "            }\n",
              "          }\n",
              "          const video = document.getElementById('webcam');\n",
              "          if (video && video.srcObject !== window._colabStream) {\n",
              "            video.srcObject = window._colabStream;\n",
              "          }\n",
              "\n",
              "          const canvas = document.getElementById('canvas');\n",
              "          window.captureFrame = () => {\n",
              "            const ctx = canvas.getContext('2d');\n",
              "            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n",
              "            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n",
              "            canvas.width = vw; canvas.height = vh;\n",
              "            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n",
              "            return canvas.toDataURL('image/jpeg', 0.9);\n",
              "          };\n",
              "          window.updateProcessed = (b64) => {\n",
              "            const img = document.getElementById('output');\n",
              "            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n",
              "          };\n",
              "          window.stopColabCamera = () => {\n",
              "            try {\n",
              "              if (window._colabStream && !window._colabStreamInactive) {\n",
              "                window._colabStream.getTracks().forEach(t => t.stop());\n",
              "                window._colabStreamInactive = true;\n",
              "              }\n",
              "            } catch (e) { console.warn(e); }\n",
              "            const c = document.getElementById('camera-container');\n",
              "            if (c) c.remove();\n",
              "          };\n",
              "          return true;\n",
              "        } )();\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "          let container = document.getElementById('camera-container');\n",
              "          if (!container) {\n",
              "            container = document.createElement('div');\n",
              "            container.id = 'camera-container';\n",
              "            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n",
              "            document.body.appendChild(container);\n",
              "            container.innerHTML = `\n",
              "              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n",
              "                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n",
              "              </div>\n",
              "              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n",
              "                <small style=\"color:#555\">Frame processado</small>\n",
              "              </div>\n",
              "              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n",
              "            `;\n",
              "          } else {\n",
              "            const left = document.getElementById('cam-left');\n",
              "            if (left) left.style.display = \"flex\";\n",
              "          }\n",
              "\n",
              "          if (!window._colabStream || window._colabStreamInactive) {\n",
              "            try {\n",
              "              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n",
              "              window._colabStreamInactive = false;\n",
              "            } catch (e) {\n",
              "              console.error('getUserMedia failed', e);\n",
              "              return false;\n",
              "            }\n",
              "          }\n",
              "          const video = document.getElementById('webcam');\n",
              "          if (video && video.srcObject !== window._colabStream) {\n",
              "            video.srcObject = window._colabStream;\n",
              "          }\n",
              "\n",
              "          const canvas = document.getElementById('canvas');\n",
              "          window.captureFrame = () => {\n",
              "            const ctx = canvas.getContext('2d');\n",
              "            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n",
              "            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n",
              "            canvas.width = vw; canvas.height = vh;\n",
              "            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n",
              "            return canvas.toDataURL('image/jpeg', 0.9);\n",
              "          };\n",
              "          window.updateProcessed = (b64) => {\n",
              "            const img = document.getElementById('output');\n",
              "            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n",
              "          };\n",
              "          window.stopColabCamera = () => {\n",
              "            try {\n",
              "              if (window._colabStream && !window._colabStreamInactive) {\n",
              "                window._colabStream.getTracks().forEach(t => t.stop());\n",
              "                window._colabStreamInactive = true;\n",
              "              }\n",
              "            } catch (e) { console.warn(e); }\n",
              "            const c = document.getElementById('camera-container');\n",
              "            if (c) c.remove();\n",
              "          };\n",
              "          return true;\n",
              "        } )();\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "          let container = document.getElementById('camera-container');\n",
              "          if (!container) {\n",
              "            container = document.createElement('div');\n",
              "            container.id = 'camera-container';\n",
              "            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n",
              "            document.body.appendChild(container);\n",
              "            container.innerHTML = `\n",
              "              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n",
              "                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n",
              "              </div>\n",
              "              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n",
              "                <small style=\"color:#555\">Frame processado</small>\n",
              "              </div>\n",
              "              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n",
              "            `;\n",
              "          } else {\n",
              "            const left = document.getElementById('cam-left');\n",
              "            if (left) left.style.display = \"flex\";\n",
              "          }\n",
              "\n",
              "          if (!window._colabStream || window._colabStreamInactive) {\n",
              "            try {\n",
              "              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n",
              "              window._colabStreamInactive = false;\n",
              "            } catch (e) {\n",
              "              console.error('getUserMedia failed', e);\n",
              "              return false;\n",
              "            }\n",
              "          }\n",
              "          const video = document.getElementById('webcam');\n",
              "          if (video && video.srcObject !== window._colabStream) {\n",
              "            video.srcObject = window._colabStream;\n",
              "          }\n",
              "\n",
              "          const canvas = document.getElementById('canvas');\n",
              "          window.captureFrame = () => {\n",
              "            const ctx = canvas.getContext('2d');\n",
              "            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n",
              "            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n",
              "            canvas.width = vw; canvas.height = vh;\n",
              "            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n",
              "            return canvas.toDataURL('image/jpeg', 0.9);\n",
              "          };\n",
              "          window.updateProcessed = (b64) => {\n",
              "            const img = document.getElementById('output');\n",
              "            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n",
              "          };\n",
              "          window.stopColabCamera = () => {\n",
              "            try {\n",
              "              if (window._colabStream && !window._colabStreamInactive) {\n",
              "                window._colabStream.getTracks().forEach(t => t.stop());\n",
              "                window._colabStreamInactive = true;\n",
              "              }\n",
              "            } catch (e) { console.warn(e); }\n",
              "            const c = document.getElementById('camera-container');\n",
              "            if (c) c.remove();\n",
              "          };\n",
              "          return true;\n",
              "        } )();\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "          let container = document.getElementById('camera-container');\n",
              "          if (!container) {\n",
              "            container = document.createElement('div');\n",
              "            container.id = 'camera-container';\n",
              "            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n",
              "            document.body.appendChild(container);\n",
              "            container.innerHTML = `\n",
              "              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n",
              "                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n",
              "              </div>\n",
              "              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n",
              "                <small style=\"color:#555\">Frame processado</small>\n",
              "              </div>\n",
              "              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n",
              "            `;\n",
              "          } else {\n",
              "            const left = document.getElementById('cam-left');\n",
              "            if (left) left.style.display = \"flex\";\n",
              "          }\n",
              "\n",
              "          if (!window._colabStream || window._colabStreamInactive) {\n",
              "            try {\n",
              "              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n",
              "              window._colabStreamInactive = false;\n",
              "            } catch (e) {\n",
              "              console.error('getUserMedia failed', e);\n",
              "              return false;\n",
              "            }\n",
              "          }\n",
              "          const video = document.getElementById('webcam');\n",
              "          if (video && video.srcObject !== window._colabStream) {\n",
              "            video.srcObject = window._colabStream;\n",
              "          }\n",
              "\n",
              "          const canvas = document.getElementById('canvas');\n",
              "          window.captureFrame = () => {\n",
              "            const ctx = canvas.getContext('2d');\n",
              "            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n",
              "            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n",
              "            canvas.width = vw; canvas.height = vh;\n",
              "            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n",
              "            return canvas.toDataURL('image/jpeg', 0.9);\n",
              "          };\n",
              "          window.updateProcessed = (b64) => {\n",
              "            const img = document.getElementById('output');\n",
              "            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n",
              "          };\n",
              "          window.stopColabCamera = () => {\n",
              "            try {\n",
              "              if (window._colabStream && !window._colabStreamInactive) {\n",
              "                window._colabStream.getTracks().forEach(t => t.stop());\n",
              "                window._colabStreamInactive = true;\n",
              "              }\n",
              "            } catch (e) { console.warn(e); }\n",
              "            const c = document.getElementById('camera-container');\n",
              "            if (c) c.remove();\n",
              "          };\n",
              "          return true;\n",
              "        } )();\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "          let container = document.getElementById('camera-container');\n",
              "          if (!container) {\n",
              "            container = document.createElement('div');\n",
              "            container.id = 'camera-container';\n",
              "            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n",
              "            document.body.appendChild(container);\n",
              "            container.innerHTML = `\n",
              "              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n",
              "                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n",
              "              </div>\n",
              "              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n",
              "                <small style=\"color:#555\">Frame processado</small>\n",
              "              </div>\n",
              "              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n",
              "            `;\n",
              "          } else {\n",
              "            const left = document.getElementById('cam-left');\n",
              "            if (left) left.style.display = \"flex\";\n",
              "          }\n",
              "\n",
              "          if (!window._colabStream || window._colabStreamInactive) {\n",
              "            try {\n",
              "              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n",
              "              window._colabStreamInactive = false;\n",
              "            } catch (e) {\n",
              "              console.error('getUserMedia failed', e);\n",
              "              return false;\n",
              "            }\n",
              "          }\n",
              "          const video = document.getElementById('webcam');\n",
              "          if (video && video.srcObject !== window._colabStream) {\n",
              "            video.srcObject = window._colabStream;\n",
              "          }\n",
              "\n",
              "          const canvas = document.getElementById('canvas');\n",
              "          window.captureFrame = () => {\n",
              "            const ctx = canvas.getContext('2d');\n",
              "            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n",
              "            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n",
              "            canvas.width = vw; canvas.height = vh;\n",
              "            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n",
              "            return canvas.toDataURL('image/jpeg', 0.9);\n",
              "          };\n",
              "          window.updateProcessed = (b64) => {\n",
              "            const img = document.getElementById('output');\n",
              "            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n",
              "          };\n",
              "          window.stopColabCamera = () => {\n",
              "            try {\n",
              "              if (window._colabStream && !window._colabStreamInactive) {\n",
              "                window._colabStream.getTracks().forEach(t => t.stop());\n",
              "                window._colabStreamInactive = true;\n",
              "              }\n",
              "            } catch (e) { console.warn(e); }\n",
              "            const c = document.getElementById('camera-container');\n",
              "            if (c) c.remove();\n",
              "          };\n",
              "          return true;\n",
              "        } )();\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "          let container = document.getElementById('camera-container');\n",
              "          if (!container) {\n",
              "            container = document.createElement('div');\n",
              "            container.id = 'camera-container';\n",
              "            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n",
              "            document.body.appendChild(container);\n",
              "            container.innerHTML = `\n",
              "              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n",
              "                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n",
              "              </div>\n",
              "              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n",
              "                <small style=\"color:#555\">Frame processado</small>\n",
              "              </div>\n",
              "              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n",
              "            `;\n",
              "          } else {\n",
              "            const left = document.getElementById('cam-left');\n",
              "            if (left) left.style.display = \"flex\";\n",
              "          }\n",
              "\n",
              "          if (!window._colabStream || window._colabStreamInactive) {\n",
              "            try {\n",
              "              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n",
              "              window._colabStreamInactive = false;\n",
              "            } catch (e) {\n",
              "              console.error('getUserMedia failed', e);\n",
              "              return false;\n",
              "            }\n",
              "          }\n",
              "          const video = document.getElementById('webcam');\n",
              "          if (video && video.srcObject !== window._colabStream) {\n",
              "            video.srcObject = window._colabStream;\n",
              "          }\n",
              "\n",
              "          const canvas = document.getElementById('canvas');\n",
              "          window.captureFrame = () => {\n",
              "            const ctx = canvas.getContext('2d');\n",
              "            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n",
              "            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n",
              "            canvas.width = vw; canvas.height = vh;\n",
              "            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n",
              "            return canvas.toDataURL('image/jpeg', 0.9);\n",
              "          };\n",
              "          window.updateProcessed = (b64) => {\n",
              "            const img = document.getElementById('output');\n",
              "            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n",
              "          };\n",
              "          window.stopColabCamera = () => {\n",
              "            try {\n",
              "              if (window._colabStream && !window._colabStreamInactive) {\n",
              "                window._colabStream.getTracks().forEach(t => t.stop());\n",
              "                window._colabStreamInactive = true;\n",
              "              }\n",
              "            } catch (e) { console.warn(e); }\n",
              "            const c = document.getElementById('camera-container');\n",
              "            if (c) c.remove();\n",
              "          };\n",
              "          return true;\n",
              "        } )();\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "          let container = document.getElementById('camera-container');\n",
              "          if (!container) {\n",
              "            container = document.createElement('div');\n",
              "            container.id = 'camera-container';\n",
              "            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n",
              "            document.body.appendChild(container);\n",
              "            container.innerHTML = `\n",
              "              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n",
              "                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n",
              "              </div>\n",
              "              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n",
              "                <small style=\"color:#555\">Frame processado</small>\n",
              "              </div>\n",
              "              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n",
              "            `;\n",
              "          } else {\n",
              "            const left = document.getElementById('cam-left');\n",
              "            if (left) left.style.display = \"flex\";\n",
              "          }\n",
              "\n",
              "          if (!window._colabStream || window._colabStreamInactive) {\n",
              "            try {\n",
              "              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n",
              "              window._colabStreamInactive = false;\n",
              "            } catch (e) {\n",
              "              console.error('getUserMedia failed', e);\n",
              "              return false;\n",
              "            }\n",
              "          }\n",
              "          const video = document.getElementById('webcam');\n",
              "          if (video && video.srcObject !== window._colabStream) {\n",
              "            video.srcObject = window._colabStream;\n",
              "          }\n",
              "\n",
              "          const canvas = document.getElementById('canvas');\n",
              "          window.captureFrame = () => {\n",
              "            const ctx = canvas.getContext('2d');\n",
              "            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n",
              "            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n",
              "            canvas.width = vw; canvas.height = vh;\n",
              "            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n",
              "            return canvas.toDataURL('image/jpeg', 0.9);\n",
              "          };\n",
              "          window.updateProcessed = (b64) => {\n",
              "            const img = document.getElementById('output');\n",
              "            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n",
              "          };\n",
              "          window.stopColabCamera = () => {\n",
              "            try {\n",
              "              if (window._colabStream && !window._colabStreamInactive) {\n",
              "                window._colabStream.getTracks().forEach(t => t.stop());\n",
              "                window._colabStreamInactive = true;\n",
              "              }\n",
              "            } catch (e) { console.warn(e); }\n",
              "            const c = document.getElementById('camera-container');\n",
              "            if (c) c.remove();\n",
              "          };\n",
              "          return true;\n",
              "        } )();\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "          let container = document.getElementById('camera-container');\n",
              "          if (!container) {\n",
              "            container = document.createElement('div');\n",
              "            container.id = 'camera-container';\n",
              "            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n",
              "            document.body.appendChild(container);\n",
              "            container.innerHTML = `\n",
              "              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n",
              "                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n",
              "              </div>\n",
              "              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n",
              "                <small style=\"color:#555\">Frame processado</small>\n",
              "              </div>\n",
              "              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n",
              "            `;\n",
              "          } else {\n",
              "            const left = document.getElementById('cam-left');\n",
              "            if (left) left.style.display = \"flex\";\n",
              "          }\n",
              "\n",
              "          if (!window._colabStream || window._colabStreamInactive) {\n",
              "            try {\n",
              "              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n",
              "              window._colabStreamInactive = false;\n",
              "            } catch (e) {\n",
              "              console.error('getUserMedia failed', e);\n",
              "              return false;\n",
              "            }\n",
              "          }\n",
              "          const video = document.getElementById('webcam');\n",
              "          if (video && video.srcObject !== window._colabStream) {\n",
              "            video.srcObject = window._colabStream;\n",
              "          }\n",
              "\n",
              "          const canvas = document.getElementById('canvas');\n",
              "          window.captureFrame = () => {\n",
              "            const ctx = canvas.getContext('2d');\n",
              "            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n",
              "            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n",
              "            canvas.width = vw; canvas.height = vh;\n",
              "            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n",
              "            return canvas.toDataURL('image/jpeg', 0.9);\n",
              "          };\n",
              "          window.updateProcessed = (b64) => {\n",
              "            const img = document.getElementById('output');\n",
              "            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n",
              "          };\n",
              "          window.stopColabCamera = () => {\n",
              "            try {\n",
              "              if (window._colabStream && !window._colabStreamInactive) {\n",
              "                window._colabStream.getTracks().forEach(t => t.stop());\n",
              "                window._colabStreamInactive = true;\n",
              "              }\n",
              "            } catch (e) { console.warn(e); }\n",
              "            const c = document.getElementById('camera-container');\n",
              "            if (c) c.remove();\n",
              "          };\n",
              "          return true;\n",
              "        } )();\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "          let container = document.getElementById('camera-container');\n",
              "          if (!container) {\n",
              "            container = document.createElement('div');\n",
              "            container.id = 'camera-container';\n",
              "            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n",
              "            document.body.appendChild(container);\n",
              "            container.innerHTML = `\n",
              "              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n",
              "                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n",
              "              </div>\n",
              "              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n",
              "                <small style=\"color:#555\">Frame processado</small>\n",
              "              </div>\n",
              "              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n",
              "            `;\n",
              "          } else {\n",
              "            const left = document.getElementById('cam-left');\n",
              "            if (left) left.style.display = \"flex\";\n",
              "          }\n",
              "\n",
              "          if (!window._colabStream || window._colabStreamInactive) {\n",
              "            try {\n",
              "              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n",
              "              window._colabStreamInactive = false;\n",
              "            } catch (e) {\n",
              "              console.error('getUserMedia failed', e);\n",
              "              return false;\n",
              "            }\n",
              "          }\n",
              "          const video = document.getElementById('webcam');\n",
              "          if (video && video.srcObject !== window._colabStream) {\n",
              "            video.srcObject = window._colabStream;\n",
              "          }\n",
              "\n",
              "          const canvas = document.getElementById('canvas');\n",
              "          window.captureFrame = () => {\n",
              "            const ctx = canvas.getContext('2d');\n",
              "            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n",
              "            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n",
              "            canvas.width = vw; canvas.height = vh;\n",
              "            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n",
              "            return canvas.toDataURL('image/jpeg', 0.9);\n",
              "          };\n",
              "          window.updateProcessed = (b64) => {\n",
              "            const img = document.getElementById('output');\n",
              "            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n",
              "          };\n",
              "          window.stopColabCamera = () => {\n",
              "            try {\n",
              "              if (window._colabStream && !window._colabStreamInactive) {\n",
              "                window._colabStream.getTracks().forEach(t => t.stop());\n",
              "                window._colabStreamInactive = true;\n",
              "              }\n",
              "            } catch (e) { console.warn(e); }\n",
              "            const c = document.getElementById('camera-container');\n",
              "            if (c) c.remove();\n",
              "          };\n",
              "          return true;\n",
              "        } )();\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "          let container = document.getElementById('camera-container');\n",
              "          if (!container) {\n",
              "            container = document.createElement('div');\n",
              "            container.id = 'camera-container';\n",
              "            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n",
              "            document.body.appendChild(container);\n",
              "            container.innerHTML = `\n",
              "              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n",
              "                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n",
              "              </div>\n",
              "              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n",
              "                <small style=\"color:#555\">Frame processado</small>\n",
              "              </div>\n",
              "              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n",
              "            `;\n",
              "          } else {\n",
              "            const left = document.getElementById('cam-left');\n",
              "            if (left) left.style.display = \"flex\";\n",
              "          }\n",
              "\n",
              "          if (!window._colabStream || window._colabStreamInactive) {\n",
              "            try {\n",
              "              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n",
              "              window._colabStreamInactive = false;\n",
              "            } catch (e) {\n",
              "              console.error('getUserMedia failed', e);\n",
              "              return false;\n",
              "            }\n",
              "          }\n",
              "          const video = document.getElementById('webcam');\n",
              "          if (video && video.srcObject !== window._colabStream) {\n",
              "            video.srcObject = window._colabStream;\n",
              "          }\n",
              "\n",
              "          const canvas = document.getElementById('canvas');\n",
              "          window.captureFrame = () => {\n",
              "            const ctx = canvas.getContext('2d');\n",
              "            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n",
              "            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n",
              "            canvas.width = vw; canvas.height = vh;\n",
              "            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n",
              "            return canvas.toDataURL('image/jpeg', 0.9);\n",
              "          };\n",
              "          window.updateProcessed = (b64) => {\n",
              "            const img = document.getElementById('output');\n",
              "            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n",
              "          };\n",
              "          window.stopColabCamera = () => {\n",
              "            try {\n",
              "              if (window._colabStream && !window._colabStreamInactive) {\n",
              "                window._colabStream.getTracks().forEach(t => t.stop());\n",
              "                window._colabStreamInactive = true;\n",
              "              }\n",
              "            } catch (e) { console.warn(e); }\n",
              "            const c = document.getElementById('camera-container');\n",
              "            if (c) c.remove();\n",
              "          };\n",
              "          return true;\n",
              "        } )();\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "          let container = document.getElementById('camera-container');\n",
              "          if (!container) {\n",
              "            container = document.createElement('div');\n",
              "            container.id = 'camera-container';\n",
              "            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n",
              "            document.body.appendChild(container);\n",
              "            container.innerHTML = `\n",
              "              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n",
              "                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n",
              "              </div>\n",
              "              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n",
              "                <small style=\"color:#555\">Frame processado</small>\n",
              "              </div>\n",
              "              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n",
              "            `;\n",
              "          } else {\n",
              "            const left = document.getElementById('cam-left');\n",
              "            if (left) left.style.display = \"flex\";\n",
              "          }\n",
              "\n",
              "          if (!window._colabStream || window._colabStreamInactive) {\n",
              "            try {\n",
              "              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n",
              "              window._colabStreamInactive = false;\n",
              "            } catch (e) {\n",
              "              console.error('getUserMedia failed', e);\n",
              "              return false;\n",
              "            }\n",
              "          }\n",
              "          const video = document.getElementById('webcam');\n",
              "          if (video && video.srcObject !== window._colabStream) {\n",
              "            video.srcObject = window._colabStream;\n",
              "          }\n",
              "\n",
              "          const canvas = document.getElementById('canvas');\n",
              "          window.captureFrame = () => {\n",
              "            const ctx = canvas.getContext('2d');\n",
              "            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n",
              "            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n",
              "            canvas.width = vw; canvas.height = vh;\n",
              "            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n",
              "            return canvas.toDataURL('image/jpeg', 0.9);\n",
              "          };\n",
              "          window.updateProcessed = (b64) => {\n",
              "            const img = document.getElementById('output');\n",
              "            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n",
              "          };\n",
              "          window.stopColabCamera = () => {\n",
              "            try {\n",
              "              if (window._colabStream && !window._colabStreamInactive) {\n",
              "                window._colabStream.getTracks().forEach(t => t.stop());\n",
              "                window._colabStreamInactive = true;\n",
              "              }\n",
              "            } catch (e) { console.warn(e); }\n",
              "            const c = document.getElementById('camera-container');\n",
              "            if (c) c.remove();\n",
              "          };\n",
              "          return true;\n",
              "        } )();\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "          let container = document.getElementById('camera-container');\n",
              "          if (!container) {\n",
              "            container = document.createElement('div');\n",
              "            container.id = 'camera-container';\n",
              "            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n",
              "            document.body.appendChild(container);\n",
              "            container.innerHTML = `\n",
              "              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n",
              "                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n",
              "              </div>\n",
              "              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n",
              "                <small style=\"color:#555\">Frame processado</small>\n",
              "              </div>\n",
              "              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n",
              "            `;\n",
              "          } else {\n",
              "            const left = document.getElementById('cam-left');\n",
              "            if (left) left.style.display = \"flex\";\n",
              "          }\n",
              "\n",
              "          if (!window._colabStream || window._colabStreamInactive) {\n",
              "            try {\n",
              "              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n",
              "              window._colabStreamInactive = false;\n",
              "            } catch (e) {\n",
              "              console.error('getUserMedia failed', e);\n",
              "              return false;\n",
              "            }\n",
              "          }\n",
              "          const video = document.getElementById('webcam');\n",
              "          if (video && video.srcObject !== window._colabStream) {\n",
              "            video.srcObject = window._colabStream;\n",
              "          }\n",
              "\n",
              "          const canvas = document.getElementById('canvas');\n",
              "          window.captureFrame = () => {\n",
              "            const ctx = canvas.getContext('2d');\n",
              "            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n",
              "            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n",
              "            canvas.width = vw; canvas.height = vh;\n",
              "            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n",
              "            return canvas.toDataURL('image/jpeg', 0.9);\n",
              "          };\n",
              "          window.updateProcessed = (b64) => {\n",
              "            const img = document.getElementById('output');\n",
              "            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n",
              "          };\n",
              "          window.stopColabCamera = () => {\n",
              "            try {\n",
              "              if (window._colabStream && !window._colabStreamInactive) {\n",
              "                window._colabStream.getTracks().forEach(t => t.stop());\n",
              "                window._colabStreamInactive = true;\n",
              "              }\n",
              "            } catch (e) { console.warn(e); }\n",
              "            const c = document.getElementById('camera-container');\n",
              "            if (c) c.remove();\n",
              "          };\n",
              "          return true;\n",
              "        } )();\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "          let container = document.getElementById('camera-container');\n",
              "          if (!container) {\n",
              "            container = document.createElement('div');\n",
              "            container.id = 'camera-container';\n",
              "            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n",
              "            document.body.appendChild(container);\n",
              "            container.innerHTML = `\n",
              "              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n",
              "                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n",
              "              </div>\n",
              "              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n",
              "                <small style=\"color:#555\">Frame processado</small>\n",
              "              </div>\n",
              "              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n",
              "            `;\n",
              "          } else {\n",
              "            const left = document.getElementById('cam-left');\n",
              "            if (left) left.style.display = \"flex\";\n",
              "          }\n",
              "\n",
              "          if (!window._colabStream || window._colabStreamInactive) {\n",
              "            try {\n",
              "              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n",
              "              window._colabStreamInactive = false;\n",
              "            } catch (e) {\n",
              "              console.error('getUserMedia failed', e);\n",
              "              return false;\n",
              "            }\n",
              "          }\n",
              "          const video = document.getElementById('webcam');\n",
              "          if (video && video.srcObject !== window._colabStream) {\n",
              "            video.srcObject = window._colabStream;\n",
              "          }\n",
              "\n",
              "          const canvas = document.getElementById('canvas');\n",
              "          window.captureFrame = () => {\n",
              "            const ctx = canvas.getContext('2d');\n",
              "            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n",
              "            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n",
              "            canvas.width = vw; canvas.height = vh;\n",
              "            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n",
              "            return canvas.toDataURL('image/jpeg', 0.9);\n",
              "          };\n",
              "          window.updateProcessed = (b64) => {\n",
              "            const img = document.getElementById('output');\n",
              "            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n",
              "          };\n",
              "          window.stopColabCamera = () => {\n",
              "            try {\n",
              "              if (window._colabStream && !window._colabStreamInactive) {\n",
              "                window._colabStream.getTracks().forEach(t => t.stop());\n",
              "                window._colabStreamInactive = true;\n",
              "              }\n",
              "            } catch (e) { console.warn(e); }\n",
              "            const c = document.getElementById('camera-container');\n",
              "            if (c) c.remove();\n",
              "          };\n",
              "          return true;\n",
              "        } )();\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "          let container = document.getElementById('camera-container');\n",
              "          if (!container) {\n",
              "            container = document.createElement('div');\n",
              "            container.id = 'camera-container';\n",
              "            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n",
              "            document.body.appendChild(container);\n",
              "            container.innerHTML = `\n",
              "              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n",
              "                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n",
              "              </div>\n",
              "              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n",
              "                <small style=\"color:#555\">Frame processado</small>\n",
              "              </div>\n",
              "              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n",
              "            `;\n",
              "          } else {\n",
              "            const left = document.getElementById('cam-left');\n",
              "            if (left) left.style.display = \"flex\";\n",
              "          }\n",
              "\n",
              "          if (!window._colabStream || window._colabStreamInactive) {\n",
              "            try {\n",
              "              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n",
              "              window._colabStreamInactive = false;\n",
              "            } catch (e) {\n",
              "              console.error('getUserMedia failed', e);\n",
              "              return false;\n",
              "            }\n",
              "          }\n",
              "          const video = document.getElementById('webcam');\n",
              "          if (video && video.srcObject !== window._colabStream) {\n",
              "            video.srcObject = window._colabStream;\n",
              "          }\n",
              "\n",
              "          const canvas = document.getElementById('canvas');\n",
              "          window.captureFrame = () => {\n",
              "            const ctx = canvas.getContext('2d');\n",
              "            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n",
              "            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n",
              "            canvas.width = vw; canvas.height = vh;\n",
              "            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n",
              "            return canvas.toDataURL('image/jpeg', 0.9);\n",
              "          };\n",
              "          window.updateProcessed = (b64) => {\n",
              "            const img = document.getElementById('output');\n",
              "            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n",
              "          };\n",
              "          window.stopColabCamera = () => {\n",
              "            try {\n",
              "              if (window._colabStream && !window._colabStreamInactive) {\n",
              "                window._colabStream.getTracks().forEach(t => t.stop());\n",
              "                window._colabStreamInactive = true;\n",
              "              }\n",
              "            } catch (e) { console.warn(e); }\n",
              "            const c = document.getElementById('camera-container');\n",
              "            if (c) c.remove();\n",
              "          };\n",
              "          return true;\n",
              "        } )();\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "          let container = document.getElementById('camera-container');\n",
              "          if (!container) {\n",
              "            container = document.createElement('div');\n",
              "            container.id = 'camera-container';\n",
              "            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n",
              "            document.body.appendChild(container);\n",
              "            container.innerHTML = `\n",
              "              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n",
              "                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n",
              "              </div>\n",
              "              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n",
              "                <small style=\"color:#555\">Frame processado</small>\n",
              "              </div>\n",
              "              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n",
              "            `;\n",
              "          } else {\n",
              "            const left = document.getElementById('cam-left');\n",
              "            if (left) left.style.display = \"flex\";\n",
              "          }\n",
              "\n",
              "          if (!window._colabStream || window._colabStreamInactive) {\n",
              "            try {\n",
              "              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n",
              "              window._colabStreamInactive = false;\n",
              "            } catch (e) {\n",
              "              console.error('getUserMedia failed', e);\n",
              "              return false;\n",
              "            }\n",
              "          }\n",
              "          const video = document.getElementById('webcam');\n",
              "          if (video && video.srcObject !== window._colabStream) {\n",
              "            video.srcObject = window._colabStream;\n",
              "          }\n",
              "\n",
              "          const canvas = document.getElementById('canvas');\n",
              "          window.captureFrame = () => {\n",
              "            const ctx = canvas.getContext('2d');\n",
              "            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n",
              "            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n",
              "            canvas.width = vw; canvas.height = vh;\n",
              "            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n",
              "            return canvas.toDataURL('image/jpeg', 0.9);\n",
              "          };\n",
              "          window.updateProcessed = (b64) => {\n",
              "            const img = document.getElementById('output');\n",
              "            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n",
              "          };\n",
              "          window.stopColabCamera = () => {\n",
              "            try {\n",
              "              if (window._colabStream && !window._colabStreamInactive) {\n",
              "                window._colabStream.getTracks().forEach(t => t.stop());\n",
              "                window._colabStreamInactive = true;\n",
              "              }\n",
              "            } catch (e) { console.warn(e); }\n",
              "            const c = document.getElementById('camera-container');\n",
              "            if (c) c.remove();\n",
              "          };\n",
              "          return true;\n",
              "        } )();\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "          let container = document.getElementById('camera-container');\n",
              "          if (!container) {\n",
              "            container = document.createElement('div');\n",
              "            container.id = 'camera-container';\n",
              "            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n",
              "            document.body.appendChild(container);\n",
              "            container.innerHTML = `\n",
              "              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n",
              "                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n",
              "              </div>\n",
              "              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n",
              "                <small style=\"color:#555\">Frame processado</small>\n",
              "              </div>\n",
              "              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n",
              "            `;\n",
              "          } else {\n",
              "            const left = document.getElementById('cam-left');\n",
              "            if (left) left.style.display = \"flex\";\n",
              "          }\n",
              "\n",
              "          if (!window._colabStream || window._colabStreamInactive) {\n",
              "            try {\n",
              "              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n",
              "              window._colabStreamInactive = false;\n",
              "            } catch (e) {\n",
              "              console.error('getUserMedia failed', e);\n",
              "              return false;\n",
              "            }\n",
              "          }\n",
              "          const video = document.getElementById('webcam');\n",
              "          if (video && video.srcObject !== window._colabStream) {\n",
              "            video.srcObject = window._colabStream;\n",
              "          }\n",
              "\n",
              "          const canvas = document.getElementById('canvas');\n",
              "          window.captureFrame = () => {\n",
              "            const ctx = canvas.getContext('2d');\n",
              "            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n",
              "            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n",
              "            canvas.width = vw; canvas.height = vh;\n",
              "            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n",
              "            return canvas.toDataURL('image/jpeg', 0.9);\n",
              "          };\n",
              "          window.updateProcessed = (b64) => {\n",
              "            const img = document.getElementById('output');\n",
              "            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n",
              "          };\n",
              "          window.stopColabCamera = () => {\n",
              "            try {\n",
              "              if (window._colabStream && !window._colabStreamInactive) {\n",
              "                window._colabStream.getTracks().forEach(t => t.stop());\n",
              "                window._colabStreamInactive = true;\n",
              "              }\n",
              "            } catch (e) { console.warn(e); }\n",
              "            const c = document.getElementById('camera-container');\n",
              "            if (c) c.remove();\n",
              "          };\n",
              "          return true;\n",
              "        } )();\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "          let container = document.getElementById('camera-container');\n",
              "          if (!container) {\n",
              "            container = document.createElement('div');\n",
              "            container.id = 'camera-container';\n",
              "            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n",
              "            document.body.appendChild(container);\n",
              "            container.innerHTML = `\n",
              "              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n",
              "                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n",
              "              </div>\n",
              "              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n",
              "                <small style=\"color:#555\">Frame processado</small>\n",
              "              </div>\n",
              "              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n",
              "            `;\n",
              "          } else {\n",
              "            const left = document.getElementById('cam-left');\n",
              "            if (left) left.style.display = \"flex\";\n",
              "          }\n",
              "\n",
              "          if (!window._colabStream || window._colabStreamInactive) {\n",
              "            try {\n",
              "              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n",
              "              window._colabStreamInactive = false;\n",
              "            } catch (e) {\n",
              "              console.error('getUserMedia failed', e);\n",
              "              return false;\n",
              "            }\n",
              "          }\n",
              "          const video = document.getElementById('webcam');\n",
              "          if (video && video.srcObject !== window._colabStream) {\n",
              "            video.srcObject = window._colabStream;\n",
              "          }\n",
              "\n",
              "          const canvas = document.getElementById('canvas');\n",
              "          window.captureFrame = () => {\n",
              "            const ctx = canvas.getContext('2d');\n",
              "            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n",
              "            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n",
              "            canvas.width = vw; canvas.height = vh;\n",
              "            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n",
              "            return canvas.toDataURL('image/jpeg', 0.9);\n",
              "          };\n",
              "          window.updateProcessed = (b64) => {\n",
              "            const img = document.getElementById('output');\n",
              "            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n",
              "          };\n",
              "          window.stopColabCamera = () => {\n",
              "            try {\n",
              "              if (window._colabStream && !window._colabStreamInactive) {\n",
              "                window._colabStream.getTracks().forEach(t => t.stop());\n",
              "                window._colabStreamInactive = true;\n",
              "              }\n",
              "            } catch (e) { console.warn(e); }\n",
              "            const c = document.getElementById('camera-container');\n",
              "            if (c) c.remove();\n",
              "          };\n",
              "          return true;\n",
              "        } )();\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "          let container = document.getElementById('camera-container');\n",
              "          if (!container) {\n",
              "            container = document.createElement('div');\n",
              "            container.id = 'camera-container';\n",
              "            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n",
              "            document.body.appendChild(container);\n",
              "            container.innerHTML = `\n",
              "              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n",
              "                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n",
              "              </div>\n",
              "              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n",
              "                <small style=\"color:#555\">Frame processado</small>\n",
              "              </div>\n",
              "              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n",
              "            `;\n",
              "          } else {\n",
              "            const left = document.getElementById('cam-left');\n",
              "            if (left) left.style.display = \"flex\";\n",
              "          }\n",
              "\n",
              "          if (!window._colabStream || window._colabStreamInactive) {\n",
              "            try {\n",
              "              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n",
              "              window._colabStreamInactive = false;\n",
              "            } catch (e) {\n",
              "              console.error('getUserMedia failed', e);\n",
              "              return false;\n",
              "            }\n",
              "          }\n",
              "          const video = document.getElementById('webcam');\n",
              "          if (video && video.srcObject !== window._colabStream) {\n",
              "            video.srcObject = window._colabStream;\n",
              "          }\n",
              "\n",
              "          const canvas = document.getElementById('canvas');\n",
              "          window.captureFrame = () => {\n",
              "            const ctx = canvas.getContext('2d');\n",
              "            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n",
              "            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n",
              "            canvas.width = vw; canvas.height = vh;\n",
              "            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n",
              "            return canvas.toDataURL('image/jpeg', 0.9);\n",
              "          };\n",
              "          window.updateProcessed = (b64) => {\n",
              "            const img = document.getElementById('output');\n",
              "            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n",
              "          };\n",
              "          window.stopColabCamera = () => {\n",
              "            try {\n",
              "              if (window._colabStream && !window._colabStreamInactive) {\n",
              "                window._colabStream.getTracks().forEach(t => t.stop());\n",
              "                window._colabStreamInactive = true;\n",
              "              }\n",
              "            } catch (e) { console.warn(e); }\n",
              "            const c = document.getElementById('camera-container');\n",
              "            if (c) c.remove();\n",
              "          };\n",
              "          return true;\n",
              "        } )();\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "          let container = document.getElementById('camera-container');\n",
              "          if (!container) {\n",
              "            container = document.createElement('div');\n",
              "            container.id = 'camera-container';\n",
              "            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n",
              "            document.body.appendChild(container);\n",
              "            container.innerHTML = `\n",
              "              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n",
              "                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n",
              "              </div>\n",
              "              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n",
              "                <small style=\"color:#555\">Frame processado</small>\n",
              "              </div>\n",
              "              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n",
              "            `;\n",
              "          } else {\n",
              "            const left = document.getElementById('cam-left');\n",
              "            if (left) left.style.display = \"flex\";\n",
              "          }\n",
              "\n",
              "          if (!window._colabStream || window._colabStreamInactive) {\n",
              "            try {\n",
              "              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n",
              "              window._colabStreamInactive = false;\n",
              "            } catch (e) {\n",
              "              console.error('getUserMedia failed', e);\n",
              "              return false;\n",
              "            }\n",
              "          }\n",
              "          const video = document.getElementById('webcam');\n",
              "          if (video && video.srcObject !== window._colabStream) {\n",
              "            video.srcObject = window._colabStream;\n",
              "          }\n",
              "\n",
              "          const canvas = document.getElementById('canvas');\n",
              "          window.captureFrame = () => {\n",
              "            const ctx = canvas.getContext('2d');\n",
              "            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n",
              "            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n",
              "            canvas.width = vw; canvas.height = vh;\n",
              "            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n",
              "            return canvas.toDataURL('image/jpeg', 0.9);\n",
              "          };\n",
              "          window.updateProcessed = (b64) => {\n",
              "            const img = document.getElementById('output');\n",
              "            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n",
              "          };\n",
              "          window.stopColabCamera = () => {\n",
              "            try {\n",
              "              if (window._colabStream && !window._colabStreamInactive) {\n",
              "                window._colabStream.getTracks().forEach(t => t.stop());\n",
              "                window._colabStreamInactive = true;\n",
              "              }\n",
              "            } catch (e) { console.warn(e); }\n",
              "            const c = document.getElementById('camera-container');\n",
              "            if (c) c.remove();\n",
              "          };\n",
              "          return true;\n",
              "        } )();\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "          let container = document.getElementById('camera-container');\n",
              "          if (!container) {\n",
              "            container = document.createElement('div');\n",
              "            container.id = 'camera-container';\n",
              "            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n",
              "            document.body.appendChild(container);\n",
              "            container.innerHTML = `\n",
              "              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n",
              "                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n",
              "              </div>\n",
              "              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n",
              "                <small style=\"color:#555\">Frame processado</small>\n",
              "              </div>\n",
              "              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n",
              "            `;\n",
              "          } else {\n",
              "            const left = document.getElementById('cam-left');\n",
              "            if (left) left.style.display = \"flex\";\n",
              "          }\n",
              "\n",
              "          if (!window._colabStream || window._colabStreamInactive) {\n",
              "            try {\n",
              "              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n",
              "              window._colabStreamInactive = false;\n",
              "            } catch (e) {\n",
              "              console.error('getUserMedia failed', e);\n",
              "              return false;\n",
              "            }\n",
              "          }\n",
              "          const video = document.getElementById('webcam');\n",
              "          if (video && video.srcObject !== window._colabStream) {\n",
              "            video.srcObject = window._colabStream;\n",
              "          }\n",
              "\n",
              "          const canvas = document.getElementById('canvas');\n",
              "          window.captureFrame = () => {\n",
              "            const ctx = canvas.getContext('2d');\n",
              "            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n",
              "            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n",
              "            canvas.width = vw; canvas.height = vh;\n",
              "            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n",
              "            return canvas.toDataURL('image/jpeg', 0.9);\n",
              "          };\n",
              "          window.updateProcessed = (b64) => {\n",
              "            const img = document.getElementById('output');\n",
              "            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n",
              "          };\n",
              "          window.stopColabCamera = () => {\n",
              "            try {\n",
              "              if (window._colabStream && !window._colabStreamInactive) {\n",
              "                window._colabStream.getTracks().forEach(t => t.stop());\n",
              "                window._colabStreamInactive = true;\n",
              "              }\n",
              "            } catch (e) { console.warn(e); }\n",
              "            const c = document.getElementById('camera-container');\n",
              "            if (c) c.remove();\n",
              "          };\n",
              "          return true;\n",
              "        } )();\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "          let container = document.getElementById('camera-container');\n",
              "          if (!container) {\n",
              "            container = document.createElement('div');\n",
              "            container.id = 'camera-container';\n",
              "            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n",
              "            document.body.appendChild(container);\n",
              "            container.innerHTML = `\n",
              "              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n",
              "                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n",
              "              </div>\n",
              "              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n",
              "                <small style=\"color:#555\">Frame processado</small>\n",
              "              </div>\n",
              "              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n",
              "            `;\n",
              "          } else {\n",
              "            const left = document.getElementById('cam-left');\n",
              "            if (left) left.style.display = \"flex\";\n",
              "          }\n",
              "\n",
              "          if (!window._colabStream || window._colabStreamInactive) {\n",
              "            try {\n",
              "              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n",
              "              window._colabStreamInactive = false;\n",
              "            } catch (e) {\n",
              "              console.error('getUserMedia failed', e);\n",
              "              return false;\n",
              "            }\n",
              "          }\n",
              "          const video = document.getElementById('webcam');\n",
              "          if (video && video.srcObject !== window._colabStream) {\n",
              "            video.srcObject = window._colabStream;\n",
              "          }\n",
              "\n",
              "          const canvas = document.getElementById('canvas');\n",
              "          window.captureFrame = () => {\n",
              "            const ctx = canvas.getContext('2d');\n",
              "            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n",
              "            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n",
              "            canvas.width = vw; canvas.height = vh;\n",
              "            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n",
              "            return canvas.toDataURL('image/jpeg', 0.9);\n",
              "          };\n",
              "          window.updateProcessed = (b64) => {\n",
              "            const img = document.getElementById('output');\n",
              "            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n",
              "          };\n",
              "          window.stopColabCamera = () => {\n",
              "            try {\n",
              "              if (window._colabStream && !window._colabStreamInactive) {\n",
              "                window._colabStream.getTracks().forEach(t => t.stop());\n",
              "                window._colabStreamInactive = true;\n",
              "              }\n",
              "            } catch (e) { console.warn(e); }\n",
              "            const c = document.getElementById('camera-container');\n",
              "            if (c) c.remove();\n",
              "          };\n",
              "          return true;\n",
              "        } )();\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "          let container = document.getElementById('camera-container');\n",
              "          if (!container) {\n",
              "            container = document.createElement('div');\n",
              "            container.id = 'camera-container';\n",
              "            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n",
              "            document.body.appendChild(container);\n",
              "            container.innerHTML = `\n",
              "              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n",
              "                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n",
              "              </div>\n",
              "              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n",
              "                <small style=\"color:#555\">Frame processado</small>\n",
              "              </div>\n",
              "              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n",
              "            `;\n",
              "          } else {\n",
              "            const left = document.getElementById('cam-left');\n",
              "            if (left) left.style.display = \"flex\";\n",
              "          }\n",
              "\n",
              "          if (!window._colabStream || window._colabStreamInactive) {\n",
              "            try {\n",
              "              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n",
              "              window._colabStreamInactive = false;\n",
              "            } catch (e) {\n",
              "              console.error('getUserMedia failed', e);\n",
              "              return false;\n",
              "            }\n",
              "          }\n",
              "          const video = document.getElementById('webcam');\n",
              "          if (video && video.srcObject !== window._colabStream) {\n",
              "            video.srcObject = window._colabStream;\n",
              "          }\n",
              "\n",
              "          const canvas = document.getElementById('canvas');\n",
              "          window.captureFrame = () => {\n",
              "            const ctx = canvas.getContext('2d');\n",
              "            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n",
              "            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n",
              "            canvas.width = vw; canvas.height = vh;\n",
              "            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n",
              "            return canvas.toDataURL('image/jpeg', 0.9);\n",
              "          };\n",
              "          window.updateProcessed = (b64) => {\n",
              "            const img = document.getElementById('output');\n",
              "            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n",
              "          };\n",
              "          window.stopColabCamera = () => {\n",
              "            try {\n",
              "              if (window._colabStream && !window._colabStreamInactive) {\n",
              "                window._colabStream.getTracks().forEach(t => t.stop());\n",
              "                window._colabStreamInactive = true;\n",
              "              }\n",
              "            } catch (e) { console.warn(e); }\n",
              "            const c = document.getElementById('camera-container');\n",
              "            if (c) c.remove();\n",
              "          };\n",
              "          return true;\n",
              "        } )();\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Liveness] energia média: 18.45 -> live\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "          let container = document.getElementById('camera-container');\n",
              "          if (!container) {\n",
              "            container = document.createElement('div');\n",
              "            container.id = 'camera-container';\n",
              "            container.style = 'display:flex; gap:12px; align-items:flex-start; justify-content:center; flex-wrap:wrap;';\n",
              "            document.body.appendChild(container);\n",
              "            container.innerHTML = `\n",
              "              <div id=\"cam-left\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <video id=\"webcam\" autoplay playsinline muted style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\"></video>\n",
              "                <small style=\"color:#555\">Pré-visualização (ao vivo)</small>\n",
              "              </div>\n",
              "              <div id=\"cam-right\" style=\"display:flex; flex-direction:column; align-items:center; gap:6px;\">\n",
              "                <img id=\"output\" style=\"max-width:640px; border:1px solid #ddd; border-radius:8px;\">\n",
              "                <small style=\"color:#555\">Frame processado</small>\n",
              "              </div>\n",
              "              <canvas id=\"canvas\" style=\"display:none;\"></canvas>\n",
              "            `;\n",
              "          } else {\n",
              "            const left = document.getElementById('cam-left');\n",
              "            if (left) left.style.display = \"flex\";\n",
              "          }\n",
              "\n",
              "          if (!window._colabStream || window._colabStreamInactive) {\n",
              "            try {\n",
              "              window._colabStream = await navigator.mediaDevices.getUserMedia({ video: {width:640, height:480}, audio:false });\n",
              "              window._colabStreamInactive = false;\n",
              "            } catch (e) {\n",
              "              console.error('getUserMedia failed', e);\n",
              "              return false;\n",
              "            }\n",
              "          }\n",
              "          const video = document.getElementById('webcam');\n",
              "          if (video && video.srcObject !== window._colabStream) {\n",
              "            video.srcObject = window._colabStream;\n",
              "          }\n",
              "\n",
              "          const canvas = document.getElementById('canvas');\n",
              "          window.captureFrame = () => {\n",
              "            const ctx = canvas.getContext('2d');\n",
              "            const vw = (video && video.videoWidth) ? video.videoWidth : 640;\n",
              "            const vh = (video && video.videoHeight) ? video.videoHeight : 480;\n",
              "            canvas.width = vw; canvas.height = vh;\n",
              "            if (video) ctx.drawImage(video, 0, 0, vw, vh);\n",
              "            return canvas.toDataURL('image/jpeg', 0.9);\n",
              "          };\n",
              "          window.updateProcessed = (b64) => {\n",
              "            const img = document.getElementById('output');\n",
              "            if (img) img.src = 'data:image/jpeg;base64,' + b64;\n",
              "          };\n",
              "          window.stopColabCamera = () => {\n",
              "            try {\n",
              "              if (window._colabStream && !window._colabStreamInactive) {\n",
              "                window._colabStream.getTracks().forEach(t => t.stop());\n",
              "                window._colabStreamInactive = true;\n",
              "              }\n",
              "            } catch (e) { console.warn(e); }\n",
              "            const c = document.getElementById('camera-container');\n",
              "            if (c) c.remove();\n",
              "          };\n",
              "          return true;\n",
              "        } )();\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧭 1:N — predito=teste | dist=67.8 | thr=68.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "if (window.stopColabCamera) window.stopColabCamera();"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'approved',\n",
              " 'mode': '1vN',\n",
              " 'user': 'teste',\n",
              " 'dist': 67.79370293171363,\n",
              " 'threshold': 68.0}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "\n",
        "# =============================\n",
        "# Runner: inclusão (novo) ou autenticação (auth) com escolha 1:1 / 1:N\n",
        "# + escolha do detector de faces (haar | dnn_ssd_resnet10)\n",
        "# =============================\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Aqui apenas definimos qual detector será usado pelo pipeline já existente.\n",
        "print(\"Selecione o detector de faces a ser usado na célula 5 (detect_faces).\")\n",
        "print(\"Opções: 'haar' (CascadeClassifier) ou 'dnn_ssd_resnet10' (OpenCV DNN SSD ResNet10)\")\n",
        "_detector_choice = input(\"Detector [dnn_ssd_resnet10/haar]: \").strip().lower()\n",
        "if _detector_choice not in (\"\", \"haar\", \"dnn_ssd_resnet10\", \"dnn\", \"ssd\", \"resnet10\"):\n",
        "    print(\"Opção inválida; usando padrão: dnn_ssd_resnet10\")\n",
        "    _detector_choice = \"dnn_ssd_resnet10\"\n",
        "if _detector_choice in (\"\", \"dnn\", \"ssd\", \"resnet10\"):\n",
        "    _detector_choice = \"dnn_ssd_resnet10\"\n",
        "\n",
        "# Propaga para a célula 5: variável global e variável de ambiente (para debug/diagnóstico)\n",
        "try:\n",
        "    DETECTION_MODEL  # verifica se existe a global da célula 5\n",
        "    globals()[\"DETECTION_MODEL\"] = _detector_choice\n",
        "except NameError:\n",
        "    # Se a célula 5 ainda não foi executada, definimos aqui para não quebrar;\n",
        "    # quando a célula 5 for rodada, ela lerá este valor do ambiente.\n",
        "    pass\n",
        "os.environ[\"DETECTION_MODEL\"] = _detector_choice\n",
        "print(f\"[Runner] Detector selecionado: {os.environ['DETECTION_MODEL']}\")\n",
        "\n",
        "# (Opcional) Validação rápida de arquivos quando DNN é escolhido (evita erro tardio)\n",
        "if os.environ[\"DETECTION_MODEL\"] == \"dnn_ssd_resnet10\":\n",
        "    proto = os.environ.get(\"DNN_PROTO_PATH\", \"models/deploy.prototxt\")\n",
        "    weights = os.environ.get(\"DNN_WEIGHTS_PATH\", \"models/res10_300x300_ssd_iter_140000_fp16.caffemodel\")\n",
        "    if not (Path(proto).exists() and Path(weights).exists()):\n",
        "        print(\"[Aviso DNN] Arquivos do DNN não encontrados.\")\n",
        "        print(f\"  Prototxt: {proto}\")\n",
        "        print(f\"  Pesos   : {weights}\")\n",
        "        print(\"  → Ajuste DNN_PROTO_PATH / DNN_WEIGHTS_PATH ou coloque os arquivos em 'models/'.\")\n",
        "\n",
        "N_SAMPLES          = 30                      # amostras para enrollment (30–60 recomendado)\n",
        "FRAME_DELAY_MS     = 100                     # intervalo entre capturas (ms)\n",
        "LBPH_NEIGHBORS     = 16                      # 8 ou 16 costumam ir bem\n",
        "DO_LIVENESS_TEST   = True                    # liveness antes da autenticação\n",
        "\n",
        "# Pergunta inicial\n",
        "print(\"Deseja incluir um novo usuário no modelo ou apenas autenticar um já existente?\")\n",
        "print(\"Digite 'novo' para incluir, ou 'auth' para apenas autenticar.\")\n",
        "modo = input(\"Modo [novo/auth]: \").strip().lower()\n",
        "\n",
        "# Definições padrão\n",
        "NEW_USER_ID = None\n",
        "EXPECTED_USER_1V1 = None\n",
        "AUTH_MODE_1V1 = True  # default (será perguntado quando for 'auth')\n",
        "\n",
        "if modo == \"novo\":\n",
        "    typed_name = input(\"Digite o identificador do novo usuário (ou deixe em branco para gerar automático): \").strip()\n",
        "    if not typed_name:\n",
        "        # Gera nome automático com o próximo índice baseado nas pastas já existentes\n",
        "        try:\n",
        "            existing_dirs = sorted([d.name for d in ENROLL_DIR.iterdir() if d.is_dir()])\n",
        "        except Exception:\n",
        "            existing_dirs = []\n",
        "        idx = len(existing_dirs)\n",
        "        typed_name = f\"novo_usuario_preview_{idx+1}\"\n",
        "        print(f\"[auto] Nome atribuído: {typed_name}\")\n",
        "    NEW_USER_ID = typed_name\n",
        "    EXPECTED_USER_1V1 = NEW_USER_ID  # após incluir, autentica 1:1 (mesma pessoa)\n",
        "\n",
        "elif modo == \"auth\":\n",
        "    # Escolha do tipo de autenticação\n",
        "    print(\"Qual tipo de autenticação deseja usar?\")\n",
        "    print(\"Digite '1' para 1:1 (comparar com um usuário específico) ou 'N' para 1:N (identificar entre os cadastrados).\")\n",
        "    auth_choice = input(\"Tipo [1/N]: \").strip().lower()\n",
        "    if auth_choice == \"1\":\n",
        "        AUTH_MODE_1V1 = True\n",
        "        EXPECTED_USER_1V1 = input(\"Digite o identificador do usuário a ser autenticado (1:1): \").strip()\n",
        "        if not EXPECTED_USER_1V1:\n",
        "            raise ValueError(\"Para autenticação 1:1 é necessário informar o identificador esperado.\")\n",
        "    else:\n",
        "        AUTH_MODE_1V1 = False\n",
        "        EXPECTED_USER_1V1 = None  # 1:N não requer nome\n",
        "else:\n",
        "    raise ValueError(\"Opção inválida. Use 'novo' ou 'auth'.\")\n",
        "\n",
        "display_result = {\"status\":\"error\", \"reason\":\"not_executed\"}\n",
        "try:\n",
        "    if modo == \"novo\":\n",
        "        # 1) enrollment do novo usuário\n",
        "        enroll_user_with_preview(user_id=NEW_USER_ID, n_samples=N_SAMPLES, interval_ms=FRAME_DELAY_MS)\n",
        "        # 2) re-treino do modelo em memória\n",
        "        _ = get_recognizer(neighbors=LBPH_NEIGHBORS, force_retrain=True)\n",
        "        # 3) calibração de threshold\n",
        "        calibrate_threshold(samples=15, neighbors=LBPH_NEIGHBORS)\n",
        "    else:\n",
        "        # Apenas autenticação: garante que o modelo está carregado (re-treina se necessário)\n",
        "        try:\n",
        "            _ = get_recognizer(neighbors=LBPH_NEIGHBORS, force_retrain=False)\n",
        "        except Exception:\n",
        "            _ = get_recognizer(neighbors=LBPH_NEIGHBORS, force_retrain=True)\n",
        "\n",
        "    # 4) autenticação (sempre roda)\n",
        "    if AUTH_MODE_1V1:\n",
        "        display_result = authenticate_1v1_preview(expected_user=EXPECTED_USER_1V1,\n",
        "                                                  neighbors=LBPH_NEIGHBORS,\n",
        "                                                  require_liveness=DO_LIVENESS_TEST)\n",
        "    else:\n",
        "        display_result = authenticate_1vN_preview(neighbors=LBPH_NEIGHBORS,\n",
        "                                                  require_liveness=DO_LIVENESS_TEST)\n",
        "\n",
        "finally:\n",
        "    # sempre encerra a pré-visualização no Colab / janelas no local\n",
        "    try:\n",
        "        stop_camera_ui()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "display_result\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================\n",
        "# Execução de AVALIAÇÃO offline (após o fluxo de câmera)\n",
        "# =============================\n",
        "from pathlib import Path\n",
        "import zipfile, urllib.request\n",
        "\n",
        "# dataset default (você pode trocar o caminho aqui, se quiser)\n",
        "try:\n",
        "    DATA_DIR\n",
        "except NameError:\n",
        "    DATA_DIR = Path(\"cv_colab_data\")\n",
        "    DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "DEFAULT_DATASET_DIR = DATA_DIR / \"dataset_default\"\n",
        "(DEFAULT_DATASET_DIR / \"positives\").mkdir(parents=True, exist_ok=True)\n",
        "(DEFAULT_DATASET_DIR / \"negatives\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def _download_and_unpack_zip(url: str, dest_root: Path) -> Path:\n",
        "    \"\"\"Baixa um .zip com positives/ e negatives/ e extrai para dest_root/'dataset_remote'.\"\"\"\n",
        "    zip_path = dest_root / \"dataset_remote.zip\"\n",
        "    out_dir  = dest_root / \"dataset_remote\"\n",
        "    print(f\"Baixando dataset remoto: {url}\")\n",
        "    urllib.request.urlretrieve(url, str(zip_path))\n",
        "    print(f\"✔ zip salvo em: {zip_path}\")\n",
        "    # limpa extração anterior\n",
        "    if out_dir.exists():\n",
        "        import shutil; shutil.rmtree(out_dir)\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    with zipfile.ZipFile(str(zip_path), 'r') as zf:\n",
        "        zf.extractall(str(out_dir))\n",
        "    # achar a raiz com positives/ e negatives/\n",
        "    def _find_ds(root: Path):\n",
        "        if (root / \"positives\").is_dir() and (root / \"negatives\").is_dir():\n",
        "            return root\n",
        "        for p in root.rglob(\"*\"):\n",
        "            if p.is_dir() and (p / \"positives\").is_dir() and (p / \"negatives\").is_dir():\n",
        "                return p\n",
        "        return None\n",
        "    ds = _find_ds(out_dir)\n",
        "    if ds is None:\n",
        "        raise ValueError(\"Zip não contém positives/ e negatives/.\")\n",
        "    print(f\"✔ dataset encontrado em: {ds}\")\n",
        "    return ds\n",
        "\n",
        "try:\n",
        "    run_eval_auto = input(\n",
        "        \"Rodar avaliação offline (Automático/Default/Remoto)? [s/N]: \"\n",
        "    ).strip().lower() in (\"s\",\"sim\",\"y\",\"yes\")\n",
        "except Exception:\n",
        "    run_eval_auto = False\n",
        "\n",
        "if run_eval_auto:\n",
        "    print(\"Fonte do dataset:\")\n",
        "    print(\"  1) Automático (enrollment + negatives persistentes/câmera)\")\n",
        "    print(f\"  2) DEFAULT ({DEFAULT_DATASET_DIR})\")\n",
        "    print(\"  3) REMOTO/LOCAL existente (URL .zip ou caminho local)\")\n",
        "    choice = (input(\"Escolha [1/2/3]: \").strip() or \"1\")\n",
        "\n",
        "    dataset_override = None\n",
        "    default_dir = None\n",
        "\n",
        "    if choice == \"2\":\n",
        "        default_dir = DEFAULT_DATASET_DIR\n",
        "        print(f\"ℹ Usando dataset DEFAULT: {default_dir}\")\n",
        "    elif choice == \"3\":\n",
        "        ds_input = input(\"Informe URL .zip OU caminho local com positives/ e negatives/: \").strip()\n",
        "        if ds_input.startswith((\"http://\",\"https://\")):\n",
        "            dataset_override = _download_and_unpack_zip(ds_input, DATA_DIR)\n",
        "        else:\n",
        "            p = Path(ds_input)\n",
        "            if not p.exists(): raise ValueError(f\"Caminho não existe: {p}\")\n",
        "            if not ((p / \"positives\").is_dir() and (p / \"negatives\").is_dir()):\n",
        "                raise ValueError(f\"Caminho inválido (esperado positives/ e negatives/): {p}\")\n",
        "            dataset_override = p\n",
        "\n",
        "    # Perguntas opcionais (as mesmas que você já tinha)\n",
        "    try:\n",
        "        use_camera = input(\"Usar câmera para completar negativos (apenas Automático)? [S/n]: \").strip().lower()\n",
        "        use_camera = not (use_camera in (\"n\",\"nao\",\"não\"))\n",
        "    except Exception:\n",
        "        use_camera = True\n",
        "\n",
        "    try:\n",
        "        neg_src = input(\"Pasta extra com negativos (vazio = nenhuma): \").strip() or None\n",
        "    except Exception:\n",
        "        neg_src = None\n",
        "\n",
        "    try:\n",
        "        max_imgs = input(\"Limitar nº de imagens por classe? (vazio = sem limite): \").strip()\n",
        "        max_imgs = int(max_imgs) if max_imgs else None\n",
        "    except Exception:\n",
        "        max_imgs = None\n",
        "\n",
        "    try:\n",
        "        th = input(\"Conf threshold (vazio = 0.5): \").strip()\n",
        "        th = float(th) if th else 0.5\n",
        "    except Exception:\n",
        "        th = 0.5\n",
        "\n",
        "    # Chamada final — agora com dataset_override e default_dataset_dir\n",
        "    if dataset_override is not None:\n",
        "        _ = run_offline_eval_from_enrollment(\n",
        "            eval_max_images=max_imgs,\n",
        "            conf_threshold=th,\n",
        "            use_camera=False,\n",
        "            negatives_src_dir=None,\n",
        "            dataset_dir_override=dataset_override,   # usa dataset pronto\n",
        "            default_dataset_dir=None,\n",
        "        )\n",
        "    elif default_dir is not None:\n",
        "        _ = run_offline_eval_from_enrollment(\n",
        "            eval_max_images=max_imgs,\n",
        "            conf_threshold=th,\n",
        "            use_camera=False,                        # default não captura; usa o que já houver lá\n",
        "            negatives_src_dir=None,\n",
        "            dataset_dir_override=None,\n",
        "            default_dataset_dir=default_dir,         # usa dataset default\n",
        "        )\n",
        "    else:\n",
        "        _ = run_offline_eval_from_enrollment(\n",
        "            neg_target_min=30,\n",
        "            capture_batch=30,\n",
        "            capture_sleep_sec=0.15,\n",
        "            eval_max_images=max_imgs,\n",
        "            conf_threshold=th,\n",
        "            use_camera=use_camera,                   # automático\n",
        "            negatives_src_dir=neg_src,\n",
        "            dataset_dir_override=None, # corrigido\n",
        "            default_dataset_dir=None, # corrigido\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 847
        },
        "id": "RxMyTuepD2e2",
        "outputId": "7b51111b-3faf-4a9b-90e2-5864c86e1fbf"
      },
      "id": "RxMyTuepD2e2",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rodar avaliação offline (Automático/Default/Remoto)? [s/N]: s\n",
            "Fonte do dataset:\n",
            "  1) Automático (enrollment + negatives persistentes/câmera)\n",
            "  2) DEFAULT (cv_colab_data/dataset_default)\n",
            "  3) REMOTO/LOCAL existente (URL .zip ou caminho local)\n",
            "Escolha [1/2/3]: 1\n",
            "Usar câmera para completar negativos (apenas Automático)? [S/n]: \n",
            "Pasta extra com negativos (vazio = nenhuma): \n",
            "Limitar nº de imagens por classe? (vazio = sem limite): \n",
            "Conf threshold (vazio = 0.5): \n",
            "✔ Positives (todos): 150\n",
            "ℹ Negativos existentes: 0. Capturando 30 para atingir >= 30 …\n",
            "✘ Não foi possível abrir a câmera para capturar negativos.\n",
            "✔ Negatives adicionados ao dataset_auto: 0\n",
            "\n",
            "[AVISO] Apenas 1 classe presente (faltando: no_face). Métricas completas não se aplicam.\n",
            "\n",
            "=== Resultados: haar ===\n",
            "Accuracy : 0.9733\n",
            "Precision: 1.0\n",
            "Recall   : 0.9733333333333334\n",
            "F1-score : 0.9864864864864865\n",
            "Tempo médio por imagem: 0.0207 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  modelo  accuracy  precision    recall        f1  avg_time    n  \\\n",
              "0   haar  0.973333        1.0  0.973333  0.986486  0.020725  150   \n",
              "\n",
              "  classes_presentes  \n",
              "0            [face]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d58d01dd-7d79-4515-b900-d174d9ee547e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>modelo</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "      <th>avg_time</th>\n",
              "      <th>n</th>\n",
              "      <th>classes_presentes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>haar</td>\n",
              "      <td>0.973333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.973333</td>\n",
              "      <td>0.986486</td>\n",
              "      <td>0.020725</td>\n",
              "      <td>150</td>\n",
              "      <td>[face]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d58d01dd-7d79-4515-b900-d174d9ee547e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d58d01dd-7d79-4515-b900-d174d9ee547e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d58d01dd-7d79-4515-b900-d174d9ee547e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"        )\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"modelo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"haar\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9733333333333334,\n        \"max\": 0.9733333333333334,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9733333333333334\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9733333333333334,\n        \"max\": 0.9733333333333334,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9733333333333334\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9864864864864865,\n        \"max\": 0.9864864864864865,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9864864864864865\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.02072466118669278,\n        \"max\": 0.02072466118669278,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.02072466118669278\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 150,\n        \"max\": 150,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          150\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"classes_presentes\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}